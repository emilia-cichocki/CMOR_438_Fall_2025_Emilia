{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import *\n",
    "import sys\n",
    "sys.path.append('/Users/emicatx/Downloads/CMOR_438_FALL_2025_Emilia/src')\n",
    "from rice_ml.preprocess.datatype import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "ArrayLike = Union[np.ndarray, Sequence[float], Sequence[Sequence[float]], pd.DataFrame, pd.Series]\n",
    "\n",
    "def _ensure_numeric(data_vector: ArrayLike, name: str = 'Data') -> np.ndarray:\n",
    "\n",
    "    # TODO: docstrings, type hints, and examples\n",
    "\n",
    "    vector = _1D_vectorized(data_vector, name)\n",
    "    \n",
    "    if not np.issubdtype(vector.dtype, np.number):\n",
    "        try:\n",
    "            vector = vector.astype(float, copy = False)\n",
    "        except (TypeError, ValueError) as e:\n",
    "            raise TypeError(f'All entries in {name} must be numeric') from e\n",
    "    else:\n",
    "        vector = vector.astype(float, copy = False)\n",
    "\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0.])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array = np.array([True, False, True, False])\n",
    "_ensure_numeric(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1, 1, 1]\n",
    "_1D_vectorized(x, 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(data_vector_1: ArrayLike, \n",
    "                       data_vector_2: ArrayLike, \n",
    "                       name_1: str = 'data_vector_1', \n",
    "                       name_2: str = 'data_vector_2') -> float:\n",
    "    \n",
    "    # TODO: docstrings, type hints, and examples\n",
    "\n",
    "    vector_1 = _ensure_numeric(data_vector_1, name_1)\n",
    "    vector_2 = _ensure_numeric(data_vector_2, name_2)\n",
    "\n",
    "    _shape_match(vector_1, vector_2)\n",
    "\n",
    "    distance = float(np.linalg.norm((vector_2 - vector_1)))\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(data_vector_1: ArrayLike, \n",
    "                       data_vector_2: ArrayLike, \n",
    "                       name_1: str = 'data_vector_1', \n",
    "                       name_2: str = 'data_vector_2') -> float:\n",
    "    \n",
    "    vector_1 = _ensure_numeric(data_vector_1, name_1)\n",
    "    vector_2 = _ensure_numeric(data_vector_2, name_2)\n",
    "\n",
    "    _shape_match(vector_1, vector_2)\n",
    "\n",
    "    distance = float(np.sum(np.abs(vector_2 - vector_1)))\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowski_distance(data_vector_1: ArrayLike, \n",
    "                       data_vector_2: ArrayLike, \n",
    "                       p: int,\n",
    "                       name_1: str = 'data_vector_1', \n",
    "                       name_2: str = 'data_vector_2') -> float:\n",
    "    \n",
    "    if not isinstance(p, int):\n",
    "        raise TypeError('p parameter must be an integer')\n",
    "    if p <= 0:\n",
    "        raise ValueError('p parameter must be greater than zero')\n",
    "    \n",
    "    vector_1 = _ensure_numeric(data_vector_1, name_1)\n",
    "    vector_2 = _ensure_numeric(data_vector_2, name_2)\n",
    "\n",
    "    _shape_match(vector_1, vector_2)\n",
    "\n",
    "    distance = float((np.sum((np.abs(vector_2 - vector_1)) ** p)) ** (1 / p))\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [-1, -2]\n",
    "b = [2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.497941445275415"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distance(a, b, 'a', 'b')\n",
    "manhattan_distance(a,b)\n",
    "minkowski_distance(a, b, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1 = pd.Series([1, 1, 1])\n",
    "\n",
    "output = _ensure_numeric(input_1)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_query = np.array([[1, 2], [3, 4]])\n",
    "X_train = np.array([[4, 6], [0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _distance_calculations(training_array: np.ndarray, query_array: np.ndarray, metric: str, p: Optional[int] = 3) -> np.ndarray:\n",
    "\n",
    "    # TODO: docstrings, examples (query is row, training is column)\n",
    "\n",
    "    query_array = _2D_numeric(query_array)\n",
    "    training_array = _2D_numeric(training_array)\n",
    "\n",
    "    distance_matrix = np.full((query_array.shape[0], training_array.shape[0]), np.nan)\n",
    "    for index_1, point_1 in enumerate(query_array):\n",
    "        for index_2, point_2 in enumerate(training_array):\n",
    "            if metric == 'euclidean':\n",
    "                distance = euclidean_distance(point_1, point_2)\n",
    "            elif metric == 'manhattan':\n",
    "                distance = manhattan_distance(point_1, point_2)\n",
    "            elif metric == 'minkowski':\n",
    "                distance = minkowski_distance(point_1, point_2, p = p)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported metric: {metric}\")\n",
    "            distance_matrix[index_1, index_2] = distance\n",
    "\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _neighbor_finding(training_array: np.ndarray, query_array: np.ndarray, k: int, metric: str, p: Optional[int] = 3) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    # TODO: docstrings and examples, potentially add further checks for other inputs\n",
    "\n",
    "    if k > training_array.shape[0]:\n",
    "        raise ValueError(f'Number of neighbors (k = {k}) cannot be greater than number of training samples ({training_array.shape[0]})')\n",
    "    \n",
    "    distance_matrix = _distance_calculations(training_array, query_array, metric = metric, p = p)\n",
    "    indices = np.argpartition(distance_matrix, kth = k - 1, axis = 1)[:, 0:k]\n",
    "\n",
    "    query_indices = np.arange(distance_matrix.shape[0])[:, None]\n",
    "    neighbor_distances = distance_matrix[query_indices, indices]\n",
    "    ordering = np.argsort(neighbor_distances, axis = 1)\n",
    "    sorted_indices = indices[query_indices, ordering]\n",
    "    distances_sorted = neighbor_distances[query_indices, ordering]\n",
    "\n",
    "    return distances_sorted, sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = np.array([1, 2, 3])\n",
    "two = np.array([1, 2, 4])\n",
    "\n",
    "overlap = (one == two).astype(float)\n",
    "mean_accuracy = float(np.mean(overlap))\n",
    "mean_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3]\n",
      " [3 4]]\n",
      "[[0.5 1. ]\n",
      " [1.  2. ]]\n",
      "[[1. 3.]\n",
      " [3. 8.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2. , 5.5])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array([1, 2, 3, 4])\n",
    "indices = np.array([[1, 2], [2, 3]])\n",
    "n_neighbor = np.array([[0.5, 1], [1, 2]])\n",
    "print(labels[indices])\n",
    "print(n_neighbor)\n",
    "weighted = labels[indices] * n_neighbor\n",
    "print(weighted)\n",
    "(np.mean(weighted, axis = 1)).astype(float, copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay\n",
      "(array([0, 0]), array([1, 2]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 3])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = np.array([[0, 1, 1]])\n",
    "targets = np.array([[1, 2, 3]])\n",
    "if np.any(weight == 0).astype(bool):\n",
    "    print('yay')\n",
    "\n",
    "print(np.where(weight != 0))\n",
    "targets[np.where(weight != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.41421356 1.41421356]\n",
      " [1.         2.23606798]]\n",
      "[[0 1]\n",
      " [1 2]]\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([\n",
    "    [0, 0],\n",
    " [2, 2],\n",
    " [1, 3]\n",
    "])\n",
    "\n",
    "# Query data (2 points in 2D)\n",
    "X_query = np.array([\n",
    "[1, 1],\n",
    " [3, 2]\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "k = 2\n",
    "metric = \"euclidean\"\n",
    "\n",
    "distances, indices = _neighbor_finding(X_train, X_query, 2, metric = metric)\n",
    "print(distances)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30471708],\n",
       "       [-1.03998411],\n",
       "       [ 0.7504512 ]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "rng.standard_normal(3).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.25992105, 3.27106631],\n",
       "       [1.25992105, 1.        ],\n",
       "       [2.        , 2.08008382]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_distance_calculations(X_query, X_train, 'minkowski', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 2]\n",
      " [1 3]\n",
      " [1 0]\n",
      " [1 7]\n",
      " [1 5]]\n",
      "[ 1  0  2  2 10  3]\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(0)\n",
    "# x = np.linspace(-5, 5, 50)\n",
    "# noise = np.random.normal(0, 1.5, size=x.shape)\n",
    "# y = -1.5 * x + 10 + noise\n",
    "# x = x.reshape(-1,1)\n",
    "# print(x.shape)\n",
    "\n",
    "x = np.array([[1, 2, 3, 0, 7, 5]])\n",
    "y = np.array([1, 0, 2, 2, 10, 3])\n",
    "x = x.reshape(-1, 1)\n",
    "x = np.hstack([np.ones_like(x), x])\n",
    "# y = y.reshape(-1, 1)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.35344034  1.11782379]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng()\n",
    "training_array = x\n",
    "train_array = x\n",
    "train_targets = y\n",
    "epochs = 1000000\n",
    "learning_rate = 0.0001\n",
    "weights = np.zeros((2,))\n",
    "for iteration in range(epochs):\n",
    "    for entry in range(train_array.shape[0]):\n",
    "        error = np.matmul(train_array[entry], weights) - train_targets[entry]\n",
    "        weights -= learning_rate * (error) * (train_array[entry]).reshape(-1)\n",
    "\n",
    "# first_matrix = np.matmul(train_array.T, train_array)\n",
    "# second_matrix = np.matmul(train_array.T, train_targets)\n",
    "# theta = np.linalg.solve(first_matrix, second_matrix)\n",
    "\n",
    "# print(theta)\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02]] [-0.03]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "import numpy as np\n",
    "\n",
    "model = Perceptron(max_iter=1000, eta0=0.01, random_state=53)\n",
    "\n",
    "train_array = np.array([[0], [1], [2], [3], [4], [5], [6], [7]])\n",
    "train_targets = np.array([-1, -1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "model.fit(train_array,train_targets)\n",
    "\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "print(coefficients, intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Perceptron algorithms (NumPy)\n",
    "\n",
    "    This module implements the single-layer and multilayer perceptron \n",
    "\n",
    "    Functions\n",
    "    ---------\n",
    "    \n",
    "\n",
    "    Classes\n",
    "    ---------\n",
    "   \n",
    "\"\"\"\n",
    "\n",
    "# TODO: finish above!\n",
    "\n",
    "__all__ = [\n",
    "    'Perceptron',\n",
    "]\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import *\n",
    "import warnings\n",
    "from rice_ml.preprocess.datatype import *\n",
    "from rice_ml.preprocess.split import _random_number\n",
    "from rice_ml.supervised_learning.distances import _ensure_numeric\n",
    "\n",
    "ArrayLike = Union[np.ndarray, Sequence[float], Sequence[Sequence[float]], pd.DataFrame, pd.Series]\n",
    "\n",
    "\n",
    "def _validate_parameters(learning_rate: Optional[float],\n",
    "                         epochs: Optional[int],\n",
    "                         ) -> None:\n",
    "\n",
    "    # TODO: add docstrings, potentially add functionality for collecting/graphing error counts\n",
    "\n",
    "    if not isinstance(learning_rate, (int, float)):\n",
    "        raise TypeError('Learning rate must be a float')\n",
    "    if learning_rate <= 0:\n",
    "        warnings.warn(f\"For model to learn properly, learning rate should be greater than zero\", UserWarning)\n",
    "    if not isinstance(epochs, int):\n",
    "        raise TypeError('Maximum epochs must be a float')\n",
    "    if epochs <= 0:\n",
    "        raise ValueError('Maximum epochs must be greater than zero')\n",
    "    \n",
    "\n",
    "def _validate_arrays_perceptron(data_array: Optional[ArrayLike] = None,\n",
    "                              target_vector: Optional[ArrayLike] = None\n",
    "                              ) -> Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]:\n",
    "\n",
    "    # TODO: add docstrings\n",
    "\n",
    "    if data_array is not None:\n",
    "        array = _2D_numeric(data_array, 'data_array')\n",
    "\n",
    "        if np.isnan(array).any():\n",
    "            raise ValueError('Data array contains missing data (NaN values)')\n",
    "\n",
    "    if target_vector is not None:\n",
    "        target_vector = np.array(target_vector)\n",
    "        if target_vector.ndim == 2 and (target_vector.shape[1] == 1 or target_vector.shape[0] == 1):\n",
    "            vector = target_vector.reshape(-1)\n",
    "            vector = _1D_vectorized(vector, 'target_vector')\n",
    "        else:\n",
    "            vector = _1D_vectorized(target_vector, 'target_vector')\n",
    "        classes = np.unique(target_vector)\n",
    "        if len(classes) != 2:\n",
    "            raise ValueError(\"Logistic regression only supports binary targets\")\n",
    "        mapping = {classes[0]: -1, classes[1]: 1}\n",
    "        vector = (np.vectorize(mapping.get)(target_vector)).reshape(-1)\n",
    "        if np.isnan(vector).any():\n",
    "            raise ValueError('Target vector contains missing data (NaN values)')\n",
    "\n",
    "    if data_array is not None and target_vector is not None:\n",
    "        _shape_match(array, vector)\n",
    "        return array, vector\n",
    "    elif data_array is not None:\n",
    "        return array\n",
    "    elif target_vector is not None:\n",
    "        return vector\n",
    "    \n",
    "\n",
    "def _activation_function(z):\n",
    "    return np.where(z > 0, 1, -1)\n",
    "    \n",
    "\n",
    "class Perceptron_3():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 epochs: int = 1000,\n",
    "                 learning_rate: float = 0.01\n",
    "                 ) -> None:\n",
    "\n",
    "        _validate_parameters(learning_rate = learning_rate, epochs = epochs)\n",
    "        \n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.coef_: Optional[np.ndarray] = None\n",
    "        self.bias_: Optional[float] = None\n",
    "        self.class_mapping_: Optional[dict] = None\n",
    "    \n",
    "    def fit(self, training_array: np.ndarray, training_targets: np.ndarray, random_state: Optional[int] = None, shuffle: bool = True) -> 'logistic_regression':\n",
    "        \n",
    "        # TODO: docstrings/comments \n",
    "\n",
    "        if not isinstance(shuffle, bool):\n",
    "            raise TypeError('Shuffle must be a boolean')\n",
    "        \n",
    "        rng = _random_number(random_state)\n",
    "\n",
    "        train_array = _validate_arrays_perceptron(training_array)\n",
    "        \n",
    "        train_targets = _validate_arrays_perceptron(training_targets)\n",
    "        \n",
    "        classes = np.unique(training_targets)\n",
    "\n",
    "        self.class_mapping_ = {-1: classes[0], 1: classes[1]}\n",
    "        \n",
    "        train_array = np.hstack([np.ones((train_array.shape[0], 1)), train_array])\n",
    "        weights = rng.normal(loc=0, scale=0.01, size=train_array.shape[1]).reshape(-1)\n",
    "        \n",
    "        for iteration in range(self.epochs):\n",
    "            if shuffle:\n",
    "                indices = rng.permutation(train_array.shape[0])\n",
    "            else:\n",
    "                indices = np.arange(train_array.shape[0])\n",
    "            for entry in indices:\n",
    "                x = train_array[entry]\n",
    "                y = train_targets[entry]\n",
    "                learn_rate = self.learning_rate\n",
    "                y_hat = _activation_function(np.matmul(x, weights))\n",
    "                error = y_hat - y\n",
    "                weights -= learn_rate * error * x\n",
    "        \n",
    "        self.bias_ = weights[0]\n",
    "        self.coef_ = weights[1:]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _verify_fit(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        if self.coef_ is None:\n",
    "            raise RuntimeError(\"Model is not fitted; call fit(training_array, training_targets)\")\n",
    "\n",
    "        return self\n",
    "    \n",
    "\n",
    "    def prediction(self, testing_array: np.ndarray) -> np.ndarray:\n",
    "        \n",
    "        # TODO: doctrings/comments\n",
    "\n",
    "        self._verify_fit()\n",
    "\n",
    "        test_array = _validate_arrays_perceptron(testing_array)\n",
    "        \n",
    "        coef_array = _1D_vectorized(self.coef_) # TODO: fix this!\n",
    "\n",
    "        if test_array.shape[1] != len(coef_array):\n",
    "            raise ValueError('Test array must have the same number of input features as coefficients')\n",
    "        \n",
    "        bias = self.bias_\n",
    "        prediction_value = _activation_function(np.matmul(test_array, coef_array) + bias)\n",
    "\n",
    "        classification = np.array([self.class_mapping_[int(prediction)] for prediction in prediction_value])\n",
    "\n",
    "        return classification\n",
    "    \n",
    "    def score(self, testing_array: ArrayLike, actual_targets: ArrayLike) -> np.ndarray:\n",
    "\n",
    "        # TODO: be consistent w/ arraylike vs np.ndarray\n",
    "\n",
    "        predicted_target_array = self.prediction(testing_array)\n",
    "        actual_target_array = _1D_vectorized(actual_targets)\n",
    "\n",
    "        if predicted_target_array.shape != actual_target_array.shape:\n",
    "            raise ValueError(\"Shapes of predicted and actual targets must match\")\n",
    "        \n",
    "        accuracy = np.mean(predicted_target_array == actual_target_array)\n",
    "\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[193], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# Target labels for OR (converted to -1, 1)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize Perceptron\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m perceptron \u001b[38;5;241m=\u001b[39m \u001b[43mPerceptron\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Train the perceptron\u001b[39;00m\n\u001b[1;32m      8\u001b[0m perceptron\u001b[38;5;241m.\u001b[39mfit(X, y)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'epochs'"
     ]
    }
   ],
   "source": [
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Features\n",
    "y = np.array([-1, 1, 1, 1])  # Target labels for OR (converted to -1, 1)\n",
    "\n",
    "# Initialize Perceptron\n",
    "perceptron = Perceptron(epochs=1000, learning_rate=0.01)\n",
    "\n",
    "# Train the perceptron\n",
    "perceptron.fit(X, y)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = perceptron.scoring(X, y)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Test predictions\n",
    "predictions = perceptron.prediction(X)\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Perceptron Accuracy: 100.00%\n",
      "Scikit-learn Perceptron Accuracy: 100.00%\n",
      "Custom Perceptron Predictions: [ 1 -1  1  1  1 -1  1  1  1  1  1 -1 -1 -1 -1  1  1  1  1  1 -1  1 -1  1\n",
      "  1  1  1  1 -1 -1 -1 -1  1 -1 -1  1  1 -1 -1 -1  1  1  1 -1 -1]\n",
      "Scikit-learn Predictions: [ 1 -1  1  1  1 -1  1  1  1  1  1 -1 -1 -1 -1  1  1  1  1  1 -1  1 -1  1\n",
      "  1  1  1  1 -1 -1 -1 -1  1 -1 -1  1  1 -1 -1 -1  1  1  1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron as SklearnPerceptron\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Convert to binary classification (e.g., setosa vs. non-setosa)\n",
    "y = np.where(y == 0, -1, 1)  # Only two classes: -1 (setosa) and 1 (non-setosa)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the custom perceptron\n",
    "perceptron = Perceptron_3(epochs=1000, learning_rate=0.01)\n",
    "perceptron.fit(X_train, y_train, shuffle = True)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = perceptron.score(X_test, y_test)\n",
    "print(f\"Custom Perceptron Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Compare with sklearn's Perceptron\n",
    "sklearn_perceptron = SklearnPerceptron(max_iter=1000, eta0=0.01)\n",
    "sklearn_perceptron.fit(X_train, y_train)\n",
    "sklearn_accuracy = sklearn_perceptron.score(X_test, y_test)\n",
    "print(f\"Scikit-learn Perceptron Accuracy: {sklearn_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Test predictions\n",
    "custom_predictions = perceptron.prediction(X_test)\n",
    "sklearn_predictions = sklearn_perceptron.predict(X_test)\n",
    "print(\"Custom Perceptron Predictions:\", custom_predictions)\n",
    "print(\"Scikit-learn Predictions:\", sklearn_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01171374]\n"
     ]
    }
   ],
   "source": [
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, epochs: int = 1000, learning_rate: float = 0.01) -> None:\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.coef_ = None  # Weights for the features\n",
    "        self.bias_ = 0  # Bias term\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> 'Perceptron':\n",
    "        \"\"\"\n",
    "        Train the perceptron using the provided training data.\n",
    "        \"\"\"\n",
    "        # Ensure the data is two-dimensional (n_samples, n_features)\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1, 1)  # Reshape to ensure it's 2D (if it's 1D)\n",
    "\n",
    "        # Initialize weights (coef) randomly small\n",
    "        self.coef_ = np.random.randn(X.shape[1]) * 0.01  # Small random weights\n",
    "        \n",
    "        # Iterating through all the epochs and data points\n",
    "        for epoch in range(self.epochs):\n",
    "            # Track the number of misclassifications in this epoch\n",
    "            errors = 0\n",
    "            for i in range(X.shape[0]):\n",
    "                # Compute the net input (weighted sum + bias)\n",
    "                net_input = np.dot(X[i], self.coef_) + self.bias_\n",
    "                \n",
    "                # Apply activation function: step function\n",
    "                y_hat = 1 if net_input > 0 else -1\n",
    "                \n",
    "                # If the prediction is wrong, update weights and bias\n",
    "                if y_hat != y[i]:\n",
    "                    # Update rule: weights += learning_rate * error * input\n",
    "                    self.coef_ += self.learning_rate * (y[i] - y_hat) * X[i]\n",
    "                    self.bias_ += self.learning_rate * (y[i] - y_hat)\n",
    "                    errors += 1\n",
    "            # Early stopping: If there are no errors in the epoch, stop training\n",
    "            if errors == 0:\n",
    "                break\n",
    "        return self\n",
    "    \n",
    "train_array = np.array([[0], [1], [2], [3], [4], [5], [6], [7]])\n",
    "train_targets = np.array([-1, -1, 1, 1, 1, 1, 1, 1])\n",
    "perceptron1 = Perceptron(epochs = 100_000, learning_rate = 0.01)\n",
    "perceptron1.fit(train_array, train_targets)\n",
    "print(perceptron1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron_2(object):\n",
    "    def __init__(self, eta = .5, epochs=50):\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        self.w_ = np.random.rand(1 + X.shape[1])\n",
    "        print(self.w_)\n",
    "        self.errors_ = []\n",
    "        \n",
    "        for _ in range(self.epochs):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (self.predict(xi) - target)\n",
    "                self.w_[:-1] -= update*xi\n",
    "                self.w_[-1] -= update\n",
    "                errors += int(update != 0)\n",
    "            if errors == 0:\n",
    "                return self\n",
    "            else:\n",
    "                self.errors_.append(errors)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_[:-1]) + self.w_[-1]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: 1}"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = dict()\n",
    "delta[5] = 1\n",
    "\n",
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.56132929 -2.0017013 ]\n",
      "-2.4229866167677963\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/RandyRDavila/Data_Science_and_Machine_Learning_Spring_2022/main/Lecture_3/Datasets/iris_dataset.csv\")\n",
    "# Store the desired species values in the numpy array y\n",
    "y = df.iloc[0:100].species.values\n",
    "\n",
    "# Convert each entry of y with setosa to -1 and otherwise 1\n",
    "y = np.where(y == 'setosa', -1, 1)\n",
    "\n",
    "# Store the desired feature measurements in the matrix X\n",
    "X = df[[\"sepal_length\", \"sepal_width\"]].iloc[:100].values\n",
    "\n",
    "# Instantiate one instance of the Perceptron class\n",
    "clf = Perceptron(epochs = 100_000)\n",
    "\n",
    "# Call the train method to train the weights and bias of the given instance\n",
    "clf.fit(X, y, shuffle = False)\n",
    "print(clf.coef_)\n",
    "print(clf.bias_)\n",
    "\n",
    "y_hat = clf.prediction(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compare y_hat and y\n",
    "print(y == y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt \n",
    "# from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "# plt.figure(figsize = (10, 8))\n",
    "# plot_decision_regions(X, y, clf = clf)\n",
    "# plt.title(\"My First Perceptron\", fontsize = 18)\n",
    "# plt.xlabel(\"sepal length [cm]\", fontsize = 15)\n",
    "# plt.ylabel(\"petal length [cm]\", fontsize = 15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97400644 0.87372018 0.93023528]\n",
      "[  80.27400644 -101.42627982 -128.06976472]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n",
      "[  80.27400644 -101.42627982 -128.06976472]\n"
     ]
    }
   ],
   "source": [
    "# Store the desired species values in the numpy array y\n",
    "y = df.iloc[0:100].species.values\n",
    "\n",
    "# Convert each entry of y with setosa to -1 and otherwise 1\n",
    "y = np.where(y == 'setosa', -1, 1)\n",
    "\n",
    "# Store the desired feature measurements in the matrix X\n",
    "X = df[[\"sepal_length\", \"sepal_width\"]].iloc[:100].values\n",
    "\n",
    "# Instantiate one instance of the Perceptron class\n",
    "clf_2 = Perceptron_2(epochs = 100_000)\n",
    "\n",
    "# Call the train method to train the weights and bias of the given instance\n",
    "clf_2.train(X, y)\n",
    "print(clf_2.w_)\n",
    "\n",
    "y_hat = clf_2.predict(X)\n",
    "\n",
    "# Compare y_hat and y\n",
    "print(y == y_hat)\n",
    "print(clf_2.w_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.22  -0.369]] [-0.05]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "import numpy as np\n",
    "\n",
    "# Store the desired species values in the numpy array y\n",
    "y = df.iloc[0:100].species.values\n",
    "\n",
    "# Convert each entry of y with setosa to -1 and otherwise 1\n",
    "y = np.where(y == 'setosa', -1, 1)\n",
    "\n",
    "# Store the desired feature measurements in the matrix X\n",
    "X = df[[\"sepal_length\", \"sepal_width\"]].iloc[:100].values\n",
    "\n",
    "# Instantiate one instance of the Perceptron class\n",
    "model = Perceptron(max_iter=1000, eta0=0.01)\n",
    "\n",
    "# Call the train method to train the weights and bias of the given instance\n",
    "model.fit(X, y)\n",
    "\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "print(coefficients, intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "plt.figure(figsize = (10, 8))\n",
    "plot_decision_regions(X, y, clf = clf)\n",
    "plt.title(\"My First Perceptron\", fontsize = 18)\n",
    "plt.xlabel(\"sepal length [cm]\", fontsize = 15)\n",
    "plt.ylabel(\"petal length [cm]\", fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.35344034],\n",
       "       [ 1.11782379]])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.35344034  1.11782379]\n"
     ]
    }
   ],
   "source": [
    "print(weights.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.35294118],\n",
       "       [ 1.11764706]])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.zeros((2,1))  # including bias as first column\n",
    "learning_rate = 0.01\n",
    "for epoch in range(10000):\n",
    "    y_pred = x @ weights\n",
    "    error = y_pred - y\n",
    "    weights -= learning_rate * (x.T @ error) / len(y)\n",
    "    # for i in range(x.shape[0]):\n",
    "    #     xi = x[i].reshape(1, -1)   # shape (1,2)\n",
    "    #     yi = y[i]                   # scalar\n",
    "    #     y_pred = xi @ weights       # predicted value\n",
    "    #     error = y_pred - yi  \n",
    "    #     weights -= learning_rate * xi.T * error\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Perceptron algorithms (NumPy)\n",
    "\n",
    "    This module implements the single-layer and multilayer perceptron \n",
    "\n",
    "    Functions\n",
    "    ---------\n",
    "    \n",
    "\n",
    "    Classes\n",
    "    ---------\n",
    "   \n",
    "\"\"\"\n",
    "\n",
    "# TODO: finish above!\n",
    "\n",
    "__all__ = [\n",
    "    'Perceptron',\n",
    "]\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import *\n",
    "import warnings\n",
    "from rice_ml.preprocess.datatype import *\n",
    "from rice_ml.preprocess.split import _random_number\n",
    "from rice_ml.supervised_learning.distances import _ensure_numeric\n",
    "\n",
    "ArrayLike = Union[np.ndarray, Sequence[float], Sequence[Sequence[float]], pd.DataFrame, pd.Series]\n",
    "\n",
    "\n",
    "def _validate_parameters(learning_rate: Optional[float],\n",
    "                         epochs: Optional[int],\n",
    "                         ) -> None:\n",
    "\n",
    "    # TODO: add docstrings, potentially add functionality for collecting/graphing error counts\n",
    "\n",
    "    if not isinstance(learning_rate, (int, float)):\n",
    "        raise TypeError('Learning rate must be a float')\n",
    "    if learning_rate <= 0:\n",
    "        warnings.warn(f\"For model to learn properly, learning rate should be greater than zero\", UserWarning)\n",
    "    if not isinstance(epochs, int):\n",
    "        raise TypeError('Maximum epochs must be a float')\n",
    "    if epochs <= 0:\n",
    "        raise ValueError('Maximum epochs must be greater than zero')\n",
    "    \n",
    "\n",
    "def _validate_arrays_perceptron(data_array: Optional[ArrayLike] = None,\n",
    "                              target_vector: Optional[ArrayLike] = None\n",
    "                              ) -> Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]:\n",
    "\n",
    "    # TODO: add docstrings\n",
    "\n",
    "    if data_array is not None:\n",
    "        array = _2D_numeric(data_array, 'data_array')\n",
    "\n",
    "        if np.isnan(array).any():\n",
    "            raise ValueError('Data array contains missing data (NaN values)')\n",
    "\n",
    "    if target_vector is not None:\n",
    "        target_vector = np.array(target_vector)\n",
    "        if target_vector.ndim == 2 and (target_vector.shape[1] == 1 or target_vector.shape[0] == 1):\n",
    "            vector = target_vector.reshape(-1)\n",
    "            vector = _1D_vectorized(vector, 'target_vector')\n",
    "        else:\n",
    "            vector = _1D_vectorized(target_vector, 'target_vector')\n",
    "        if np.isnan(vector).any():\n",
    "            raise ValueError('Target vector contains missing data (NaN values)')\n",
    "\n",
    "    if data_array is not None and target_vector is not None:\n",
    "        _shape_match(array, vector)\n",
    "        return array, vector\n",
    "    elif data_array is not None:\n",
    "        return array\n",
    "    elif target_vector is not None:\n",
    "        return vector\n",
    "\n",
    "\n",
    "def _sigmoid(z):\n",
    "    \n",
    "    # TODO: add unit tests?\n",
    "\n",
    "    return 1.0/(1.0 + np.exp(-z))\n",
    "\n",
    "def derivative_sigmoid(z):\n",
    "    return _sigmoid(z) * (1.0 - _sigmoid(z))\n",
    "    \n",
    "\n",
    "class multilayer_Perceptron():\n",
    "\n",
    "    def __init__(self,\n",
    "                  layers: ArrayLike,\n",
    "                  epochs: int = 1000,\n",
    "                  learning_rate: float = 0.01\n",
    "                 ) -> None:\n",
    "\n",
    "        _validate_parameters(learning_rate = learning_rate, epochs = epochs)\n",
    "        \n",
    "        layer_array = _ensure_numeric(layers)\n",
    "\n",
    "        self.layers = layers\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.coef_: Optional[list] = None\n",
    "        self.bias_: Optional[list] = None\n",
    "        self.class_mapping_: Optional[dict] = None\n",
    "\n",
    "    def _weight_initialization(self, random_state: Optional[int] = None) -> Tuple[list, list]:\n",
    "        layers = self.layers\n",
    "        weights = []\n",
    "        bias = []\n",
    "        rng = _random_number(random_state)\n",
    "        for i in range(1, len(layers)):\n",
    "            layer_weight = rng.standard_normal((layers[i - 1], layers[i]))\n",
    "            layer_bias = np.zeros(layers[i]) # rng.standard_normal\n",
    "            weights.append(layer_weight)\n",
    "            bias.append(layer_bias)\n",
    "        \n",
    "        return weights, bias\n",
    "    \n",
    "    def _forward_layer(self, training_array: np.ndarray, weights: list, bias: list) -> Tuple[list, list]:\n",
    "        \n",
    "        train_array = _validate_arrays_perceptron(training_array)\n",
    "\n",
    "        z = []\n",
    "        a = [train_array]\n",
    "        for i in range(len(weights)):\n",
    "            z_layer = np.matmul(a[-1], weights[i]) + bias[i]\n",
    "            z.append(z_layer)\n",
    "            a_layer = _sigmoid(z_layer)\n",
    "            a.append(a_layer)\n",
    "            \n",
    "        return z, a\n",
    "\n",
    "    def _back_propagation(self, z: list, a: list, weights: list, training_targets: np.ndarray) -> Tuple[list, list]:\n",
    "\n",
    "        train_targets = _validate_arrays_perceptron(training_targets) # TODO: account for multiple classes!\n",
    "        \n",
    "        L = len(self.layers) - 1\n",
    "        learning_rate = self.learning_rate\n",
    "        delta = dict()\n",
    "        delta[L] = (a[-1] - train_targets) * derivative_sigmoid(z[-1])\n",
    "        d_weights = []\n",
    "        d_bias = []\n",
    "\n",
    "        for i in range(L - 1, 0, -1):\n",
    "            delta[i] = (np.matmul(delta[i + 1], weights[i].T)) * derivative_sigmoid(z[i - 1])\n",
    "    \n",
    "        for j in range(1, L + 1):\n",
    "            d_weights_layer = learning_rate * np.matmul(a[j - 1].T, delta[j])\n",
    "            d_bias_layer = learning_rate * np.mean(delta[j], axis = 0)\n",
    "            d_weights.append(d_weights_layer)\n",
    "            d_bias.append(d_bias_layer)\n",
    "\n",
    "        return d_weights, d_bias\n",
    "\n",
    "    def _weight_update(self, weights: list, bias: list, d_weights: list, d_bias: list) -> Tuple[list, list]:\n",
    "        \n",
    "        for i in range(len(weights)):\n",
    "                weights[i] -= d_weights[i]\n",
    "                bias[i] -= d_bias[i]\n",
    "\n",
    "        return weights, bias\n",
    "\n",
    "    def fit(self, training_array: np.ndarray, training_targets: np.ndarray, random_state: Optional[int] = None) -> 'multilayer_Perceptron':\n",
    "        \n",
    "        train_array = _validate_arrays_perceptron(training_array)\n",
    "        train_targets = _validate_arrays_perceptron(training_targets)\n",
    "\n",
    "        weights, bias = self._weight_initialization(random_state = random_state)\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            z, a = self._forward_layer(train_array, weights, bias)\n",
    "            d_weights, d_bias = self._back_propagation(z, a, weights, train_targets)\n",
    "            weights, bias = self._weight_update(weights, bias, d_weights, d_bias)\n",
    "\n",
    "        self.coef_ = weights\n",
    "        self.bias_ = bias\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def _verify_fit(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        if self.coef_ is None or self.bias_ is None:\n",
    "            raise RuntimeError(\"Model is not fitted; call fit(training_array, training_targets)\")\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, testing_array: np.ndarray):\n",
    "        \n",
    "        # TODO: doctrings/comments\n",
    "\n",
    "        self._verify_fit()\n",
    "\n",
    "        test_array = _validate_arrays_perceptron(testing_array)\n",
    "        \n",
    "        coef_array = self.coef_\n",
    "        # coef_array = _1D_vectorized(self.coef_) # TODO: fix this!\n",
    "\n",
    "        if test_array.shape[1] != self.coef_[0].shape[0]:\n",
    "            raise ValueError('Test array must have the same number of input features as coefficients')\n",
    "        \n",
    "        bias = self.bias_\n",
    "\n",
    "        z, a = self._forward_layer(testing_array, self.coef_, self.bias_)\n",
    "\n",
    "        prediction = a[-1]\n",
    "\n",
    "        predicted_labels = np.where(prediction > 0.5, 1, 0)\n",
    "\n",
    "        return prediction, predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weights = list of length L - 1 (L is number of layers, L - 1 is number of layers not including output) - indexed from 0 to L - 2\n",
    "- each entry in weights: array of dimension (number of neurons in next layer x number of neurons in past layer)\n",
    "biases = list of length L - 1\n",
    "- each entry in biases: vector of dimension (number of neurons in next layer x 1)\n",
    "activation = list of length L (with first entry just the train array, so L - 1 meaningful entries)\n",
    "- each entry in activation: array of dimension (number of samples, number of neurons in layer before one being calculated for)\n",
    "z = list of length L - 1\n",
    "- each entry in z: array of dimension (number of samples, number of neurons in layer being calculated for (off by 1 index from activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.99132972e-01 8.76348496e-04]\n",
      " [9.38306166e-01 6.33514452e-02]\n",
      " [9.36380644e-01 6.23814358e-02]\n",
      " [1.26031855e-01 8.73582736e-01]]\n",
      "[[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1],\n",
    "])\n",
    "X_test = X_train.copy() # Use the same inputs for testing\n",
    "\n",
    "Y_train = np.array([\n",
    "    [1, 0],  # Input (0, 0) -> Class 0\n",
    "    [1, 0],  # Input (0, 1) -> Class 0\n",
    "    [1, 0],  # Input (1, 0) -> Class 0\n",
    "    [0, 1],  # Input (1, 1) -> Class 1\n",
    "])\n",
    "# Model setup\n",
    "# Layers: [2 Input, 2 Hidden, 1 Output] - The same architecture is fine.\n",
    "model = multilayer_Perceptron(layers=[2, 2, 2], epochs=5000, learning_rate=0.1) \n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "prediction, predictions = model.predict(X_test)\n",
    "\n",
    "print(prediction)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-1.1244749 , -1.11475602],\n",
      "       [-0.15569741,  0.0827548 ],\n",
      "       [ 0.73760329, -0.093025  ]]), array([[-0.57136956,  0.72300382],\n",
      "       [-1.31929255,  0.63363937]]), array([[ 0.50434387],\n",
      "       [-0.40621188]])] [array([-0.50024246,  0.0590798 ]), array([ 1.1589291, -1.6235606]), array([-1.10884683])]\n",
      "[array([[-1.1244749 , -1.11475602],\n",
      "       [-0.15569741,  0.0827548 ],\n",
      "       [ 0.73760329, -0.093025  ]]), array([[-0.57136956,  0.72300382],\n",
      "       [-1.31929255,  0.63363937]]), array([[ 0.50434387],\n",
      "       [-0.40621188]])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.multilayer_Perceptron at 0x1537d4520>"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [3, 2, 2, 1]\n",
    "\n",
    "# Create an MLP instance\n",
    "mlp = multilayer_Perceptron(layers, learning_rate=0.1, epochs=1000)\n",
    "\n",
    "# Toy dataset (X: 4 samples, 2 features; y: binary target)\n",
    "X = np.array([[0, 0, 0],\n",
    "              [0, 1, 0],\n",
    "              [1, 0, 1],\n",
    "              [1, 1, 1]])\n",
    "\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]])\n",
    "\n",
    "# Fit the model to the data\n",
    "mlp.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.33333333 2.33333333]\n",
      " [2.33333333 2.33333333]]\n",
      "[[2.33333333 2.33333333]\n",
      " [2.33333333 2.33333333]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EighResult(eigenvalues=array([0.        , 4.66666667]), eigenvectors=array([[-0.70710678,  0.70710678],\n",
       "       [ 0.70710678,  0.70710678]]))"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array = np.array([\n",
    "    [1, 2],\n",
    "    [2, 3],\n",
    "    [4, 5]\n",
    "])\n",
    "\n",
    "observation_number = data_array.shape[0]\n",
    "means = np.mean(data_array, axis = 0)\n",
    "\n",
    "covariance_matrix = np.dot((data_array - means).T, (data_array - means)) / (observation_number - 1)\n",
    "print(covariance_matrix)\n",
    "cov_numpy = np.cov(data_array, rowvar=False)\n",
    "print(cov_numpy)\n",
    "\n",
    "np.linalg.eigh(covariance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def z_score_standardize(data_array: ArrayLike, return_params: bool = False, ddof: int = 0) -> Union[np.ndarray, Tuple[np.ndarray, dict]]:\n",
    "    \n",
    "    # TODO: add type hints/docstrings/examples\n",
    "\n",
    "    array = _2D_numeric(data_array)\n",
    "\n",
    "    if not isinstance(ddof, int):\n",
    "        raise TypeError(f\"ddof parameter must be an integer, got {type(ddof).__name__}\")\n",
    "    \n",
    "    if not isinstance(return_params, bool):\n",
    "        raise TypeError(f\"return_params must be a boolean, got {type(return_params).__name__}\")\n",
    "    \n",
    "    if ddof < 0:\n",
    "        raise ValueError(f\"ddof parameter must be greater than or equal to zero\")\n",
    "\n",
    "    columnwise_mean = array.mean(axis = 0)\n",
    "    scale = array.std(axis = 0, ddof = ddof)\n",
    "    scale[scale == 0.0] = 1.0\n",
    "    standardized_array = (array - columnwise_mean) / scale\n",
    "\n",
    "    if return_params:\n",
    "        return standardized_array, {'mean': columnwise_mean, 'scale': scale}\n",
    "\n",
    "    return standardized_array\n",
    "\n",
    "\n",
    "class pca():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 n_components: int) -> None:\n",
    "        \n",
    "        if not isinstance(n_components, int):\n",
    "            raise TypeError('Number of retained components must be an integer')\n",
    "        if n_components <= 0:\n",
    "            raise ValueError('Number of retained components must be greater than zero')\n",
    "\n",
    "        self.n_components = n_components\n",
    "        self.components: Optional[np.ndarray] = None\n",
    "        self.eigenvalues: Optional[np.ndarray] = None\n",
    "        self.variance: Optional[np.ndarray] = None\n",
    "\n",
    "        # TODO: add a check here that n_components does not exceed number of features\n",
    "    \n",
    "    def fit(self, data_input_array: ArrayLike) -> np.ndarray:\n",
    "\n",
    "        data_array = z_score_standardize(data_input_array)\n",
    "\n",
    "        if self.n_components > data_array.shape[1]:\n",
    "            raise ValueError('Number of retained components cannot exceed number of features')\n",
    "\n",
    "        observation_number = data_array.shape[0]\n",
    "        means = np.mean(data_array, axis = 0)\n",
    "\n",
    "        covariance_matrix = np.dot((data_array - means).T, (data_array - means)) / (observation_number - 1)\n",
    "\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "\n",
    "        sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "        sorted_eigenvalues = eigenvalues[sorted_indices]\n",
    "        sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "        self.eigenvalues = sorted_eigenvalues[:self.n_components]\n",
    "        self.variance = sorted_eigenvalues[:self.n_components]/(np.sum(eigenvalues))\n",
    "        self.components = sorted_eigenvectors[:, :self.n_components]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _verify_fit(self) -> 'pca':\n",
    "        if self.components is None or self.variance is None:\n",
    "            raise RuntimeError(\"Model is not fitted; call fit(data_input_array)\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_input_array: ArrayLike) -> np.ndarray:\n",
    "\n",
    "        self._verify_fit()\n",
    "        data_array = z_score_standardize(data_input_array)\n",
    "        transformed_data = np.dot(data_array, self.components)\n",
    "\n",
    "        return transformed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.67397595 -0.25169344]\n",
      " [-0.68991106 -0.12173674]\n",
      " [-0.26415742  0.96012009]]\n",
      "[0.67185508 0.31058257]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.07448672, -1.67301084],\n",
       "       [ 2.45265516,  0.78952027],\n",
       "       [-0.89213185,  0.64291825],\n",
       "       [ 0.2954202 , -0.50985255],\n",
       "       [-1.78145679,  0.75042487]])"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [2.5, 2.4, 0.5],\n",
    "    [0.5, 0.7, 2.2],\n",
    "    [2.2, 2.9, 2.9],\n",
    "    [1.9, 2.2, 1.5],\n",
    "    [3.1, 3.0, 3.3]\n",
    "])\n",
    "\n",
    "pca_new = pca(n_components = 2)\n",
    "\n",
    "pca_new.fit(X)\n",
    "print(pca_new.components)\n",
    "print(pca_new.variance)\n",
    "\n",
    "pca_new.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _validate_parameters(max_depth: Optional[int], min_samples_split: Optional[int]) -> None:\n",
    "\n",
    "    # TODO: type hints, docstrings\n",
    "\n",
    "    if max_depth is not None and not isinstance(max_depth, int):\n",
    "        raise TypeError('Maximum depth must be an integer')\n",
    "    if max_depth is not None and max_depth <= 0:\n",
    "        raise ValueError('Maximum depth must be greater than zero')\n",
    "    if not isinstance(min_samples_split, int):\n",
    "        raise TypeError('Minimum samples required to split node must be an integer')\n",
    "    if min_samples_split <= 0:\n",
    "        raise TypeError('Minimum samples required to split node must be greater than zero')\n",
    "    \n",
    "def _validate_parameters_node(feature_index: Optional[int], \n",
    "                              threshold_value: Optional[float], \n",
    "                              left: Optional[\"Node\"] = None, \n",
    "                              right: Optional[\"Node\"] = None) -> None:\n",
    "\n",
    "    # TODO: type hints, docstrings\n",
    "\n",
    "    if feature_index is not None and not isinstance(feature_index, int):\n",
    "        raise TypeError('Feature index must be an integer')\n",
    "    if feature_index is not None and feature_index < 0:\n",
    "        raise ValueError('Feature index must be greater than or equal to zero')\n",
    "    if threshold_value is not None and not isinstance(threshold_value, (float, int)):\n",
    "        raise TypeError('Threshold value must be a float')\n",
    "    if left is not None and not isinstance(left, Node):\n",
    "        raise TypeError('Left node must be an instance of the Node class')\n",
    "    if right is not None and not isinstance(right, Node):\n",
    "        raise TypeError('Right node must be an instance of the Node class')\n",
    "\n",
    "def _entropy(train_targets: np.ndarray):\n",
    "\n",
    "    train_targets = _1D_vectorized(train_targets)\n",
    "\n",
    "    _, counts = np.unique(train_targets, return_counts = True)\n",
    "    probabilities = counts / np.sum(counts)\n",
    "    probabilities_filtered = probabilities[probabilities > 0]\n",
    "    entropy = -np.sum(probabilities_filtered * np.log2(probabilities_filtered))\n",
    "\n",
    "    return entropy\n",
    "\n",
    "\n",
    "class Node():\n",
    "\n",
    "    def __init__(self,\n",
    "                 feature_index: Optional[int] = None,\n",
    "                 threshold_value: Optional[float] = None,\n",
    "                 left: \"Node\" = None,\n",
    "                 right: \"Node\" = None,\n",
    "                 value: Optional[Any] = None) -> None:\n",
    "        \n",
    "        _validate_parameters_node(feature_index, threshold_value, left, right)\n",
    "\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold_value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value: Optional[Any] = value\n",
    "\n",
    "    def is_leaf(self) -> bool:\n",
    "        return self.value is not None\n",
    "\n",
    "class decision_tree():\n",
    "\n",
    "    def __init__(self,\n",
    "                 max_depth: Optional[int] = None,\n",
    "                 min_samples_split: Optional[int] = 2) -> None:\n",
    "        \n",
    "        _validate_parameters(max_depth, min_samples_split)\n",
    "\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree: Optional[Node] = None\n",
    "        self._class_mappings: Optional[dict] = None\n",
    "        self._reverse_class_mappings: Optional[dict] = None\n",
    "        self._n_features: Optional[int] = None\n",
    "\n",
    "    def _information_gain(self,\n",
    "                          parent_class: np.ndarray,\n",
    "                          left_class: np.ndarray,\n",
    "                          right_class: np.ndarray) -> ...:\n",
    "        \n",
    "        parent_entropy = _entropy(parent_class)\n",
    "        left_entropy = _entropy(left_class)\n",
    "        right_entropy = _entropy(right_class)\n",
    "\n",
    "        if len(parent_class) != len(left_class) + len(right_class):\n",
    "            raise ValueError('Summed number of split samples must equal total number of samples')\n",
    "        \n",
    "        left_weight = len(left_class) / len(parent_class)\n",
    "        right_weight = len(right_class) / len(parent_class)\n",
    "\n",
    "        final_gain = parent_entropy - (left_weight * left_entropy + right_weight * right_entropy)\n",
    "\n",
    "        return final_gain\n",
    "    \n",
    "    def _best_split(self,\n",
    "                    training_array: ArrayLike,\n",
    "                    training_targets: ArrayLike) -> ...:\n",
    "        \n",
    "        train_array = _2D_numeric(training_array)\n",
    "        train_targets = _1D_vectorized(training_targets)\n",
    "\n",
    "        _, n_features = train_array.shape\n",
    "\n",
    "        best_gain = -np.inf\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "\n",
    "        for feature in range(n_features):\n",
    "            possible_thresholds = np.unique(train_array[:, feature])\n",
    "            for threshold in possible_thresholds:\n",
    "                left_indices = train_array[:, feature] <= threshold\n",
    "                right_indices = train_array[:, feature] > threshold\n",
    "                \n",
    "                left_classes = train_targets[left_indices]\n",
    "                right_classes = train_targets[right_indices]\n",
    "\n",
    "                if len(left_classes) == 0 or len(right_classes) == 0:\n",
    "                    continue\n",
    "                \n",
    "                gain = self._information_gain(train_targets, left_classes, right_classes)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "        \n",
    "        return best_feature, best_threshold\n",
    "                \n",
    "    def _leaf_value(self, training_targets: np.ndarray) -> Union[int, float, str]:\n",
    "\n",
    "        train_targets = _1D_vectorized(training_targets)\n",
    "        classes, counts = np.unique(train_targets, return_counts = True)\n",
    "        classification = classes[np.argmax(counts)]\n",
    "\n",
    "        return classification\n",
    "    \n",
    "    def _build_tree(self, training_array: ArrayLike, training_targets: ArrayLike, depth: int) -> Node:\n",
    "\n",
    "        train_array = _2D_numeric(training_array)\n",
    "        train_targets = _1D_vectorized(training_targets)\n",
    "\n",
    "        n_samples, n_features = train_array.shape\n",
    "\n",
    "        if n_samples < self.min_samples_split:\n",
    "            return Node(value = self._leaf_value(train_targets))\n",
    "        if self.max_depth is not None and self.max_depth <= depth:\n",
    "            return Node(value = self._leaf_value(train_targets))\n",
    "        if len(np.unique(train_targets)) == 1:\n",
    "            return Node(value = self._leaf_value(train_targets))\n",
    "        \n",
    "        best_feature, best_threshold = self._best_split(train_array, train_targets)\n",
    "\n",
    "        left_indices = train_array[:, best_feature] <= best_threshold\n",
    "        right_indices = train_array[:, best_feature] > best_threshold\n",
    "        \n",
    "        left_classes = train_targets[left_indices]\n",
    "        right_classes = train_targets[right_indices]\n",
    "\n",
    "        left_child = self._build_tree(train_array[left_indices, :], left_classes, depth + 1)\n",
    "        right_child = self._build_tree(train_array[right_indices, :], right_classes, depth + 1)\n",
    "\n",
    "        return Node(feature_index = best_feature, threshold_value = best_threshold, left = left_child, right = right_child)\n",
    "    \n",
    "    def fit(self, training_array: ArrayLike, training_targets: ArrayLike) -> \"decision_tree\":\n",
    "        \n",
    "        unique_classes = list(dict.fromkeys(training_targets))\n",
    "        self._class_mappings = {cls: i for i, cls in enumerate(unique_classes)}\n",
    "\n",
    "        self._reverse_class_mappings = {\n",
    "                                    i: (cls.item() if isinstance(cls, np.generic) else cls)\n",
    "                                    for cls, i in self._class_mappings.items()\n",
    "                                }\n",
    "        \n",
    "        train_targets = np.array([self._class_mappings[item] for item in training_targets])\n",
    "        \n",
    "        train_array = _2D_numeric(training_array)\n",
    "        self._n_features = train_array.shape[1]\n",
    "\n",
    "        final_tree = self._build_tree(train_array, train_targets, 0)\n",
    "        self.tree = final_tree\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def _verify_fit(self) -> \"decision_tree\":\n",
    "        if self.tree is None:\n",
    "            raise RuntimeError(\"Model is not fitted; call fit(training_array, training_targets)\")\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, testing_array: ArrayLike) -> np.ndarray:\n",
    "\n",
    "        self._verify_fit()\n",
    "\n",
    "        test_array = _2D_numeric(testing_array)\n",
    "\n",
    "        if test_array.shape[1] != self._n_features:\n",
    "            raise ValueError(\"Number of features in testing data must match number of features in training data\")\n",
    "        \n",
    "        # TODO: add something to test that test_array has the same number of features\n",
    "\n",
    "        prediction_array = np.full((test_array.shape[0],), np.nan, dtype = object)\n",
    "        for sample in range(test_array.shape[0]):\n",
    "            prediction = self._predict_recursive(test_array[sample, :], self.tree)\n",
    "            prediction_array[sample] = prediction\n",
    "        \n",
    "        if any(value is np.nan or value is None for value in prediction_array):\n",
    "            raise ValueError(\"Predictions were not made for all samples\")\n",
    "        \n",
    "        predictions = np.array([self._reverse_class_mappings[p] for p in prediction_array], dtype=object)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "    def _predict_recursive(self, testing_row: np.ndarray, node: Node) -> Union[int, float, str]:\n",
    "        \n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        \n",
    "        if testing_row[node.feature_index] <= node.threshold:\n",
    "            return self._predict_recursive(testing_row, node.left)\n",
    "        else:\n",
    "            return self._predict_recursive(testing_row, node.right)\n",
    "    \n",
    "    def print_tree(self, node: Optional[Node] = None, depth: int = 0) -> None:\n",
    "        \n",
    "        if node is None:\n",
    "            self._verify_fit()\n",
    "            node = self.tree\n",
    "\n",
    "        if node.is_leaf():\n",
    "            print(\"\\t\" * depth + f\"Predict: {node.value}\")\n",
    "        else:\n",
    "            print(\"\\t\" * depth + f\"Feature {node.feature_index} <= {node.threshold}\")\n",
    "            self.print_tree(node.left, depth + 1)\n",
    "            self.print_tree(node.right, depth + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1]\n",
      "Feature 0 <= 0.0\n",
      "\tPredict: 0\n",
      "\tPredict: 1\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([\n",
    "    [0, 3, 0],  # Red, small, smooth\n",
    "    [0, 5, 1],  # Red, medium, rough\n",
    "    [1, 4, 0],  # Green, medium, smooth\n",
    "    [1, 6, 1],  # Green, large, rough\n",
    "    [2, 2, 0],  # Yellow, small, smooth\n",
    "    [2, 7, 1],  # Yellow, large, rough\n",
    "    [0, 4, 0],\n",
    "    [1, 5, 1],\n",
    "    [2, 3, 0],\n",
    "    [1, 7, 1]\n",
    "])\n",
    "\n",
    "# Target values: Edible=1, Not=0\n",
    "y_train = np.array([0, 0, 1, 1, 0, 1, 0, 1, 0, 1])\n",
    "\n",
    "X_test = np.array([\n",
    "    [0, 2, 0],  # Red, very small, smooth\n",
    "    [1, 6, 0],  # Green, large, smooth\n",
    "    [2, 5, 1],  # Yellow, medium-large, rough\n",
    "    [0, 6, 1],  # Red, large, rough\n",
    "    [1, 3, 0]   # Green, small, smooth\n",
    "])\n",
    "\n",
    "decision = decision_tree(max_depth = 1)\n",
    "\n",
    "decision.fit(X_train, y_train)\n",
    "\n",
    "predict = decision.predict(X_test)\n",
    "\n",
    "print(predict)\n",
    "\n",
    "decision.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class regression_tree():\n",
    "\n",
    "    def __init__(self,\n",
    "                 max_depth: Optional[int] = None,\n",
    "                 min_samples_split: Optional[int] = 2) -> None:\n",
    "        \n",
    "        _validate_parameters(max_depth, min_samples_split)\n",
    "\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree: Optional[Node] = None\n",
    "        self._n_features: Optional[int] = None\n",
    "\n",
    "    def _variance_reduction(self,\n",
    "                          parent_class: np.ndarray,\n",
    "                          left_class: np.ndarray,\n",
    "                          right_class: np.ndarray) -> float:\n",
    "        \n",
    "        parent_variance = np.var(parent_class)\n",
    "        left_variance = np.var(left_class)\n",
    "        right_variance = np.var(right_class)\n",
    "\n",
    "        if len(parent_class) != len(left_class) + len(right_class):\n",
    "            raise ValueError('Summed number of split samples must equal total number of samples')\n",
    "        \n",
    "        left_weight = len(left_class) / len(parent_class)\n",
    "        right_weight = len(right_class) / len(parent_class)\n",
    "\n",
    "        final_var_reduction = parent_variance - (left_weight * left_variance + right_weight * right_variance)\n",
    "\n",
    "        return final_var_reduction\n",
    "    \n",
    "    def _best_split(self,\n",
    "                    training_array: ArrayLike,\n",
    "                    training_targets: ArrayLike) -> Tuple[int, float]:\n",
    "        \n",
    "        train_array = _2D_numeric(training_array)\n",
    "        train_targets = _ensure_numeric(training_targets)\n",
    "\n",
    "        _, n_features = train_array.shape\n",
    "\n",
    "        best_var = -np.inf\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "\n",
    "        for feature in range(n_features):\n",
    "            feature_values = np.sort(np.unique(train_array[:, feature]))\n",
    "            possible_thresholds = (feature_values[:-1] + feature_values[1:]) / 2\n",
    "            for threshold in possible_thresholds:\n",
    "                left_indices = train_array[:, feature] <= threshold\n",
    "                right_indices = train_array[:, feature] > threshold\n",
    "                \n",
    "                left_classes = train_targets[left_indices]\n",
    "                right_classes = train_targets[right_indices]\n",
    "\n",
    "                if len(left_classes) == 0 or len(right_classes) == 0:\n",
    "                    continue\n",
    "                \n",
    "                var = self._variance_reduction(train_targets, left_classes, right_classes)\n",
    "\n",
    "                if var > best_var:\n",
    "                    best_var = var\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "        \n",
    "        return best_feature, best_threshold\n",
    "                \n",
    "    def _leaf_value(self, training_targets: np.ndarray) -> Union[int, float, str]:\n",
    "\n",
    "        train_targets = _ensure_numeric(training_targets)\n",
    "        regression = np.mean(train_targets)\n",
    "\n",
    "        return regression\n",
    "    \n",
    "    def _build_tree(self, training_array: ArrayLike, training_targets: ArrayLike, depth: int) -> Node:\n",
    "\n",
    "        train_array = _2D_numeric(training_array)\n",
    "        train_targets = _ensure_numeric(training_targets)\n",
    "\n",
    "        n_samples, n_features = train_array.shape\n",
    "\n",
    "        if n_samples < self.min_samples_split:\n",
    "            return Node(value = self._leaf_value(train_targets))\n",
    "        if self.max_depth is not None and self.max_depth <= depth:\n",
    "            return Node(value = self._leaf_value(train_targets))\n",
    "        if np.var(train_targets) == 0:\n",
    "            return Node(value = self._leaf_value(train_targets))\n",
    "        \n",
    "        best_feature, best_threshold = self._best_split(train_array, train_targets)\n",
    "\n",
    "        left_indices = train_array[:, best_feature] <= best_threshold\n",
    "        right_indices = train_array[:, best_feature] > best_threshold\n",
    "        \n",
    "        left_classes = train_targets[left_indices]\n",
    "        right_classes = train_targets[right_indices]\n",
    "\n",
    "        left_child = self._build_tree(train_array[left_indices, :], left_classes, depth + 1)\n",
    "        right_child = self._build_tree(train_array[right_indices, :], right_classes, depth + 1)\n",
    "\n",
    "        return Node(feature_index = best_feature, threshold_value = best_threshold, left = left_child, right = right_child)\n",
    "    \n",
    "    def fit(self, training_array: ArrayLike, training_targets: ArrayLike) -> \"regression_tree\":\n",
    "        \n",
    "        train_targets = _ensure_numeric(training_targets)\n",
    "        train_array = _2D_numeric(training_array)\n",
    "        self._n_features = train_array.shape[1]\n",
    "\n",
    "        final_tree = self._build_tree(train_array, train_targets, 0)\n",
    "        self.tree = final_tree\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def _verify_fit(self) -> \"regression_tree\":\n",
    "        if self.tree is None:\n",
    "            raise RuntimeError(\"Model is not fitted; call fit(training_array, training_targets)\")\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, testing_array: ArrayLike) -> np.ndarray:\n",
    "\n",
    "        self._verify_fit()\n",
    "\n",
    "        test_array = _2D_numeric(testing_array)\n",
    "\n",
    "        if test_array.shape[1] != self._n_features:\n",
    "            raise ValueError(\"Number of features in testing data must match number of features in training data\")\n",
    "\n",
    "        prediction_array = np.full((test_array.shape[0],), np.nan, dtype = float)\n",
    "        for sample in range(test_array.shape[0]):\n",
    "            prediction = self._predict_recursive(test_array[sample, :], self.tree)\n",
    "            prediction_array[sample] = prediction\n",
    "        \n",
    "        if any(value is np.nan or value is None for value in prediction_array):\n",
    "            raise ValueError(\"Predictions were not made for all samples\")\n",
    "        \n",
    "        return prediction_array\n",
    "\n",
    "    def _predict_recursive(self, testing_row: np.ndarray, node: Node) -> Union[int, float, str]:\n",
    "        \n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        \n",
    "        if testing_row[node.feature_index] <= node.threshold:\n",
    "            return self._predict_recursive(testing_row, node.left)\n",
    "        else:\n",
    "            return self._predict_recursive(testing_row, node.right)\n",
    "    \n",
    "    def print_tree(self, node: Optional[Node] = None, depth: int = 0) -> None:\n",
    "        \n",
    "        if node is None:\n",
    "            self._verify_fit()\n",
    "            node = self.tree\n",
    "\n",
    "        if node.is_leaf():\n",
    "            print(\"\\t\" * depth + f\"Predict: {node.value}\")\n",
    "        else:\n",
    "            print(\"\\t\" * depth + f\"Feature {node.feature_index} <= {node.threshold}\")\n",
    "            self.print_tree(node.left, depth + 1)\n",
    "            self.print_tree(node.right, depth + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _validate_parameters_rf(n_trees: int, \n",
    "                         task: Literal['classification', 'regression'], \n",
    "                         max_depth: Optional[int],\n",
    "                         min_samples_split: Optional[int],\n",
    "                         max_features: Optional[Union[int, float, Literal[\"sqrt\", \"log2\"]]],\n",
    "                         random_state: Optional[int]) -> None:\n",
    "    \n",
    "    # TODO: type hints, docstrings\n",
    "\n",
    "    if not isinstance(n_trees, int):\n",
    "        raise TypeError('Number of trees must be an integer')\n",
    "    if n_trees <= 0:\n",
    "        raise ValueError('Number of trees must be greater than zero')\n",
    "    if task not in ['classification', 'regression']:\n",
    "        raise ValueError(f\"Task type must be one of {['classification', 'regression']}\")\n",
    "    if max_depth is not None and not isinstance(max_depth, int):\n",
    "        raise TypeError('Maximum depth must be an integer')\n",
    "    if max_depth is not None and max_depth <= 0:\n",
    "        raise ValueError('Maximum depth must be greater than zero')\n",
    "    if min_samples_split is not None and not isinstance(min_samples_split, int):\n",
    "        raise TypeError('Minimum samples required to split node must be an integer')\n",
    "    if min_samples_split <= 0:\n",
    "        raise TypeError('Minimum samples required to split node must be greater than zero')\n",
    "    if max_features is not None:\n",
    "        if not isinstance(max_features, (int, float)) and max_features not in [\"sqrt\", \"log2\"]:\n",
    "            raise TypeError(f\"Maximum number of features must be an integer, float, or in {['sqrt', 'log2']}\")\n",
    "        if isinstance(max_features, (int, float)) and max_features <= 0:\n",
    "            raise ValueError(\"Maximum number of features must be greater than zero\")\n",
    "    if random_state is not None and not isinstance(random_state, int):\n",
    "        raise TypeError(\"Random state parameter must be an integer\")\n",
    "    \n",
    "class random_forest():\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_trees: int,\n",
    "                 task: Literal['classification', 'regression'],\n",
    "                 max_depth: Optional[int] = None,\n",
    "                 min_samples_split: Optional[int] = 2,\n",
    "                 max_features: Optional[Union[int, float, Literal[\"sqrt\", \"log2\"]]] = \"sqrt\",\n",
    "                 random_state: Optional[int] = None\n",
    "                 ) -> None:\n",
    "        \n",
    "        _validate_parameters_rf(n_trees, task, max_depth, min_samples_split, max_features, random_state)\n",
    "\n",
    "        self.n_trees = n_trees\n",
    "        self.task = task\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_features = max_features\n",
    "        self.random_state = random_state\n",
    "        self.trees: list = []\n",
    "        self.n_features_: Optional[int] = None\n",
    "\n",
    "    def _bootstrap_data(self, training_array: np.ndarray, training_targets: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "        n_samples = training_array.shape[0]\n",
    "        rng = _random_number(self.random_state)\n",
    "        index_choices = rng.choice(n_samples, size = n_samples, replace = True)\n",
    "        bootstrapped_train_array = training_array[index_choices]\n",
    "        bootstrapped_train_targets = training_targets[index_choices]\n",
    "\n",
    "        return bootstrapped_train_array, bootstrapped_train_targets\n",
    "    \n",
    "    def _feature_selection(self, total_features: int) -> np.ndarray:\n",
    "        \n",
    "        selection_type = self.max_features\n",
    "        \n",
    "        if selection_type is None:\n",
    "            return np.arange(total_features)\n",
    "        if isinstance(selection_type, int):\n",
    "            n_select = selection_type\n",
    "        elif isinstance(selection_type, float):\n",
    "            n_select = max(1, int(selection_type * total_features))\n",
    "        elif selection_type == 'sqrt':\n",
    "            n_select = max(1, int(np.sqrt(total_features)))\n",
    "        elif selection_type == 'log2':\n",
    "            n_select = max(1, int(np.log2(total_features)))\n",
    "        \n",
    "        rng = _random_number(self.random_state)\n",
    "\n",
    "        features = rng.choice(total_features, size = n_select, replace = False)\n",
    "\n",
    "        return features\n",
    "\n",
    "    def fit(self, training_array: ArrayLike, training_targets: ArrayLike) -> 'random_forest':\n",
    "        \n",
    "        # TODO: type hints/docstrings\n",
    "\n",
    "        train_array = _2D_numeric(training_array)\n",
    "        train_targets = _1D_vectorized(training_targets)\n",
    "\n",
    "        self.n_features_ = train_array.shape[1]\n",
    "\n",
    "        for _ in range(self.n_trees):\n",
    "            sampled_train_array, sampled_train_targets = self._bootstrap_data(train_array, train_targets)\n",
    "            features = self._feature_selection(self.n_features_)\n",
    "            subset_train_array = sampled_train_array[:, features]\n",
    "\n",
    "            if self.task == 'classification':\n",
    "                tree = decision_tree(self.max_depth, self.min_samples_split)\n",
    "            elif self.task == 'regression':\n",
    "                tree = regression_tree(self.max_depth, self.min_samples_split)\n",
    "\n",
    "            tree.fit(subset_train_array, sampled_train_targets)\n",
    "\n",
    "            self.trees.append((tree, features))\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def _verify_fit(self) -> \"random_forest\":\n",
    "        if len(self.trees) == 0:\n",
    "            raise RuntimeError(\"Model is not fitted; call fit(training_array, training_targets)\")\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def prediction(self, testing_array: ArrayLike) -> np.ndarray:\n",
    "\n",
    "        # TODO: type hints, docstrings\n",
    "\n",
    "        self._verify_fit()\n",
    "\n",
    "        test_array = _2D_numeric(testing_array)\n",
    "        if test_array.shape[1] != self.n_features_:\n",
    "            raise ValueError(\"Number of features in testing data must match number of features in training data\")\n",
    "\n",
    "        predictions = []\n",
    "        for tree, features in self.trees:\n",
    "            subset_test_array = test_array[:, features]\n",
    "            prediction_value = tree.predict(subset_test_array)\n",
    "            predictions.append(prediction_value)\n",
    "\n",
    "        prediction_array = np.array(predictions)\n",
    "\n",
    "        if self.task == 'classification':\n",
    "            final_prediction = []\n",
    "            for i in range(prediction_array.shape[1]):\n",
    "                values, counts = np.unique(prediction_array[:, i], return_counts = True)\n",
    "                final_prediction.append(values[np.argmax(counts)])\n",
    "            \n",
    "            final_prediction_array = np.array(final_prediction)\n",
    "        elif self.task == 'regression':\n",
    "            final_prediction_array = np.mean(prediction_array, axis = 0)\n",
    "        \n",
    "        return final_prediction_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X0 = np.random.normal(loc=0.0, scale=1.0, size=(50, 2))\n",
    "y0 = np.zeros(50, dtype=int)\n",
    "\n",
    "# Class 1: centered around (3,3)\n",
    "X1 = np.random.normal(loc=3.0, scale=1.0, size=(50, 2))\n",
    "y1 = np.ones(50, dtype=int)\n",
    "\n",
    "# Combine\n",
    "X_train = np.vstack([X0, X1])\n",
    "y_train = np.concatenate([y0, y1])\n",
    "\n",
    "# Class 0 test points\n",
    "X0_test = np.array([\n",
    "    [-0.5, 0.0],\n",
    "    [0.2, -0.3],\n",
    "    [0.0, 0.5],\n",
    "    [-1.0, 0.2],\n",
    "    [0.1, -0.8],\n",
    "    [-0.4, 0.3],\n",
    "    [0.5, 0.1],\n",
    "    [-0.2, -0.2],\n",
    "    [0.0, -0.5],\n",
    "    [0.3, 0.4]\n",
    "])\n",
    "\n",
    "# Class 1 test points\n",
    "X1_test = np.array([\n",
    "    [2.8, 3.1],\n",
    "    [3.0, 2.5],\n",
    "    [3.2, 3.0],\n",
    "    [3.5, 3.3],\n",
    "    [2.9, 2.7],\n",
    "    [3.1, 3.2],\n",
    "    [2.7, 3.0],\n",
    "    [3.3, 3.4],\n",
    "    [2.9, 3.1],\n",
    "    [3.0, 3.0]\n",
    "])\n",
    "\n",
    "X_test = np.vstack([X0_test, X1_test])\n",
    "y_test = np.array([0]*10 + [1]*10)\n",
    "\n",
    "rf = random_forest(100, 'classification')\n",
    "rf.fit(X_train, y_train)\n",
    "x_pred = rf.prediction(X_test)\n",
    "print((x_pred == y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 6. 9.]\n",
      "Feature 0 <= 2.5\n",
      "\tFeature 0 <= 1.5\n",
      "\t\tPredict: 2.0\n",
      "\t\tPredict: 4.0\n",
      "\tFeature 0 <= 3.5\n",
      "\t\tPredict: 6.0\n",
      "\t\tPredict: 9.0\n",
      "0 2.5\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([[1], [2], [3], [4], [5]])\n",
    "y_train = np.array([2.0, 4.0, 6.0, 8.0, 10.0])  # Linear relationship: y = 2*x\n",
    "\n",
    "# Testing data\n",
    "X_test = np.array([[1.5], [3.5], [5]])\n",
    "\n",
    "regression = regression_tree(max_depth = 2, min_samples_split=1)\n",
    "regression.fit(X_train, y_train)\n",
    "print(regression.predict(X_test))\n",
    "regression.print_tree()\n",
    "\n",
    "best_feature, best_threshold = regression._best_split(X_train, y_train)\n",
    "print(best_feature, best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4]\n",
      "[4. 6.]\n",
      "Feature 0 <= 1.5\n",
      "\tPredict: 4.0\n",
      "\tPredict: 6.0\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([\n",
    "    [1, 2],\n",
    "    [1, 4],\n",
    "    [2, 2],\n",
    "    [2, 4]\n",
    "])\n",
    "y_train = np.array([3.0, 5.0, 5.0, 7.0])\n",
    "print(X_train[1])\n",
    "tree = regression_tree(max_depth=1, min_samples_split=2)\n",
    "tree.fit(X_train, y_train)\n",
    "X_test = np.array([[1,3],[2,3]])\n",
    "y_pred = tree.predict(X_test)\n",
    "print(y_pred)  # should be approx [4.0, 6.0]\n",
    "tree.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 5.]\n",
      "Feature 0 <= 1.5\n",
      "\tFeature 1 <= 3.0\n",
      "\t\tPredict: 3.0\n",
      "\t\tPredict: 5.0\n",
      "\tFeature 1 <= 3.0\n",
      "\t\tPredict: 5.0\n",
      "\t\tPredict: 7.0\n"
     ]
    }
   ],
   "source": [
    "# Training data (2 features)\n",
    "X_train = np.array([\n",
    "    [1, 2],\n",
    "    [1, 4],\n",
    "    [2, 2],\n",
    "    [2, 4]\n",
    "])\n",
    "y_train = np.array([3.0, 5.0, 5.0, 7.0])  # roughly: y = x1 + x2\n",
    "\n",
    "# Testing data\n",
    "X_test = np.array([\n",
    "    [1, 3],\n",
    "    [2, 3]\n",
    "])\n",
    "\n",
    "# Expected outcomes (depending on splits):\n",
    "#   1,3  leaf covering [1,2], [1,4]  mean = (3+5)/2 = 4\n",
    "#   2,3  leaf covering [2,2], [2,4]  mean = (5+7)/2 = 6\n",
    "expected_y = np.array([4.0, 6.0])\n",
    "\n",
    "tree = regression_tree(max_depth=None, min_samples_split=1)\n",
    "tree.fit(X_train, y_train)\n",
    "X_test = np.array([[1,3],[2,3]])\n",
    "y_pred = tree.predict(X_test)\n",
    "print(y_pred)  # should be approx [4.0, 6.0]\n",
    "tree.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[1], [1], [2], [2]])\n",
    "y_train = np.array([5.0, 5.0, 10.0, 10.0])\n",
    "\n",
    "X_test = np.array([[1], [2], [1.5]])\n",
    "\n",
    "# Expected outcomes:\n",
    "#   1  leaf covering [1,1]  mean = 5\n",
    "#   2  leaf covering [2,2]  mean = 10\n",
    "#   1.5  maybe split [1,2]  mean = (5+10)/2 = 7.5\n",
    "expected_y = np.array([5.0, 10.0, 7.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def euclidean_distance(data_vector_1: ArrayLike, \n",
    "                       data_vector_2: ArrayLike, \n",
    "                       name_1: str = 'data_vector_1', \n",
    "                       name_2: str = 'data_vector_2') -> float:\n",
    "    \n",
    "    # TODO: docstrings, type hints, and examples\n",
    "\n",
    "    vector_1 = _ensure_numeric(data_vector_1, name_1)\n",
    "    vector_2 = _ensure_numeric(data_vector_2, name_2)\n",
    "\n",
    "    _shape_match(vector_1, vector_2)\n",
    "\n",
    "    distance = float(np.linalg.norm((vector_2 - vector_1)))\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _validate_parameters_k_means(n_clusters: int, max_iterations: int, tol: float, random_state: Optional[int] = None) -> None:\n",
    "\n",
    "    if not isinstance(n_clusters, int):\n",
    "        raise TypeError('Number of clusters must be an integer')\n",
    "    if n_clusters <= 0:\n",
    "        raise ValueError('Number of clusters must be greater than zero')\n",
    "    if not isinstance(max_iterations, int):\n",
    "        raise TypeError('Maximum number of iterations must be an integer')\n",
    "    if max_iterations <= 0:\n",
    "        raise ValueError('Maximum number of iterations must be greater than zero')\n",
    "    if not isinstance(tol, float):\n",
    "        raise TypeError('Tolerance must be a float')\n",
    "    if tol <= 0:\n",
    "        raise ValueError('Tolerance must be greater than zero')\n",
    "    if random_state is not None and not isinstance(random_state, int):\n",
    "        raise TypeError('Random state must be an integer')\n",
    "\n",
    "class k_means():\n",
    "    \n",
    "    def __init__(self,\n",
    "                n_clusters: int,\n",
    "                max_iterations: int,\n",
    "                tol: float = 1e-6,\n",
    "                random_state: Optional[int] = None) -> None:\n",
    "        \n",
    "        _validate_parameters_k_means(n_clusters, max_iterations, tol, random_state)\n",
    "\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iterations\n",
    "        self.tol = tol\n",
    "        self.random_state = random_state\n",
    "        self.cluster_labels: Optional[np.ndarray] = None\n",
    "        self.centroids_: Optional[np.ndarray] = None\n",
    "        self.inertia_: Optional[float] = None\n",
    "        self.n_features_: Optional[int] = None\n",
    "        \n",
    "\n",
    "    def _initial_centroids(self, training_array: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        train_array = _2D_numeric(training_array) # TODO: move this so it isn't redundant\n",
    "        rng = _random_number(self.random_state)\n",
    "        centroid_indices = rng.choice(train_array.shape[0], self.n_clusters, replace = False)\n",
    "        initial_centroids = train_array[centroid_indices]\n",
    "        \n",
    "        return initial_centroids\n",
    "    \n",
    "    def _distance_calc(self, training_array: np.ndarray, centroid_array: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        distance_array = np.full((training_array.shape[0], self.n_clusters), np.nan)\n",
    "\n",
    "        for sample in range(training_array.shape[0]):\n",
    "            data_vector = training_array[sample]\n",
    "            for centroid in range(centroid_array.shape[0]):\n",
    "                centroid_vector = centroid_array[centroid]\n",
    "                distance_array[sample, centroid] = euclidean_distance(data_vector, centroid_vector)\n",
    "\n",
    "        if any(value is np.nan or value is None for value in distance_array):\n",
    "            raise ValueError('Distance was not computed for all points')\n",
    "        \n",
    "        return distance_array\n",
    "    \n",
    "    def _clustering(self, training_array: np.ndarray, centroid_array: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        centroids = _2D_numeric(centroid_array)\n",
    "        distance_array = self._distance_calc(training_array, centroids)\n",
    "        cluster_indices = np.argmin(distance_array, axis = 1)\n",
    "\n",
    "        return cluster_indices\n",
    "    \n",
    "    def _updated_centroids(self, training_array: np.ndarray, cluster_labels: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        updated_centroids = np.full((self.n_clusters, training_array.shape[1]), np.nan)\n",
    "\n",
    "        rng = _random_number(self.random_state)\n",
    "        for cluster in range(self.n_clusters):\n",
    "            training_array_cluster = training_array[cluster_labels == cluster]\n",
    "            if len(training_array_cluster) > 0:\n",
    "                updated_centroids[cluster] = training_array_cluster.mean(axis = 0)\n",
    "            else:\n",
    "                updated_centroids[cluster] = training_array[rng.choice(training_array.shape[0])]\n",
    "      \n",
    "        if any(value is np.nan or value is None for value in updated_centroids):\n",
    "            raise ValueError('Not all centroids were updated')\n",
    "        \n",
    "        return updated_centroids\n",
    "    \n",
    "    def _inertia(self, training_array: np.ndarray, centroid_array: np.ndarray, cluster_indices_array: np.ndarray) -> float:\n",
    "\n",
    "        cluster_indices = _ensure_numeric(cluster_indices_array).astype(int)\n",
    "        distance_array = self._distance_calc(training_array, centroid_array)\n",
    "\n",
    "        actual_distances = distance_array[np.arange(training_array.shape[0]), cluster_indices]\n",
    "        squared_distances = actual_distances ** 2\n",
    "        final_distance = np.sum(squared_distances)\n",
    "\n",
    "        return final_distance\n",
    "    \n",
    "    def fit(self, training_array: np.ndarray) -> 'k_means':\n",
    "\n",
    "        train_array = _2D_numeric(training_array)\n",
    "\n",
    "        self.n_features_ = train_array.shape[1]\n",
    "\n",
    "        centroids = self._initial_centroids(train_array)\n",
    "\n",
    "        for iteration in range(self.max_iter):\n",
    "            cluster_labels = self._clustering(train_array, centroids)\n",
    "            updated_centroids = self._updated_centroids(train_array, cluster_labels)\n",
    "\n",
    "            shift = np.sum(np.linalg.norm(updated_centroids - centroids, axis = 1))\n",
    "\n",
    "            centroids = updated_centroids\n",
    "\n",
    "            if shift < self.tol:\n",
    "                break\n",
    "\n",
    "        inertia = self._inertia(train_array, updated_centroids, cluster_labels)\n",
    "\n",
    "        self.centroids_ = centroids\n",
    "        self.cluster_labels = cluster_labels\n",
    "        self.inertia_ = inertia\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _verify_fit(self):\n",
    "        if self.centroids_ is None or self.cluster_labels is None or self.inertia_ is None:\n",
    "            raise RuntimeError(\"Model is not fitted; call fit(training_array)\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def prediction(self, testing_array: ArrayLike) -> np.ndarray:\n",
    "\n",
    "        test_array = _2D_numeric(testing_array)\n",
    "\n",
    "        if test_array.shape[1] != self.n_features_:\n",
    "            raise ValueError('Test data must have the same number of features as training data')\n",
    "        \n",
    "        cluster_predictions = self._clustering(test_array, self.centroids_)\n",
    "\n",
    "        return cluster_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333333 0.33333333]\n",
      " [9.33333333 0.33333333]\n",
      " [5.33333333 5.33333333]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 2, 2, 1, 1, 1])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [5, 5],\n",
    "    [6, 5],\n",
    "    [5, 6],\n",
    "    [9, 0],\n",
    "    [9, 1],\n",
    "    [10, 0]\n",
    "])\n",
    "\n",
    "\n",
    "cluster = k_means(3, 100)\n",
    "cluster.fit(X)\n",
    "print(cluster.centroids_)\n",
    "cluster.cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _validate_parameters_dbscan(epsilon: float, core_point_min: int) -> None:\n",
    "\n",
    "    if not isinstance(epsilon, (float, int)):\n",
    "        raise TypeError('Epsilon must be a float or integer')\n",
    "    if epsilon < 0:\n",
    "        raise ValueError('Epsilon must be non-negative')\n",
    "    if not isinstance(core_point_min, int):\n",
    "        raise TypeError('Minimum number of neighboring samples to be considered a core point must be an integer')\n",
    "    if core_point_min < 0:\n",
    "        raise ValueError('Minimum number of neighboring samples to be considered a core point must be non-negative')\n",
    "    \n",
    "class dbscan():\n",
    "\n",
    "    def __init__(self,\n",
    "                 epsilon: float,\n",
    "                 core_point_min: int) -> None:\n",
    "        \n",
    "        _validate_parameters_dbscan(epsilon, core_point_min)\n",
    "\n",
    "        self.epsilon = epsilon\n",
    "        self.min_points = core_point_min\n",
    "        self.cluster_labels: Optional[np.ndarray] = None\n",
    "        self.core_point_indices: Optional[np.ndarray] = None\n",
    "\n",
    "    def _distance_calc(self, training_array: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        n_features = training_array.shape[0]\n",
    "        distance_array = np.full((n_features, n_features), np.nan)\n",
    "\n",
    "        for feature_1 in range(n_features):\n",
    "            for feature_2 in range(n_features):\n",
    "                distance_array[feature_1, feature_2] = euclidean_distance(training_array[feature_1], training_array[feature_2])\n",
    "\n",
    "        if any(value is np.nan or value is None for value in distance_array):\n",
    "            raise ValueError('Distance was not computed for all points')\n",
    "        \n",
    "        return distance_array\n",
    "    \n",
    "    def _find_neighbors(self, point_index: int, distance_array: np.ndarray) -> list:\n",
    "        \n",
    "        distances = _2D_numeric(distance_array)\n",
    "        if not isinstance(point_index, int):\n",
    "            raise TypeError('Point index must be an integer')\n",
    "        if point_index < 0:\n",
    "            raise ValueError('Point index must be non-negative')\n",
    "        \n",
    "        neighbors = np.where(distances[point_index] <= self.epsilon)[0]\n",
    "        neighbors = neighbors.tolist()\n",
    "\n",
    "        return neighbors\n",
    "\n",
    "    def _expand_region(self, \n",
    "                       cluster_labels: np.ndarray, \n",
    "                       point_index: int, \n",
    "                       neighbor_list: list,\n",
    "                       cluster_id: int,\n",
    "                       distance_array: np.ndarray) -> None:\n",
    "        \n",
    "        cluster_labels[point_index] = cluster_id\n",
    "\n",
    "        i = 0\n",
    "        while i < len(neighbor_list):\n",
    "            neighbor_point_index = neighbor_list[i]\n",
    "\n",
    "            if cluster_labels[neighbor_point_index] == -1:\n",
    "                cluster_labels[neighbor_point_index] = cluster_id\n",
    "\n",
    "            new_neighbors = self._find_neighbors(neighbor_point_index, distance_array)\n",
    "\n",
    "            if len(new_neighbors) >= self.min_points:\n",
    "                for neighbor in new_neighbors:\n",
    "                    if neighbor not in neighbor_list:\n",
    "                        neighbor_list.append(neighbor)\n",
    "            \n",
    "            i += 1\n",
    "\n",
    "    def fit(self, training_array: ArrayLike) -> 'dbscan':\n",
    "\n",
    "        train_array = _2D_numeric(training_array)\n",
    "        n_samples = train_array.shape[0]\n",
    "\n",
    "        cluster_labels = np.full(n_samples, -1, dtype = int)\n",
    "        cluster_id = 0\n",
    "\n",
    "        distance_array = self._distance_calc(train_array)\n",
    "\n",
    "        for point_index in range(n_samples):\n",
    "            if cluster_labels[point_index] != -1:\n",
    "                continue\n",
    "            \n",
    "            neighbor_list = self._find_neighbors(point_index, distance_array)\n",
    "\n",
    "            if len(neighbor_list) < self.min_points:\n",
    "                cluster_labels[point_index] = -1\n",
    "            else:\n",
    "                self._expand_region(cluster_labels, point_index, neighbor_list, cluster_id, distance_array)\n",
    "                cluster_id += 1\n",
    "\n",
    "        self.cluster_labels = cluster_labels\n",
    "        self.core_sample_indices_ = np.where(np.array([len(self._find_neighbors(point, distance_array)) for point in range(n_samples)]) >= self.min_points)[0]\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, -1,  1,  1])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [1, 1],   # Cluster 0\n",
    "    [1.5, 1], # Cluster 0\n",
    "    [1, 1.5], # Cluster 0\n",
    "    [5, 5],   # Noise (far from other points)\n",
    "    [8, 8],   # Cluster 1\n",
    "    [8.5, 8], # Cluster 1\n",
    "])\n",
    "\n",
    "cluster = dbscan(1, 2)\n",
    "\n",
    "cluster.fit(X)\n",
    "cluster.cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(G.neighbors(1))\n",
    "dictionary = {n: n for n in G.nodes}\n",
    "dictionary\n",
    "list(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 6, 5, 7, 1, 3, 8, 9, 0, 4])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _random_number(random_state: Optional[int]) -> np.random.Generator:\n",
    "    \n",
    "    # TODO: type hints/docstrings\n",
    "\n",
    "    if random_state is not None and not isinstance(random_state, int):\n",
    "            raise TypeError(f\"Random state must be an integer\")\n",
    "    if random_state is None:\n",
    "        return np.random.default_rng()\n",
    "    else:\n",
    "        return np.random.default_rng(int(random_state))\n",
    "    \n",
    "rng = _random_number(None)\n",
    "rng.choice(10, size = 10, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import *\n",
    "from collections import defaultdict\n",
    "\n",
    "def _random_number(random_state: Optional[int]) -> np.random.Generator:\n",
    "    \n",
    "    # TODO: type hints/docstrings\n",
    "\n",
    "    if random_state is not None and not isinstance(random_state, int):\n",
    "            raise TypeError(f\"Random state must be an integer\")\n",
    "    if random_state is None:\n",
    "        return np.random.default_rng()\n",
    "    else:\n",
    "        return np.random.default_rng(int(random_state))\n",
    "    \n",
    "\n",
    "def validate_parameters(graph: nx.Graph, max_iter: int, random_state: Optional[int] = None):\n",
    "\n",
    "    if not isinstance(graph, nx.Graph):\n",
    "        raise TypeError(\"Input graph must be a NetworkX graph\")\n",
    "    if not isinstance(max_iter, int):\n",
    "        raise TypeError(\"Maximum number of iterations must be an integer\")\n",
    "    if max_iter <= 0:\n",
    "        raise ValueError(\"Maximum number of iterations must be greater than zero\")\n",
    "    if random_state is not None and not isinstance(random_state, int):\n",
    "        raise TypeError(\"Random state parameter must be an integer\")\n",
    "\n",
    "class label_propagation():\n",
    "\n",
    "    def __init__(self,\n",
    "                 graph: nx.Graph,\n",
    "                 max_iter: int,\n",
    "                 random_state: Optional[int] = None) -> None:\n",
    "        validate_parameters(graph, max_iter, random_state)\n",
    "\n",
    "        self.graph = graph\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "        self.labels: Dict[Hashable, Hashable] = {node: node for node in self.graph.nodes}\n",
    "        self.fit_: bool = False\n",
    "\n",
    "    def _label_updates(self, \n",
    "                       node: Hashable) -> Hashable:\n",
    "        \n",
    "        try:\n",
    "            hash(node)\n",
    "        except TypeError:\n",
    "            print(f\"Input for node ({node}) is not hashable\")\n",
    "        \n",
    "        rng = _random_number(self.random_state)\n",
    "        \n",
    "        frequency_counts = defaultdict(int)\n",
    "        for neighbor in list(self.graph.neighbors(node)):\n",
    "            frequency_counts[self.labels[neighbor]] += 1\n",
    "\n",
    "        if not frequency_counts:\n",
    "            return self.labels[node]\n",
    "        \n",
    "        maximum_count = max(frequency_counts.values())\n",
    "        tied_labels = [label for label, count in frequency_counts.items() if count == maximum_count]\n",
    "        tiebreaker = rng.choice(tied_labels)\n",
    "\n",
    "        return tiebreaker\n",
    "    \n",
    "    def propagation(self) -> 'label_propagation':\n",
    "\n",
    "        # TODO: type hints/docstrings - the dictionary is node, label\n",
    "\n",
    "        rng = _random_number(self.random_state)\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "\n",
    "            changed = False\n",
    "\n",
    "            shuffled_nodes = rng.permutation(list(self.graph.nodes()))\n",
    "\n",
    "            for node in shuffled_nodes:\n",
    "                new_label = self._label_updates(node)\n",
    "                if new_label != self.labels[node]:\n",
    "                    self.labels[node] = new_label\n",
    "                    changed = True\n",
    "\n",
    "            if not changed:\n",
    "                break\n",
    "            \n",
    "        self.fit_ = True\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def _verify_fit(self) -> \"label_propagation\":\n",
    "        if not self.fit_:\n",
    "            raise RuntimeError(\"Label propagation algorithm has not been run; call propagation()\")\n",
    "        \n",
    "    def get_communities(self, data_type = Literal['dict', 'list']) -> list:\n",
    "\n",
    "        self._verify_fit()\n",
    "\n",
    "        if data_type not in ('dict', 'list'):\n",
    "            raise ValueError(f\"Data type must be one of {['dict', 'list']}\")\n",
    "        community_dict = defaultdict(set)\n",
    "        for node, label in self.labels.items():\n",
    "            community_dict[label].add(node)\n",
    "\n",
    "        if data_type == 'dict':\n",
    "            return dict(community_dict)\n",
    "        \n",
    "        elif data_type == 'list':\n",
    "            return list(community_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApQAAAHzCAYAAACe1o1DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABGv0lEQVR4nO3dCXjUZZrv/TtbJSSQBLJCWBJ2giGEHRRUQFGhRQUUXHvxTHcfp9eZ6XOm3zNXn5l35szpOe+Znn6Pc17nbbunZZFVBEFBWV3aVlDZFJE17GRfSFVIJamc636k0glkr6r8q/71/VzX/ypJJf96AuaqX57nue8noqmpqUkAAACAHors6RcCAAAAikAJAAAAnxAoAQAA4BMCJQAAAHxCoAQAAIBPCJQAAADwCYESAAAAPiFQAgAAwCcESgAAAPiEQAkAAACfECgBAADgEwIlAAAAfEKgBAAAgE8IlAAAAPAJgRIAAAA+IVACAADAJwRKAAAA+IRACQAAAJ8QKAEAAOATAiUAAAB8QqAEAACATwiUAAAA8AmBEgAAAD4hUAIAAMAnBEoAAAD4hEAJAAAAnxAoAQAA4BMCJQAAAHxCoAQAAIBPCJQAAADwCYESAAAAPiFQAgAAwCcESgAAAPiEQAkAAACfECgBAADgEwIlAAAAfEKgBAAAgE+ifftyAMGkweORGnejeJqaJDIiQvo6oiQ6kt8bAQCBRaAEQlx1Xb2cq3TJNWedOOsbb3s+ISZKMhNiJSc5XhJjYywZIwDA3iKampqarB4EgO5zuhvkUFGVFLvcEiEiHf0ge59Pj3dIQUaSJDj4XRIA4D8ESiAE6YzkkeIq0Z/e7vwAa7CMiBDJT08yM5YAAPgDgRIIMSfKrsvx0hqf75Ob2lfGpvTzy5gAAOGN3fpAiM1M+iNMKr1PYaXLL/cCAIQ3NlIBIbRnUpe52/L5xx/KL55b2uZz/7hum4yeOLnN5w4XV0lavIM9lQAAn/AuAoQILcDpbIPKQ898R0bmTWz1scxh2e1+vt5P73vXkBR/DRMAEIYIlECItAbSau7O5E6eLjMfWNTl+2o+1fvq/WkpBADoKfZQAiGyd1IrtLuitqZGGhsaunzviJv3BwCgp5ihBEKANi3vSjuGF3/+E7nhckpkVJSMmzxdnv2rv5GRefkdfk3Tzft3/FkAALSPQAkEuXqPp80TcFqKjomRGfcvlEl3z5XE/gPk4umT8sbvXpK/efpR+Ye1W2V4bl6HX6/312MbOaYRANAT9KEEglzljXrZe76021939fw5+enieZI7ZYb8zcuvdvr5c4elSnIc+ygBAN3HdAQQ5Dw9/J1v4LAcmTp3gWkp1NjYGLDXAQCAJW8gCHk8HikpKZErV67IpdIKkaHjenSf1IGDpKHeLXW1Lonv2/GpOJF6JiMAAD1AoASCIDyWlpbK1atXTYDU69q1a9Jws1I7PTNTMoaM/foQ7m4qunhBHLFxEhef0Onn9nVE9Wj8AAAQKIFepFuWy8rKmoOjhki96uvrzfMpKSkyaNAgGT9+vHnMzMwUh8Mhb58t7rAwp6q8TJIGtG5OXnjiC/lk3ztSMPteieyk2CYhJoqCHABAjxEogQCGx4qKilbhUR/d7q8blPfv39+ExjFjxjSHx7i4uDbvlZkQK2crXe22Dvrnn3xPHHFxMqZgiiQNSJVLZ07Krg2rxRHXR57+i/+rw3FG3Lw/AAA9RZU34Af6Y1RVVdUcHr0B8saNG+b55ORkExoHDhzY/NinT58u319Pstld2H6l95srX5b3t78uV88XSq3zuiT2T5G8mXfJ4y/81BTndGZ+dion5QAAeoxACXST/shUV1e32vOoV21trXk+MTGxVXjUKz4+3ufX/eBimZS43F1qcN5VOjuZFu/gLG8AgE8IlEAnrl+/ftuytdPpNM/17du3OTR6Q6R+LBCc7gbZVVgiHj/+xEZGiNyXnSYJDna/AAB6jkAJtKBB8dbwqIFS6Sxjy/CoV79+Hbfi8Tc9c/tQUZXf7jcpI0myk32fPQUAhDcCJcKWy+W6bdlal7KV7m+8ddlal7IjgqBX44my63K8tMbn++Sm9pOxKYGZTQUAhBcCJcKCFsfcGh4rKyvNc7GxsbeFRy2iCYbw2NFM5ZHiKtGf3u78AOt3pN/WxHRmJgEA/kOghO3U1dU1h0fvY3l5uXlOezq2DI56afueYA6PHe2p1OXvYpfbBMWOfpC9z6fHO6QgI4k9kwAAvyJQIqRpT0c9VaZleNRTZ1RMTIzp7dgyPGrj8FAMj521FNIZy2vOujabn2vTcu0zmZMcT2sgAEBAECgRMvQ0maKiolbL1hoe9X/h6OhoEx5bzj6mpqZ2ekKM3TR4PFLjbpTde/bIjVqXLH/sEU7AAQAEHOteCEp6jnVxcXGr8Kh/1vAYFRUlGRkZMnToUJkxY4YJj2lpaebj4U7DY3JcpPSNEikqukqYBAD0CgIlLNfY2NgqPOrStc5EejweM8OYnp4uWVlZMnXqVBMe9c+Ex45pL8yaGt8rwQEA6AoCJXqVhsSSkpJW4VH3QGqo1L2NOtOoobGgoMA86kykLmeje7Q/pla26zYB3UsKAEAg8U6NgIbHsrKyVsvWGh51OVt5w2NeXp551D2QhB//8J7Wo7OUWsUOAEAgESjhF7q30RseW7bs0RkypdXVGhpzc3Obez5qCx8EBoESANCbCJToUXisqKi47YhCbeGjNMBoaBwzZkzzzGNcXJzVww4r3iMh2UcJAOgNBEp0Gh6rqqpuC4+6P08lJSWZ0Dh79uzmmUc9thDW0n8DLWjynkMOAEAgESjRKjxqAGm551Gv2tpa87yeZa2hcebMmc29HuPjOb4vGGmBE5XeAIDeQqAMY97w2PKMa6fTaZ7TMKKBcdq0ac3h0bsvD6FB/72YoQQA9IawD5Tek0U8TU0SqbM6jihbNoPWoHjrsrU3bOgsowbGyZMnNy9b6x48ux1RGG7039D7CwIAAIEUloHS7mcf6xL1reFR90EqLY7R0Jifn98886hL2YRHe85QXr582ephAADCQFgFSqe7QQ4VVUmxyy0an9o7xFxD5tlKl5ypdEl6vEMKMpIkwRGcf1VaHNNyyVqvyspK81xsbKwJjOPHj28Oj8nJyYTHMMEeSgBAbwnOlBQAOiN5pLhKmm6myPbCpJf3+RKXW3YVlkh+epKZsbRSXV2dCY8tA2R5ebl5Tns66lL12LFjm8PjgAEDCI9hzLvk7T3CEgCAQAmLQHmi7LocL+3ZTI0GSw2hOrNZ19goY1O+7u8XaNrTUU+VablsXVpaap7Towg1PI4aNapVeCQ04NYZSq3c11Dp7UsJAEAgRIfDzGRPw+St9D5xUVGS7eeZSj1NpqioqFV41POuNQxERUWZxuA5OTly5513mvCYmppKeES3TsshUAIAAina7nsmdZm7PWe/OCrrX/yfcuKzg+KuuyEZQ4bJfcuekoXPPt/u1xwurpK0eEeP91TqOdbFxcWt9jzqnzU8akjU8DhkyBCZPn26CY963rWGSqC7OC0HANBbbB0odZnau2fyVoc/2C//+P1vSk7uHbL0+z+WuPgEuXaxUMqKrnZ4T+/y911DUjp9/cbGRhMWW+551JlI75629PR0ExqnTJliHvXPupwN+ENCQoJ5pBclACDQou3cGkirudviqrku/+s//0gm3zNP/vLXv+nW8rHmU72v3r9lSyENibpM3bJdj+6B1FCphTE606ihsaCgwDxmZGQQHhFQOrOtPUaZoQQABFq0nfdOttca6P3tr0tlaYk8+eP/bMLkDZdLHHFxXQ6Wet/jV8ukT9Wf9j3qpcvZSvc4amjMy8szj7qMHRMTev0sYY9lb2YoAQCBZttAqU3L22sNdPTD9yW+bz+zvP3LF74lVwrPSlx8vMx5eKl866//qzhi4zq8t973XGmlnHxzi6SkpJjQOG7cuObwqP0fgWBAL0oAQG+wZaCs93jaPAHH6+r5c9LY2GDC5LwlK+Spn/5cvjjwoby1+nfirK6Sn/7z/9fpa8T2S5S/+KufSd/4Pn4ePeDfQFlWVmb1MAAANmfLQOl0tx8m1Q2XU+pqa+X+5c/Kd/7L35uPzbj/IWmor5d31q+S5T/8KxmUPbyTV4mQhkhb/vXBZoHy/PnzVg8DAGBztmxm6GmvtPsm3S+p7lr4SKuP37XoUfN48vCnfnkdIFj2UGpbKgAAAsWWgTKyk+MGB6RlmMfklNRWH09K+boVUE11lV9eBwiGGUrtNKBnvgMAECi2DJR9HR03Ah8+foJ5LC++1urjFcVF5jGp/wC/vA5gNZqbAwB6gy0DZXRkpCTEtB/2Zj34DfO4Z9PaVh/fvfFViYqOlvHTZnX6Gnp/fR0gFI5fpHUQACCQbFtVkpkQK2crXW22DhqemydzlyyXva+tM9Xe46fOlM8P/FH+uHObPPZnP5ABGZlduj8QSud5AwAQKLYNlDnJ8XKm0tXu89/9r7+UtIFZsnfzejmwe6ekDhos3/rrv5VFz/2HLt3/+B/2SWJBvmRnZ5uTcIBg5HA4zEWgBAAEUkSTjcs/P7hYJiUud7sNzntCo2NcY50UvrvDnNM9cOBAmTlzpowfP75bRzgCveXFF1+UUaNGyYIFC6weCgDApmwdKJ3uBtlVWCIeP36HkREi92WnSXxMlJw9e1Y+/PBD85iUlCQzZswwZ3VzUg6Cye9//3tTnLNkyRKrhwIAsCnbLnmrBEe05KcnyaGirrUB6oqJ6UnmvmrEiBHmunbtmvzxj3+UXbt2yf79+2XKlCkybdo0SUxM9NvrAj3F8YsAgECz9Qyl14my63K81Pc31NzUfjI25esih7ZUV1fLxx9/LJ9++qnU19dLXl6eWQ7PyPi67yVghZ07d8qZM2fkhRdesHooAACbsvUMpdfYlH4SGxUlR4qrRONzUzf3TGrNjc5MZifHd/i5OiN53333yezZs+Wzzz4z4fLIkSNmFnPWrFmSk5NDAQ8sOy0HAIBACYtA6a36To93mOXvYpfbBMWOgqX3+bR4hxRk/GmZuyvi4uJMgJw+fbp88cUXZjl81apVkpmZ2VzAExVFU3T03pJ3XV2dmTWPiYmxejgAABsKiyXvW1XX1cu5Spdcc9aJs76xzabl2mdSQ2hirO9vwPpXfO7cORMsT58+bWYyNWxOnjyZAh4EnBaN6S80P/zhD6V///5WDwcAYENhM0PZkobE/IwkyReRBo9HatyN4mlqMmdz63GK/j4BR5e5hw8fbq6ioiITLPfs2SPvvfeeTJo0yVSHU8CD3jgth0AJAAiEsAyULWl4TI7rvf6RWqDzyCOPyNy5c+XAgQPyySefmL2Wd9xxh1kO12VxwJ84LQcAEGhhHyitojOS8+fPNwU8hw4dko8++kiOHj1qZjF1/6U+UsADf+jTp4/Zs0ugBAAECoHSYrqHUpe8tW+lt4Bn9erVkp6eboKlzlxSwANf6C8mOktJpTcAIFDCsignmOk/R2FhoQmWp06dMi1fvAU8Wj0O9MTLL78saWlpsnjxYquHAgCwIWYog3A2SftV6qVnhWuw3LdvX6sCHj3mEegO/cWEJW8AQKAwQxkCdKnSW8Cj/QS9BTwDBw60emgIEdu3b5dLly7J9773PauHAgCwIWYoQ2R2ad68ea0KeI4dO2ZmMXWfpZ7EQwEPOsIMJQAgkAiUIcThcJj9lFOnTpUvv/xSPvzwQ1mzZo0p4NEZS525jI7mnxS306Icp9MpHo9HIv3cZxUAANJHCNJAoMc35ubmyoULF0yw3Lp1q2mWroFzypQpFPDgthlKpaHS+98AAPgLgTKE6TL3sGHDzFVSUmIKePbv3y/vv/++FBQUmAKe5ORkq4eJIDsth0AJAPA3AqVNaEuYhx9+uNUJPPqoM5m6HD5o0CCrhwgLeUMk+ygBAIFAoLThTJSGyrvuuksOHz5sCnh+85vfSHZ2tgmWo0aNooAnDCUkJJhHmpsDAAKBQGnjAh49fUf3U544ccLss1y7dq2ZydRgmZeXRwFPmO271VDJDCUAIBBIFGEQJLR4Z9y4cXLx4kUTLN944w3Zu3dvc+DUs54RHrPXBEoAQCAQKMOELnMPHTrUXKWlpaaA5913321VwNO/f3+rh4kAohclACBQOCknjGkLGS3cOXjwoNy4ccPMZOpyeFZWltVDQwBoayntBvD8889bPRQAgM0QKCH19fXNBTzl5eWmDZEGy9GjR1PAYyPap1RPWPrxj39s9VAAADbDkjckJibGnL4zefJk+eqrr8w+y3Xr1klKSooJlvn5+RTw2GgPpf4OyS8KAAB/IiWgVQGPFu94C3h0n+X27dtl3759JnDqFR8fb/Uw4cMeysbGRrO9gUIsAIA/ESjRpiFDhpirrKzMLIV/8MEH5vIW8AwYMMDqIcKH03IIlAAAfyJQokO67L1w4UK55557mk/f0SIencWcNWuWDB482Oohogen5aSnp1s9HACAjRAo0SXaFPvuu+82IfLIkSNmOfy3v/2taUOk+yzHjBnDvrwQmqEEAMCfCJTodgGPNkP3FvBosFy/fr1ZAvcW8OjnIPjov0tsbCy9KAEAfkegRI/obOTYsWPNdenSJRMs33rrrVYFPN7zoxE8OC0HABAI9KGE32gPSy3gOXTokPnzxIkTTQGP7sNEcHjllVdMqFyyZInVQwEA2AiBEn7ncrmaC3j0NB6dxdS9l1o1Dmu99tprZg/lN7/5TauHAgCwEQIlAqahoUGOHj1qlsP1/HCtCNdgqQU82vMSve/tt9+WU6dOyZ//+Z9bPRQAgI2whxIBo6frTJo0yfSu1BCjJ/Bs2LDBFPDoUrguiVPA07t0uZsqbwCAvxEo0SsFPHouuF6XL182M5Y7duxoLuCZNm0aBTy92IvS7Xaby+FwWD0cAIBNECjRq7KysmTp0qVSUVFhCng0XP7hD38w7Ya07VBqaqrVQwyLXpRa6c1pRwAAfyFQwhL9+/eXBx98sNUJPJ999pnZX6nBUhum0yg9sKflECgBAP5CoISl9Ezp2bNnmxB57Ngxs8/y97//vZnJ1AIerRCngMd/OC0HABAIBEoETQGPFu9ooc7p06dNsNy4caOZyfQW8LDnz3dxcXESFRVFc3MAgF8RKBFUdJl71KhR5rpy5YrZY7lz585WBTzeWTb07O+XSm8AgL/RhxJBr7Ky0hTw6B5Lj8cjEyZMMEvkaWlpVg8tJP32t781xU+LFy+2eigAAJsgUCJk1NbWyqeffioff/yxWbLVNkQaLIcNG0YBTzesX79e6uvr5emnn7Z6KAAAmyBQIuQ0NjaaAh5dDi8uLpZBgwaZYJmbm0sBTxe8+eabcvHiRfne975n9VAAADbBHkqEHC0q0SId7V155swZU8CjZ1Tv2bPHFPBocQ8FPB23DmIPJQDAnwiUCFm6zD1y5EhzXb161cxY6lnV+/fvlylTppgCHm/fRfyJFuW4XC4z06vhHAAAXxEoYQsDBw6Uxx57TObNm2f2WGqjdA2YeXl5Zjk8PT3d6iEGDW+VvNPplMTERKuHAwCwAQIlbCUpKUnuv/9+mTNnjqkK1+rww4cPmzZEGiyzs7PDvoCn5Wk5BEoAgD8QKGHbBt560s706dPl888/N7OVK1euNDOZ3gKecF3u5bQcAIC/EShhaxoatXhHe1eePXvWBMvNmzebAh4Nm5MmTZLY2FgJJwkJCWaWltNyAAD+QqBEWNAANWLECHNdu3bNLIXv3r1b3n333eYCnnBZ/tXWShoqmaEEAPgLfSgRtqqrq00BjzZL10bf3gKejIwMsbt/+7d/k6ysLFm0aJHVQwEA2ACBEmGvrq6uuYBHQ6bOYur+y5ycHNsW8KxZs8ZsB1i+fLnVQwEA2ACBErhJ+zIeP37cNErXZfHMzEwzYzl+/HjbFfBs3bpVSkpK5Pnnn7d6KAAAGyBQArfQH4nCwkITLE+fPm32VmoBz+TJk21TwLN37145cuSI/OQnP7F6KAAAG6AoB7iFLnPrcrdeela4VoZrVfh7771nqsI1XGq/y1BvHaRV3hqe7bqsDwDoPQRKoAN6ws7ixYtl7ty5poDnk08+MY933HGHWQ7XZfFQDZQej0dqa2slPj7e6uEAAEIcgRLo4uky8+fPl9mzZ8uhQ4dMAc/Ro0dl+PDhpoBHH0Nppq/laTkESgCArwiUQDfoHsoZM2aYvpXeAp7Vq1ebmUwNljpzGQoFPC1Py+GccwCArwiUQA+bg2t41Arw8+fPm2C5ZcuW5hN4tIBHj38MhRlKAAB8RaAEfKDL3NnZ2ebSNjxawLNv377mAh6dzQzGAp7o6GgTeDktBwDgD7QNAvxMZ/28BTzaNN1bwDNw4EAJJv/6r/9qmrg/8MADVg8FABDimKEEArA/cd68ea0KeI4dO2baEGmwHDlyZFAU8HhbBwEA4CtmKIEA0/Y8X375pdlneeXKFUlLS2su4NGlZ6ts3rzZHDX5zW9+07IxAADsgUAJ9BL9Ubtw4YIJlidPnjQzhN4Cnj59+vT6eN555x356quv5Ac/+EGvvzYAwF5Y8gZ6iS5zDxs2zFylpaWmgGf//v2tCniSk5N7bTwseQMA/IVACVggNTVVvvGNb8i9994rBw8eNNeBAwdMGyLdZzlo0KBeaR3kdrvN5XA4Av56AAD7YskbCAIa6o4cOWJmLSsqKkwbIg2Wo0aNClgBz7lz52T1q6/Ks8//mfRLTJLIiAjp64iS6MjIgLweAMC+CJRAkBXwnDhxwuyzvHz5spnJ1GA5YcIEvxXwVNfVy7lKl1yudkltY9NtgTUhJkoyE2IlJzleEmNj/PKaAAB7I1ACQUh/LC9evGhmLDVgJiQkmAKeKVOm9LiAx+lukENFVVLscotGyI5+8L3Pp8c7pCAjSRIc7I4BALSPQAkEubKyMhMsdUlcZxMLCgpMAU///v27fA+dkTxSXCX6096dH3gNljqBmZ+eZGYsAQBoC4ESCBFOp7O5gKe2tlbGjRtn+llmZWV1+HUnyq7L8VLfq7lzU/vK2JSvzwAHAKAlAiUQYurr65sLeMrLy2Xo0KEmWI4ePfq2/ZA6M6nL3P4yKSNJspmpBADcgkAJhHABjzZI1wIe3W+ZkpJiCnjy8/NNAY/umdxVWCKeLvyEb3rp17L2X34pQ0aNkX/Ztq/dz4uMELkvO409lQCAVgiUgA14C3j0iEct4Jk6darIsHFSXtfY6Z7JsmtX5AcPzjazm2lZQzoMlDr/mRbvkLuGpPj9ewAAhC6mGQAbGDJkiLl0CVyD5YEjn8uIzNFd+tpX/unvZHT+ZPE0Nkp1ZXmHn6vhVKvEtfUQLYUAAF50MAZsZMCAAbJw4UK5d8ly7T3U6ed/cfAj+ePbb8q3/vpvu/waETf3ZgIA4EWgBGyorK7x634/HWhsbJTf/v1/kflLn5RhY8Z1+d4aU6856/wwSgCAXRAoAZup93jEWd/Y6ee9s26llFy5JMt/9LNuv4bev8Hj6eEIAQB2Q6AEbMbp7jxMXq8ol3X/7/8jy77/Y0ka0LMCm5ouvA4AIDwQKAGb8XRh7+Srv/4n6ZucLA8+/e2Avg4AIDxQ5Q3YTGQneyevFJ6V3RtWm0KciuKi5o+73XXSWF8vxZcuSp++faVfcn+fXgcAED7oQwnYjO5tfOPUn4LirT7/+EP5xXNLO7zHwmefl2///O86/JyHR2VIdCSLHAAAZigB29GQlxAT1W5hztDRY+RnL/72to+v/fU/Sa2zxgTJzCHZHb6G3p8wCQDwIlACNpSZECtnK11tnpKT2D9Fps9/8LaPv/nKy+axredairh5fwAAvJhiAGwoJzm+0yMXe6rp5v0BAPBiDyVgUx9cLJMSl9uvwZKzvAEAbWGGErCpgoykzg7L6Ta9n94XAICWCJSATSU4oiU/3b/hb2J6krkvAAAtESgBG9O9jrmpfX27yc1dMXFVxZLN3kkAQBsIlIDNjU3pZ5apIyO+3gPZHfr5kZERklhTIgd3bJH33nsvQKMEAIQy1q6AMJmpTI93yKGiKil2uU1Q7KhYx/u8FuBoGE1wDJSYmgrZt2+fREdHy6xZs3px9ACAYEegBMJEgiPaVGdX19XLuUqXXHPWtdn8XJuWa59JDaGJsTHNH58zZ440NDTIrl27TKicNm1a734DAICgRaAEwoyGxPyMJMm/eUxjjbtRPE1N5mzuvo72T8CJiIiQuXPnmlC5Y8cOEyonTZrU6+MHAAQfAiUQxjQ8Jsd1fSu1hsr777/fhMpt27ZJVFSU5OdrNAUAhDMCJYBu0VD50EMPSWNjo2zdutXMVI4fP97qYQEALESgBNCjULlo0SITKl977TUzUzl27FirhwUAsAhtgwD0SGRkpCxevFjGjRsnGzdulFOnTlk9JACARQiUAHwKlY899piMGjVK1q9fL2fPnrV6SAAACxAoAfhEl7uXLl0qOTk5sm7dOjl//rzVQwIA9DICJQCfaWHO448/LllZWfLqq6/KpUuXrB4SAKAXESgB+EVMTIysWLFCMjMzZfXq1XL16lWrhwQA6CUESgB+43A45Mknn5TU1FRZtWqVFBUVWT0kAEAvIFAC8KvY2Fh56qmnJCkpSVauXCklJSVWDwkAEGAESgB+16dPH3nmmWekb9++JlSWl5dbPSQAQAARKAEERHx8vAmVOmP5yiuvSGVlpdVDAgAECIESQMDoDOWzzz5rWgvpTGV1dbXVQwIABACBEkBAJSYmmlDp8XhMqKypqbF6SAAAPyNQAgi45ORkEyrdbrcJlU6n0+ohAQD8iEAJoFcMGDDAhEqXy2X6VNbW1lo9JACAnxAoAfQa7U+pobKqqsqEyhs3blg9JACAHxAoAfSq9PR0U/2trYT0mEZdBgcAhDYCJYBeN3DgQNP8XE/SWbt2rdTX11s9JACADwiUACwxePBgEyovX74s69evl4aGBquHBADoIQIlAMsMHTpUVqxYIefPn5eNGzdKY2Oj1UMCAPQAgRKApXJycuSJJ56QM2fOyGuvvWb6VQIAQguBEoDlRo4cKcuWLZOvvvpKtmzZQqgEgBBDoAQQFMaMGSOPPfaYfP7557Jt2zZpamqyekgAgC6K7uonAkCgjR8/3uyjfP311yU6OloeeughiYiIsHpYAIBOECgBBJUJEyaYim+dpYyKipIFCxYQKgEgyBEoAQSdSZMmmZnKt956y8xUzps3j1AJAEGMQAkgKE2dOtXMVL7zzjsSExMjd999t9VDAgC0g0AJIGjNnDnThMq9e/ea5e+77rrL6iEBANpAoAQQ1GbPnm1C5Z49e8zy94wZM6weEgDgFgRKAEHvnnvuMaHy7bffNqFyypQpVg8JANACgRJA0NOCnPnz55tQ+eabb5pQOXHiRKuHBQC4iUAJIGRC5QMPPGBC5RtvvGH2VObl5Vk9LAAAgRJAqIXKRYsWtWp+Pm7cOKuHBQBhj6MXAYRcqHz44YfNqTqbNm2SkydPWj0kAAh7BEoAIScyMlIeeeQRGT16tGzYsEHOnDlj9ZAAIKwRKAGEJN1DuXTpUhk+fLisW7dOCgsLrR4SAIQtAiWAkA6Vjz/+uAwdOlReffVVuXjxotVDAoCwRKAEENK0MOeJJ56QQYMGyZo1a+TKlStWDwkAwg6BEkDIczgcsmLFCklLS5NVq1bJtWvXrB4SAIQVAiUAW4iNjZWnnnpK+vfvb0JlSUmJ1UMCgLBBoARgG3FxcfL0009Lv379ZOXKlVJWVmb1kAAgLBAoAdhKfHy8PPPMMyZcvvLKK1JRUWH1kADA9giUAGwnISFBnn32WYmJiTEzlVVVVVYPCQBsjUAJwJZ02VtDpdJQef36dauHBAC2RaAEYFtJSUkmVDY0NJhQ6XQ6rR4SANgSgRKArWnVt4bKGzdumFDpcrmsHhIA2A6BEoDtpaSkmFBZU1Mjq1evNuESAOA/BEoAYUGbnmv1t1Z964k6dXV1Vg8JAGyDQAkgbGRmZpo+ldr0fO3atVJfX2/1kADAFgiUAMJKVlaWOVFHz/xet26dKdgBAPiGQAkg7AwZMkSefPJJuXDhgmzYsEEaGxutHhIAhDQCJYCwlJ2dLcuXL5ezZ8/Kpk2bCJUA4AMCJYCwNWLECHn88cfl5MmT8vrrr4vH47F6SAAQkgiUAMLa6NGjZenSpXL8+HF54403pKmpyeohAUDIIVACCHvjxo2TRx99VI4cOSLbt28nVAJAN0V39wsAwI7y8vLMPsqtW7dKdHS0PPDAAxIREWH1sAAgJBAoAeCmiRMnmjZCb775pgmV8+fPJ1QCQBcQKAGghSlTpphQ+fbbb5tQee+991o9JAAIegRKALjFjBkzzPL37t27TaicPXu21UMCgKBGoASANtx5551mpnLv3r0mVM6cOdPqIQFA0CJQAkA75syZY877fueddyQqKkqmTZtm9ZAAICgRKAGgHVqQM2/ePDNTuWPHDjNTOWnSJKuHBQBBh0AJAJ2EygULFpg9ldu2bTOhcsKECVYPCwCCCoESALoQKh966CEzU7llyxaz/D1+/HirhwUAQYNACQBdDJXf+MY3zEzl5s2bzUzlmDFjrB4WAAQFjl4EgC6KjIyURx55xATJjRs3yunTp60eEgAEBQIlAHQzVC5ZskRGjBgh69evl3Pnzlk9JACwHIESALpJ91AuW7ZMhg0bJmvXrpULFy5YPSQAsBSBEgB6QPdQPvHEE5KVlSVr1qyRy5cvWz0kALAMgRIAeigmJkZWrFghGRkZsnr1arl69arVQwIASxAoAcAHDodDnnzySRkwYICsWrVKiouLrR4SAPQ6AiUA+CguLk6efvppSUpKkpUrV0ppaanVQwKAXkWgBAA/6NOnjwmV8fHxJlSWl5dbPSQA6DUESgDwk4SEBHn22WfNMriGysrKSquHBAC9gkAJAH7Ut29fEyr1ZB0NldXV1VYPCQACjkAJAH6WmJgozz33nDmmUUNlTU2N1UMCgIAiUAJAACQnJ5tQWVdXZ6q/XS6X1UMCgIAhUAJAgGgrIQ2VTqfThMra2lqrhwQAAUGgBIAASk1NlWeeeUaqqqrMiTo6YwkAdkOgBIAA05N0NFRqf0oNlW632+ohAYBfESgBoBcMHDjQ9KksKiqStWvXSn19vdVDAgC/IVACQC8ZPHiwOabx8uXLsmHDBmloaLB6SADgFwRKAOhFw4YNk+XLl8u5c+dk06ZNprUQAIQ6AiUA9LLhw4fLE088IadOnZLNmzeLx+OxekgA4BMCJQBYYNSoUbJs2TI5ceKEbNmyhVAJIKQRKAHAImPHjpXHHntMPv/8c9m+fbs0NTVZPSQA6JHonn0ZAMAfxo8fb4pzdJYyKipKHnroIXMOOACEEgIlAFgsPz/fhEqdpYyOjpb777+fUAkgpBAoASAITJ482VR879ixQ2JiYmTu3LlWDwkAuoxACQBBYtq0aWamcteuXWamcs6cOVYPCQC6hEAJAEFk1qxZJlTu27fP7Km88847rR4SAHSKQAkAQUZnJjVU7t6928xUTp8+3eohAUCHCJQAEITuvfdeEyp37txpQqXusQSAYEWgBIAgpFXe9913X6vqb60GB4BgRKAEgCAOlQ8++KAJlVu3bjV7Ku+44w6rhwUAtyFQAkCQh8pFixaZlkJ67reGynHjxlk9LABohaMXASDIRUZGyuLFiyU3N1c2bdokp06dsnpIANAKgRIAQiRUPvroozJq1ChZv369nD171uohAUAzAiUAhAhd7l66dKnk5OTI2rVr5fz581YPCQAMAiUAhBCt9n788cdlyJAh8uqrr8rFixetHhIAECgBINToWd/Lly+XzMxMWbNmjVy5csXqIQEIcwRKAAhBDodDnnzySUlNTZXVq1dLUVGR1UMCEMYIlAAQomJjY+Xpp5+W5ORkWblypZSUlFg9JABhikAJACEsLi7OhMq+ffuaUFlWVmb1kACEIQIlAIS4+Ph4eeaZZ0y41FBZUVFh9ZAAhBkCJQDYgM5QPvvss6a1kIbKqqoqq4cEIIwQKAHAJvr16yfPPfecNDU1mVB5/fp1q4cEIEwQKAHARpKSksxMZX19vaxatUqcTqfVQwIQBgiUAGAzAwYMMKHS5XKZUFlbW2v1kADYHIESAGxI+1NqqNRlb+1TeePGDauHBMDGCJQAYFPp6emm+ru8vNycqFNXV2f1kADYFIESAGxMj2fUPpXFxcWydu1as7cSAPyNQAkANpeVlSVPPfWUOfN73bp10tDQYPWQANgMgRIAwsDQoUNlxYoVcuHCBdm4caM0NjZaPSQANkKgBIAwkZOTI0888YScOXNGXnvtNfF4PFYPCYBNECgBIIyMHDlSli1bJl999ZW8/vrrhEoAfkGgBIAwM2bMGFmyZIl88cUXsm3bNnOyDgD4gkAJAGEoNzdXHn30UTl8+LC8+eabhEoAPon27csBAKEqLy/PVHy/8cYbEh0dLQsWLJCIiAirhwUgBBEoASCMFRQUmFD51ltvmVA5b948QiWAbiNQAkCYmzp1qgmV77zzjgmV99xzj9VDAhBiCJQAAJk5c6bpTblnzx4TKu+66y6rhwQghBAoAQCGhkidqfSGyhkzZnT4+Q0ej9S4G8XT1CSRERHS1xEl0ZHUegLhiEAJAGh29913m1D59ttvS1RUlFkOb6m6rl7OVbrkmrNOnPW3n7aTEBMlmQmxkpMcL4mxMb04cgBWIlACAJppQY4W5tTX1zcX6mjhjtPdIIeKqqTY5RYt2WmvyZCGzLOVLjlT6ZL0eIcUZCRJgoO3GsDuIppoPgYAuIW+NWh/yk8//VTmLV0hpTH9RN8tuvOGocFTC8bz05PMjCUA+yJQAgDapG8PW/5wUJrShugfvk6HPZSb2lfGpvTz6/gABA92TwMA2lRYVft1mFQ+9qY8XlojhZUu/wwMQNBhYwsA4Da6Z/JIcVWbz1049ZVsePF/ypkvjkplabHExvWRwSNHy+Jvf1+mzr2/3XseLq6StHgHeyoBG2KGEgBwGy3AaW9DVMmVS1LrrJF7H1km3/75/y1L/+NPzMf/+3/8pryzfnW799T76X0B2A97KAEAt7UG2l1Y2q2v0aboP1uyQNx1dfK/drzf4efOz06lpRBgM8xQAgBa0T6T3d0xqT0rUzIHiet6dYefF3Hz/gDshY0sAIBWtGl5V5aubrhc4q6rFdf163Jw7zty6P19cueDD3f4NU0375/vt9ECCAYESgBAs3qPp80TcNryyi//Vt5Zv8r8d2RkpEy/7yF5/m/+odOv0/vrsY0c0wjYB4ESANDM6e5amFQLn3teZixYKBXFRfLhjm3i8TRKQ319l75WzwBPjiNQAnZBUQ4AoFl5rVv2Xyjr0df+3beXi/N6tfz3DW+aIxw7cs/QFBnQx9HDUQIINvx6CABoFulDA/MZCxbJ6WOH5cq5MwF9HQDBh0AJAGjW1xHV4691190wj66a6wF9HQDBh0AJAGimhTIJMR2Hvaqy23tU6t7Jd7dsFEdcnAweMbrDr9f7U5AD2AtFOQCAVjITYuVspavd1kEv/eJnUltTI7lTpsuAjEypLC2R97ZtlstnT8tz/+kX0ichod17N3k8UltcJKWJkZKamhqw7wFA76IoBwDQrZNyPnhzi+x5ba1cOHlCrldWSJ+EvjJ8fJ489PS3ZercBZ3e/9L+7VJx7YqMGTNGZs6cKUOHDu20iAdAcCNQAgBu88HFMilxubvU4LyrNDKmxTtkxsAkOXbsmPzxj3+UkpISycrKMsFy3Lhxpp8lgNBDoAQA3MbpbpBdhSXi8eM7RGSEyH3ZaZLg+Hq3lb79nD59Wj788EMpLCyU5ORkmTFjhhQUFIjDQUshIJQQKAEAbdIztw8VVfntfpMykiQ7Ob7N565cuWJmLL/44guJjY2VqVOnyrRp06Rv375+e30AgUOgBAC060TZdTleWuPzfXJT+8nYlM7DYWVlpXz88cfy2WefSWNjo0yYMMEsh6elpfk8BgCBQ6AEAHQ6U3mkuEr03aKpm3smtdZmYnr7M5PtuXHjhnz66acmXF6/fl1GjRols2bNkmHDhlHAAwQhAiUAoEt7KnX5u9jlNkGxozcO7/Pp8Q4pyEhq3jPZEzpL+fnnn5t9lsXFxTJw4EATLHNzcyngAYIIgRIA0K2WQjpjec1ZJ876xjablmsfy5zkeEmMjfHb6+pb1ZkzZ8w+y7Nnz0pSUlJzAY/uuQRgLQIlAKBHGjweqXE3SlFJiWzZvFmeWrZEBg8aGPDXvXbtmgmWOnOp1eCTJ0+W6dOnS79+/QL+2gDaRqAEAPikurpafvWrX8mKFStk9OiOj130p6qqKrPHUvdaNjQ0NBfwpKen99oYAHyNoxcBAD5JuHnUYk2N79Xg3aHL3vfff7/MmTPHVIVruDx8+LCMHDnSBMucnBwKeIBeQqAEAPgkKipK4uPjez1QesXFxZlCHV321j6WWsCzatUqyczMbC7g0TECCByWvAEAPnvppZdkyJAhsnDhQquHYgp4zp07Z4KlFvIkJiaaAp5JkyZRwAMECDOUAACf6Yk2Vs1Q3kqXuYcPH26uoqIiU8Cze/dueffdd5sLeDRkAvAfZigBAD7bsmWLlJWVyXe+8x0J1sKhAwcOyCeffCL19fVyxx13mH2WuiwOwHfMUAIA/DJDef78eQlWOiM5f/58mT17dnMBz9GjR80spu6z1EcKeICeI1ACAHymPSD1iERd9ArmYKZ7KHVmctq0aXL8+HGzHL569WrJyMgwH9eZSwp4gO4jUAIA/DJDqcck6hncffr0kWCnoTEvL88EyMLCQhMsddl+z549Zo+l7rXU6nEAXUOgBAD4zHtKjRbmhEKg9NLZVO1XqZeeFa7Bct++ffLee++ZqnCtDtd+lwA6RqAEAPhlhtIbKNPS0iQU6Qk7ixcvlrlz5zYX8OheS28Bz8CBgT9WEghVBEoAgN8Cpe6jtMNs67x580wBz6FDh+Sjjz6SY8eOmVlMLeAZMWJEUO8TBaxAoAQA+MzhcJgrWHpR+oN+P7qfcurUqfLll1+aRulr1qwxM5neAp7oaN5GAcVPAgDAr5XedhMZGSnjx483RzheuHDBBMutW7e2KuAJpX2jQCAQKAEAtjstJxB0mXvYsGHmKi0tNQU8+/fvb1XAk5ycbPUwAUtwUg4AwC82bdokTqdTnnvuOQkXGqAPHjxoLm2ZpLOYus9y0KBBVg8N6FUESgCAX+zcuVPOnDkjL7zwgoQbt9sthw8fNgU8FRUVkp2dbfZZjho1igIehAWWvAEAfmHXPZRdLeDR03emTJkiJ06cMPss165dK6mpqSZYTpgwgQIe2Br/dwMA/LaHsq6uTurr6yUmJkbCkRbw6LL3uHHj5OLFi2af5bZt22Tv3r3NgTM+Pt7qYQJ+R6AEAPi9uXn//v0lnOky99ChQ81VVlZmguX7778vH3zwgUycONHMWob73xHshUAJAPD78YuEpT9JSUmRRYsWyb333ttcwKOn8OgsphbwZGVlWT1EwGcESgCAX9jptJxASEhIkHvuuUfuvPNOOXLkiJm1fPnll80spgbL0aNHU8CDkEWgBAD4hTb31j2Edu5F6Q+6v1T3UmrvypMnT5oCnnXr1pmZTG8BT7juQUXoIlACAPxCZ9d0lpIZyq7R8D127FhzeQt4tm/f3lzAo0c+UsCDUEGgBAD4dR8lM5TdN2TIEHOVl5ebYKnFOy0LeAYMGGD1EIEO0dgcAOA3unTb2NgoTz31lNVDCWkul8sU7xw4cMD8txbwaLDU0AkEIwIlAMBvdMn28uXL8t3vftfqodiC9vQ8evSombXU9kMaKDVYjhkzxiyZA8GCJW8AgN+E82k5gaDFOZMnT24u4NFguWHDBrMEPmPGDLMkTgEPggGBEgDgN1qUo0u0Ho+HGTQ/FzzprKReOgOswXLHjh2yb98+U7yjRTzalgiwCoESAODXQKk7qZxOZ3Ojc/iXNkJfunSpVFRUyEcffWTCpbYeys/PN7OWen440NsIlACAgJyWQ6AMLD2N6MEHHzTN0vXknY8//lg+/fRTM4upjdJ1vyWN0tFbCJQAgICcljNw4ECrhxM2DeVnz55tinWOHTtmZiv//d//3cxkarDUPpdsP0CgESgBAH7j3cdHL8reFx0dLQUFBaZQ5/Tp0yZYbty40cxkegt4HA6H1cOETREoAQB+ExUVZU53IVBaR5e5R40aZa4rV66YPZY7d+6U/fv3myMftYDHO5MM+At9KAEAfvXSSy+Z/XsLFy60eii4qbKy0hTwfPbZZ6YCX88L1yXytLQ0q4cGmyBQAgD8avXq1aY34hNPPGH1UHCL2tpaU7ijBTw6izx69GgTLIcNG0YBD3xCoAQA+NXWrVultLRUvvOd71g9FLRDj8fUAh5dDi8uLpZBgwaZYJmbm0sBD3qEQAkA8Kvdu3fLF198IT/60Y+sHgo6oRHgzJkzpoDn3LlzkpycbAp4tLiHAh50B0U5AICAHL+oYYVl1OCm/z4jR44019WrV82M5dtvv92qgId+ougKAiUAwK+0gliXVG/cuGF6JCI0aN/Qxx57TObNm2f2WB44cMDMXHoLeNLT060eIoIYgRIAELDTcgiUoScpKUnuv/9+mTNnjqkK1+rww4cPm1lMbZSenZ3NzDNuQ6AEAPiVt8ehBkra0oSuuLg4EyCnT59u9sTqbOXKlSvNTKa3gEf7jgKKQAkACNjxiwh9Ghp12TsvL0/Onj1r9llu3rxZ9uzZY8LmpEmTJDY21uphwmIESgCAX2l1sF6clmMvusw9YsQIcxUVFZlgqRX97777rkyePNmEy8TERKuHCYvQNggA4HcvvviiOfpvwYIFVg8FAVRdXW0KeLRZen19vZnF1OXwjIwMq4eGXkagBAD43e9//3tTnLNkyRKrh4JeUFdX11zAoyFTZzF1/2VOTg4FPGGCQAkA8LtNmzaJ0+mU5557zuqhoBdpu6jjx4+bAp5r166ZmUoNluPHj6eAx+YIlAAAv9u5c6c5geWFF16weiiwgEaLwsJCEyxPnz5t9lZ6C3i0ehz2Q1EOACBgp+UgPOkyty5366VnhWsBj1aFtyzg0X6XsA8CJQAgIK2DdF+dFmrExMRYPRxYSE/YWbx4scydO9ecvvPJJ5+YQh5dBtcCHu1ridBHoAQABLS5ef/+/a0eDoJk1lqPdZw9e7YcOnTIFPAcO3bMzGLqPkst5KGAJ3QRKAEAAT1+kUCJlrRHqS55T506Vb788kuzz3LNmjVmJlNnLLX1EAU8oYdACQDwO07LQWciIyPNsrce4Xj+/Hmzz3Lr1q2yd+9emTZtmkyZMoUCnhBCoAQA+F2fPn3MLBOn5aAzusydnZ1trpKSEhMs9+/fL++//74UFBTIjBkzJDk52ephohMESgBAQEKCzlIyQ4nuSEtLk4cffrhVAY8+egt4Bg0aZPUQ0Q76UAIAAuLll182AUErfIGecLvdcvjwYVPAU1FRYWYxtYBn5MiRFPAEGQIlACAg1q1bZ05Oeeqpp6weCkKcx+OREydOmAKey5cvm19UvAU80dEstgYDAiUAICC2b99u3vy/+93vWj0U2IRGlosXL5pg+dVXX5ltFd4CHt23C+sQ6wEAAcFpOfA3XeYeOnSouUpLS81SuJ6+07KAhzZV1iBQAgACQmePXC6XWa7UFjGAP6WmpsqiRYvk3nvvlYMHD5riHX3UNkS6HJ6VlWX1EMMKgRIAELBAqUuUTqezudE54G8JCQlyzz33yJ133ilHjhwxbYe0IGzYsGEmWI4ePTogBTwNHo/UuBvF09QkkdrVwBEl0WH8ixOBEgAQ8NNyCJQIND0zXvdSTpo0yeyv1GCphWEpKSkmWObn5/tcwFNdVy/nKl1yzVknzvrG255PiImSzIRYyUmOl8TY8DrDnqIcAEBAVFdXy69+9StZsWKFmSUCepsW8Giw1CMedSZTj3vUKz4+vlv3cbob5FBRlRS73KJznR0Fp4ibz6fHO6QgI0kSHOExdxce3yUAoNfpG7jitBxYZciQIeYqLy83wfKDDz4wl7eAZ8CAAZ3eQ2ckjxRXiXf6rbNZuKabjyUut+wqLJH89CQzY2l3BEoAQEDo0Ys6E0SghNU0OC5cuPC2Ap5x48aZRumDBw9u8+tOlF2X46U9+/+3ybQ5EjOzWdfYKGNT7L3tgyVvAEDAvPTSS2aGSN/MgWBRX18vR48eNbOWZWVl5v9RDZa6NcPbkUBnJjUM+sukjCTJtvFMJTOUAICAVnozQ4lgLOCZPHmyKeA5efKkaZS+fv16M5OpBTyjcu8wy9ztqXU6Zetv/7ecOnpITh87LDVVlfLCf/uVzH3siXa/5nBxlaTFO2y7p9Ke3xUAIChodbc2oAaCkbYTGjNmjLkuXbpkZizfeustGV4bIfFpA/UT2vy66xXlsvF//0pSB2XJsDG58sWBDzt9Le/y911DUsSOCJQAgIAW5hQWFlo9DKBTuo9y2bJlcqmkTA6Uuzv83P7p6fLy+4elf1q6nD52RP7Tsgc7vb/uL9QqcW09ZMeWQuHbgRMA0GvHL7JdH6GizBNtWv90JMYRa8Jkd0Xc3JtpRwRKAEBA91A2NjbKjRs3rB4K0CXatDxQv/403by/HREoAQC9cloOEOzqPZ42T8DxJ2d9ozm20W4IlACAgM5QKl32BoKd0x3YMOmlZ4DbDYESABDwQMkMJUKBp5f2+npsuKeYQAkACBiHw2EuAiWCnc6iX7hwvldeK7KddkShjLZBAIBeqfQGgoXT6ZQrV66Y6+rVq+ZR/x+NjI6W3CXfMv0pA6mvI0rshkAJAAgoTsuBlVwuV3No9F7V1dXmubi4OBk0aJDk5+ebx4EDB8rH5e6AFuYkxERJ9M3jHe2EQAkACCgCJXqLtqe6NTxWVlaa52JjY01gvOOOO0x41Cs5Ofm22cjMuio5W+nqtHXQW6t/J67r1VJeXGT+/Mm+XVJedNX894NPf1sS+iXe9jX6SpkJsWJHBEoAQMADZVHR12+6gL/U1dU1h0fvY3l5efNZ3RoYx44d2xwe9Zzurixl5yTHy5kuNB9/43cvScmVS81//njXW+ZSc76xpM1A2XTz/nZEoAQABBR7KOErt9st165daxUevWfER0dHm5nHkSNHNofHlJQUiezhsrIei5ge75ASl7vDWcqX9h7o1n0jRCQt3mHLYxcVgRIAEPAZSp1Nqq+vNzNHQEf0/xOd0W4ZHktKSszxnVFRUZKZmSk5OTly5513miCZlpbW4/DYnoKMJNlVqK/pv3tGRHx9X7siUAIAeq0XZf/+/a0eDoJIQ0ODFBcXt9rzqH/W8KghMSMjQ4YMGSLTp083M48aHjVUBlqCI1ry05PkUFGV3+45MT3J3Neu7PudAQCC7vhFAmX40jPdNSy2LJrRmUiPx2P2Nmp41NA4ZcoU85ienm6Ws62iex3rGhvleKnvBWW5qf0k26Z7J70IlACAgOL4xfCjIVGXqVv2etQ9kBoqNTzqTKOGxokTJ5pHDZPBuB1ibEo/iY2KkiPFVWb5u6mbeyYjIr6embR7mFQESgBAQPXp08csU9I6yL7hsaysrFV41EuXs1VqaqoJjXl5eWbPo+6B1NOTQoXOVGqRji5/F7vcJih2FCwjbj6vBTi6ZzLBxsvcLYXHdwkAsIzOSOksJTOUoU/3NmprnpZ7HjU8aiGN0tY8Gh7HjRtnHjU8av/HUJfgiJa7hqRIdV29nKt0yTVnXZvNzxNiokyfSQ2hdq3mbg+BEgAQcDQ3D83wqE3Bbw2PWrGvdD+szjjefffdzafM6MkzdqYhMT8jSfK1oMjjkRp3o3i0gCgiwhynaMcTcLqKQAkACDgCZfCHx6qqqtvOt9aTZ1RSUpIJjdqqxxse4+Ptvy+wIxoek+PCN0DeikAJAOiVQHn58mWrh4Gb4VG3H9waHvXMa29VvobGGTNmNDcKT0hIsHrYCHIESgBAwHFajnV0ZvjW8OidLdagqIFx6tSpzTOP3jZPQHcQKAEAvTJD6XQ6TUWwv081wZ/o33HLPo96eYO8VttraCwoKGieedTw2JXzrYHOECgBAL3Wi1IDDzNg/lFbW3tbeNR9kEqLYzQwTpgwoTk86j5IwiMChUAJAOjV03IIlN2nxTHe8Oh9rKioMM9pT0cNjLm5uc3hUSuwCY/oTQRKAECvnpaj+/TQPrfbfVt41MbhSk+T0b+/MWPGNIdH7f1IeITVCJQAgIDzVgnTOqg1bQiuRxK2XLYuLS01z+k51toYfMSIETJ79mwTHlNSUtiDiqBEoAQABJwevah9C8M5UOpRhEVFRa3Co553rW189O9Hw2N2drbMmjXLhEc975rwiFBBoAQA9IrE5GSpqmuQ8lq37U8WaWxsbBUedem6uLi4uco9IyNDBg8eLNOmTTPhMT093YRKIFRFNOmvRgAABEDLs49r3A237fWzw9nHGh51prFleNQwqR/X71fDone/ozc86nI2YCcESgCA3zndDXKoqEqKXW7RCNnRG433+fR4hxRkJEmCI3jDls4w6h7HluFR90DqcraGx9TU1FbhUWcitZAGsDsCJQDAr3RG8khxlei7S3feYDRY6gRmfnqSmbG0mr49anV1yz2PGh61kEZ5w6NWXeuj7oHUFj5AOCJQAgD85kTZdTle6nvhTW5qXxmb0nv9KvWtsLy8vFWrHn3UFj5KW/O0DI/6GBsb22vjA4IdgRIA4LeZSV3m9pdJGUmSHYCZSn3bq6ysvO1867q6OvN8cnLybeFRjy0E0D4CJQDAL3smdxWWiKeNd5TTxw7Lvtc3yOcHPpSSyxelX3J/GZU/WZ780c9kUM6Idu8ZGSFyX3aaT3sq9S2uurr6tvCoxxaqxMTEVnseNTxqeyMA3UOgBAD47IOLZVLicre5Z/J//PA/yIlDB2XWgkUybMw4qSwtkR1r/l1uuJzyj+u2y9DRY9vdU5kW75C7hqR0eRx6Ek/LPY96uVwu85we+XjrzKP3BB8AviFQAgB8bg20u/Dr013acuKzgzLijnyJaVGwcqXwrPz04Xkyc8FC+dH/eLHD+8/PTm2zpZA2SffOOHovb+N0nWXMyspqDo96cYY4EDjB25sBABAyeyc7ag00dtLU2z42KHu4DBk5Wi6dOdXhvSNu3n9Uv5jblq11KVvp/kYNjBMnTmwOj7qUzfnWQO8hUAIAfKJNy5t6UhhTVmpCZYefpzOcl4tky7a15s9aWa2BMS8vrzk8JiUlER4BixEoAQA9Vu/xiLO+sdtf9962zVJedFWW//AvO/3cmPi+8uiSJTJ40CDp378/4REIQgRKAECPOd3dD5OXzp6Sl//u5zJm4mS555HHO/+CiAgZOnKMJMdx4gwQrCKtHgAAIHR5ulnXWVFSLP/tu89KfL9+8pe//o1ERUUF5HUA9C5mKAEAPRbZjeVn5/Vq+Yc/e0qc1dXy92telwEZmQF5HQC9j0AJAOixvo6uzTC6627IP37/OdMu6Be/W99pMU5PXweANVjyBgD0WHRkpCTEdBz2Ghsb5Z9/8j05efhT+Yt/+f9lTMGUbr2G3l9fB0DwYoYSAOCTzIRYOVvpard10Cu//Fs5uPcdmXLvfVJTVSnvvvFaq+fvfnhJu/eOuHl/AMGNQAkA8ElOcrycqfz6eMO2FH75hXn8ZN8uc92qo0DZdPP+AIIbRy8CAAJ6lndP9eQsbwDWYFMKAMBnBRl6Wo1/76n30/sCCH4ESgCAzxIc0ZKf7t/wNzE9ydwXQPAjUAIA/EL3Ouam9vXLvXJT+0k2eyeBkMEeSgCAX52rdMmR4irRd5fuvMFE3Fzm1plJwiQQWgiUAAC/c7ob5FBRlRS73CYodvRG430+Pd5h9kwmsMwNhBwCJQAgYKrr6s2M5TVnnTjrG9tsWq59JnW5PDE2xpIxAvAdgRIA0CsaPB6pcTeKp6nJnM2txylyAg5gDwRKAAAA+IRfDQEAAOATAiUAAAB8QqAEAACATwiUAAAA8AmBEgAAAD4hUAIAAMAnBEoAAAD4hEAJAAAAnxAoAQAA4BMCJQAAAHxCoAQAAIBPCJQAAADwCYESAAAAPiFQAgAAwCcESgAAAPiEQAkAAACfECgBAADgEwIlAAAAfEKgBAAAgE8IlAAAAPAJgRIAAAA+IVACAADAJwRKAAAA+IRACQAAAJ8QKAEAAOATAiUAAAB8QqAEAACATwiUAAAA8AmBEgAAAD4hUAIAAMAnBEoAAAD4hEAJAAAAnxAoAQAA4BMCJQAAAHxCoAQAAIBPCJQAAADwCYESAAAA4ov/Az0SWOZ5bjEPAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "# Community 1\n",
    "G.add_edges_from([(1,2),(2,3),(3,1)])\n",
    "# Community 2\n",
    "G.add_edges_from([(4,5),(5,6),(6,4)])\n",
    "# Weak bridge\n",
    "G.add_edge(3,4)\n",
    "\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "nx.draw(G, pos, with_labels=True, node_color=\"lightblue\", edge_color=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: {1, 2, 3}, 6: {4, 5, 6}}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphing = label_propagation(G, 50)\n",
    "graphing.propagation()\n",
    "graphing.get_communities('dict')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
