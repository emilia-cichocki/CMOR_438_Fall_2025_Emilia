{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import *\n",
    "import sys\n",
    "sys.path.append('/Users/emicatx/Downloads/CMOR_438_FALL_2025_Emilia/src')\n",
    "from rice_ml.preprocess.datatype import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ArrayLike = Union[np.ndarray, Sequence[float], Sequence[Sequence[float]], pd.DataFrame, pd.Series]\n",
    "\n",
    "def _ensure_numeric(data_vector: ArrayLike, name: str = 'Data') -> np.ndarray:\n",
    "\n",
    "    # TODO: docstrings, type hints, and examples\n",
    "\n",
    "    vector = _1D_vectorized(data_vector, name)\n",
    "    \n",
    "    if not np.issubdtype(vector.dtype, np.number):\n",
    "        try:\n",
    "            vector = vector.astype(float, copy = False)\n",
    "        except (TypeError, ValueError) as e:\n",
    "            raise TypeError(f'All entries in {name} must be numeric') from e\n",
    "    else:\n",
    "        vector = vector.astype(float, copy = False)\n",
    "\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array = np.array([True, False, True, False])\n",
    "_ensure_numeric(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1, 1, 1]\n",
    "_1D_vectorized(x, 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(data_vector_1: ArrayLike, \n",
    "                       data_vector_2: ArrayLike, \n",
    "                       name_1: str = 'data_vector_1', \n",
    "                       name_2: str = 'data_vector_2') -> float:\n",
    "    \n",
    "    # TODO: docstrings, type hints, and examples\n",
    "\n",
    "    vector_1 = _ensure_numeric(data_vector_1, name_1)\n",
    "    vector_2 = _ensure_numeric(data_vector_2, name_2)\n",
    "\n",
    "    _shape_match(vector_1, vector_2)\n",
    "\n",
    "    distance = float(np.linalg.norm((vector_2 - vector_1)))\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(data_vector_1: ArrayLike, \n",
    "                       data_vector_2: ArrayLike, \n",
    "                       name_1: str = 'data_vector_1', \n",
    "                       name_2: str = 'data_vector_2') -> float:\n",
    "    \n",
    "    vector_1 = _ensure_numeric(data_vector_1, name_1)\n",
    "    vector_2 = _ensure_numeric(data_vector_2, name_2)\n",
    "\n",
    "    _shape_match(vector_1, vector_2)\n",
    "\n",
    "    distance = float(np.sum(np.abs(vector_2 - vector_1)))\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowski_distance(data_vector_1: ArrayLike, \n",
    "                       data_vector_2: ArrayLike, \n",
    "                       p: int,\n",
    "                       name_1: str = 'data_vector_1', \n",
    "                       name_2: str = 'data_vector_2') -> float:\n",
    "    \n",
    "    if not isinstance(p, int):\n",
    "        raise TypeError('p parameter must be an integer')\n",
    "    if p <= 0:\n",
    "        raise ValueError('p parameter must be greater than zero')\n",
    "    \n",
    "    vector_1 = _ensure_numeric(data_vector_1, name_1)\n",
    "    vector_2 = _ensure_numeric(data_vector_2, name_2)\n",
    "\n",
    "    _shape_match(vector_1, vector_2)\n",
    "\n",
    "    distance = float((np.sum((np.abs(vector_2 - vector_1)) ** p)) ** (1 / p))\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [-1, -2]\n",
    "b = [2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.497941445275415"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distance(a, b, 'a', 'b')\n",
    "manhattan_distance(a,b)\n",
    "minkowski_distance(a, b, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1 = pd.Series([1, 1, 1])\n",
    "\n",
    "output = _ensure_numeric(input_1)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_query = np.array([[1, 2], [3, 4]])\n",
    "X_train = np.array([[4, 6], [0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _distance_calculations(training_array: np.ndarray, query_array: np.ndarray, metric: str, p: Optional[int] = 3) -> np.ndarray:\n",
    "\n",
    "    # TODO: docstrings, examples (query is row, training is column)\n",
    "\n",
    "    query_array = _2D_numeric(query_array)\n",
    "    training_array = _2D_numeric(training_array)\n",
    "\n",
    "    distance_matrix = np.full((query_array.shape[0], training_array.shape[0]), np.nan)\n",
    "    for index_1, point_1 in enumerate(query_array):\n",
    "        for index_2, point_2 in enumerate(training_array):\n",
    "            if metric == 'euclidean':\n",
    "                distance = euclidean_distance(point_1, point_2)\n",
    "            elif metric == 'manhattan':\n",
    "                distance = manhattan_distance(point_1, point_2)\n",
    "            elif metric == 'minkowski':\n",
    "                distance = minkowski_distance(point_1, point_2, p = p)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported metric: {metric}\")\n",
    "            distance_matrix[index_1, index_2] = distance\n",
    "\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _neighbor_finding(training_array: np.ndarray, query_array: np.ndarray, k: int, metric: str, p: Optional[int] = 3) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    # TODO: docstrings and examples, potentially add further checks for other inputs\n",
    "\n",
    "    if k > training_array.shape[0]:\n",
    "        raise ValueError(f'Number of neighbors (k = {k}) cannot be greater than number of training samples ({training_array.shape[0]})')\n",
    "    \n",
    "    distance_matrix = _distance_calculations(training_array, query_array, metric = metric, p = p)\n",
    "    indices = np.argpartition(distance_matrix, kth = k - 1, axis = 1)[:, 0:k]\n",
    "\n",
    "    query_indices = np.arange(distance_matrix.shape[0])[:, None]\n",
    "    neighbor_distances = distance_matrix[query_indices, indices]\n",
    "    ordering = np.argsort(neighbor_distances, axis = 1)\n",
    "    sorted_indices = indices[query_indices, ordering]\n",
    "    distances_sorted = neighbor_distances[query_indices, ordering]\n",
    "\n",
    "    return distances_sorted, sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = np.array([1, 2, 3])\n",
    "two = np.array([1, 2, 4])\n",
    "\n",
    "overlap = (one == two).astype(float)\n",
    "mean_accuracy = float(np.mean(overlap))\n",
    "mean_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3]\n",
      " [3 4]]\n",
      "[[0.5 1. ]\n",
      " [1.  2. ]]\n",
      "[[1. 3.]\n",
      " [3. 8.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2. , 5.5])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array([1, 2, 3, 4])\n",
    "indices = np.array([[1, 2], [2, 3]])\n",
    "n_neighbor = np.array([[0.5, 1], [1, 2]])\n",
    "print(labels[indices])\n",
    "print(n_neighbor)\n",
    "weighted = labels[indices] * n_neighbor\n",
    "print(weighted)\n",
    "(np.mean(weighted, axis = 1)).astype(float, copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay\n",
      "(array([0, 0]), array([1, 2]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 3])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = np.array([[0, 1, 1]])\n",
    "targets = np.array([[1, 2, 3]])\n",
    "if np.any(weight == 0).astype(bool):\n",
    "    print('yay')\n",
    "\n",
    "print(np.where(weight != 0))\n",
    "targets[np.where(weight != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.41421356 1.41421356]\n",
      " [1.         2.23606798]]\n",
      "[[0 1]\n",
      " [1 2]]\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([\n",
    "    [0, 0],\n",
    " [2, 2],\n",
    " [1, 3]\n",
    "])\n",
    "\n",
    "# Query data (2 points in 2D)\n",
    "X_query = np.array([\n",
    "[1, 1],\n",
    " [3, 2]\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "k = 2\n",
    "metric = \"euclidean\"\n",
    "\n",
    "distances, indices = _neighbor_finding(X_train, X_query, 2, metric = metric)\n",
    "print(distances)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30471708],\n",
       "       [-1.03998411],\n",
       "       [ 0.7504512 ]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "rng.standard_normal(3).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2.]\n",
      "[4. 6.]\n",
      "[0. 0.]\n",
      "[3. 4.]\n",
      "[4. 6.]\n",
      "[0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.49794145, 2.08008382],\n",
       "       [2.08008382, 4.49794145]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_distance_calculations(X_query, X_train, 'minkowski', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 2]\n",
      " [1 3]\n",
      " [1 0]\n",
      " [1 7]\n",
      " [1 5]]\n",
      "[ 1  0  2  2 10  3]\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(0)\n",
    "# x = np.linspace(-5, 5, 50)\n",
    "# noise = np.random.normal(0, 1.5, size=x.shape)\n",
    "# y = -1.5 * x + 10 + noise\n",
    "# x = x.reshape(-1,1)\n",
    "# print(x.shape)\n",
    "\n",
    "x = np.array([[1, 2, 3, 0, 7, 5]])\n",
    "y = np.array([1, 0, 2, 2, 10, 3])\n",
    "x = x.reshape(-1, 1)\n",
    "x = np.hstack([np.ones_like(x), x])\n",
    "# y = y.reshape(-1, 1)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.]\n",
      "[-0.35344034  1.11782379]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng()\n",
    "training_array = x\n",
    "train_array = x\n",
    "train_targets = y\n",
    "epochs = 1000000\n",
    "learning_rate = 0.0001\n",
    "weights = np.zeros((2,))\n",
    "for iteration in range(epochs):\n",
    "    for entry in range(train_array.shape[0]):\n",
    "        error = np.matmul(train_array[entry], weights) - train_targets[entry]\n",
    "        weights -= learning_rate * (error) * (train_array[entry]).reshape(-1)\n",
    "\n",
    "# first_matrix = np.matmul(train_array.T, train_array)\n",
    "# second_matrix = np.matmul(train_array.T, train_targets)\n",
    "# theta = np.linalg.solve(first_matrix, second_matrix)\n",
    "\n",
    "# print(theta)\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02]] [-0.03]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "import numpy as np\n",
    "\n",
    "model = Perceptron(max_iter=1000, eta0=0.01, random_state=53)\n",
    "\n",
    "train_array = np.array([[0], [1], [2], [3], [4], [5], [6], [7]])\n",
    "train_targets = np.array([-1, -1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "model.fit(train_array,train_targets)\n",
    "\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "print(coefficients, intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Perceptron algorithms (NumPy)\n",
    "\n",
    "    This module implements the single-layer and multilayer perceptron \n",
    "\n",
    "    Functions\n",
    "    ---------\n",
    "    \n",
    "\n",
    "    Classes\n",
    "    ---------\n",
    "   \n",
    "\"\"\"\n",
    "\n",
    "# TODO: finish above!\n",
    "\n",
    "__all__ = [\n",
    "    'Perceptron',\n",
    "]\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import *\n",
    "import warnings\n",
    "from rice_ml.preprocess.datatype import *\n",
    "from rice_ml.preprocess.split import _random_number\n",
    "from rice_ml.supervised_learning.distances import _ensure_numeric\n",
    "\n",
    "ArrayLike = Union[np.ndarray, Sequence[float], Sequence[Sequence[float]], pd.DataFrame, pd.Series]\n",
    "\n",
    "\n",
    "def _validate_parameters(learning_rate: Optional[float],\n",
    "                         epochs: Optional[int],\n",
    "                         ) -> None:\n",
    "\n",
    "    # TODO: add docstrings, potentially add functionality for collecting/graphing error counts\n",
    "\n",
    "    if not isinstance(learning_rate, (int, float)):\n",
    "        raise TypeError('Learning rate must be a float')\n",
    "    if learning_rate <= 0:\n",
    "        warnings.warn(f\"For model to learn properly, learning rate should be greater than zero\", UserWarning)\n",
    "    if not isinstance(epochs, int):\n",
    "        raise TypeError('Maximum epochs must be a float')\n",
    "    if epochs <= 0:\n",
    "        raise ValueError('Maximum epochs must be greater than zero')\n",
    "    \n",
    "\n",
    "def _validate_arrays_perceptron(data_array: Optional[ArrayLike] = None,\n",
    "                              target_vector: Optional[ArrayLike] = None\n",
    "                              ) -> Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]:\n",
    "\n",
    "    # TODO: add docstrings\n",
    "\n",
    "    if data_array is not None:\n",
    "        array = _2D_numeric(data_array, 'data_array')\n",
    "\n",
    "        if np.isnan(array).any():\n",
    "            raise ValueError('Data array contains missing data (NaN values)')\n",
    "\n",
    "    if target_vector is not None:\n",
    "        target_vector = np.array(target_vector)\n",
    "        if target_vector.ndim == 2 and (target_vector.shape[1] == 1 or target_vector.shape[0] == 1):\n",
    "            vector = target_vector.reshape(-1)\n",
    "            vector = _1D_vectorized(vector, 'target_vector')\n",
    "        else:\n",
    "            vector = _1D_vectorized(target_vector, 'target_vector')\n",
    "        classes = np.unique(target_vector)\n",
    "        if len(classes) != 2:\n",
    "            raise ValueError(\"Logistic regression only supports binary targets\")\n",
    "        mapping = {classes[0]: -1, classes[1]: 1}\n",
    "        vector = (np.vectorize(mapping.get)(target_vector)).reshape(-1)\n",
    "        if np.isnan(vector).any():\n",
    "            raise ValueError('Target vector contains missing data (NaN values)')\n",
    "\n",
    "    if data_array is not None and target_vector is not None:\n",
    "        _shape_match(array, vector)\n",
    "        return array, vector\n",
    "    elif data_array is not None:\n",
    "        return array\n",
    "    elif target_vector is not None:\n",
    "        return vector\n",
    "    \n",
    "\n",
    "def _activation_function(z):\n",
    "    return np.where(z > 0, 1, -1)\n",
    "    \n",
    "\n",
    "class Perceptron_3():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 epochs: int = 1000,\n",
    "                 learning_rate: float = 0.01\n",
    "                 ) -> None:\n",
    "\n",
    "        _validate_parameters(learning_rate = learning_rate, epochs = epochs)\n",
    "        \n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.coef_: Optional[np.ndarray] = None\n",
    "        self.bias_: Optional[float] = None\n",
    "        self.class_mapping_: Optional[dict] = None\n",
    "    \n",
    "    def fit(self, training_array: np.ndarray, training_targets: np.ndarray, random_state: Optional[int] = None, shuffle: bool = True) -> 'logistic_regression':\n",
    "        \n",
    "        # TODO: docstrings/comments \n",
    "\n",
    "        if not isinstance(shuffle, bool):\n",
    "            raise TypeError('Shuffle must be a boolean')\n",
    "        \n",
    "        rng = _random_number(random_state)\n",
    "\n",
    "        train_array = _validate_arrays_perceptron(training_array)\n",
    "        \n",
    "        train_targets = _validate_arrays_perceptron(training_targets)\n",
    "        \n",
    "        classes = np.unique(training_targets)\n",
    "\n",
    "        self.class_mapping_ = {-1: classes[0], 1: classes[1]}\n",
    "        \n",
    "        train_array = np.hstack([np.ones((train_array.shape[0], 1)), train_array])\n",
    "        weights = rng.normal(loc=0, scale=0.01, size=train_array.shape[1]).reshape(-1)\n",
    "        \n",
    "        for iteration in range(self.epochs):\n",
    "            if shuffle:\n",
    "                indices = rng.permutation(train_array.shape[0])\n",
    "            else:\n",
    "                indices = np.arange(train_array.shape[0])\n",
    "            for entry in indices:\n",
    "                x = train_array[entry]\n",
    "                y = train_targets[entry]\n",
    "                learn_rate = self.learning_rate\n",
    "                y_hat = _activation_function(np.matmul(x, weights))\n",
    "                error = y_hat - y\n",
    "                weights -= learn_rate * error * x\n",
    "        \n",
    "        self.bias_ = weights[0]\n",
    "        self.coef_ = weights[1:]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _verify_fit(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        if self.coef_ is None:\n",
    "            raise RuntimeError(\"Model is not fitted; call fit(training_array, training_targets)\")\n",
    "\n",
    "        return self\n",
    "    \n",
    "\n",
    "    def prediction(self, testing_array: np.ndarray) -> np.ndarray:\n",
    "        \n",
    "        # TODO: doctrings/comments\n",
    "\n",
    "        self._verify_fit()\n",
    "\n",
    "        test_array = _validate_arrays_perceptron(testing_array)\n",
    "        \n",
    "        coef_array = _1D_vectorized(self.coef_) # TODO: fix this!\n",
    "\n",
    "        if test_array.shape[1] != len(coef_array):\n",
    "            raise ValueError('Test array must have the same number of input features as coefficients')\n",
    "        \n",
    "        bias = self.bias_\n",
    "        prediction_value = _activation_function(np.matmul(test_array, coef_array) + bias)\n",
    "\n",
    "        classification = np.array([self.class_mapping_[int(prediction)] for prediction in prediction_value])\n",
    "\n",
    "        return classification\n",
    "    \n",
    "    def score(self, testing_array: ArrayLike, actual_targets: ArrayLike) -> np.ndarray:\n",
    "\n",
    "        # TODO: be consistent w/ arraylike vs np.ndarray\n",
    "\n",
    "        predicted_target_array = self.prediction(testing_array)\n",
    "        actual_target_array = _1D_vectorized(actual_targets)\n",
    "\n",
    "        if predicted_target_array.shape != actual_target_array.shape:\n",
    "            raise ValueError(\"Shapes of predicted and actual targets must match\")\n",
    "        \n",
    "        accuracy = np.mean(predicted_target_array == actual_target_array)\n",
    "\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "Predictions: [-1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Features\n",
    "y = np.array([-1, 1, 1, 1])  # Target labels for OR (converted to -1, 1)\n",
    "\n",
    "# Initialize Perceptron\n",
    "perceptron = Perceptron(epochs=1000, learning_rate=0.01)\n",
    "\n",
    "# Train the perceptron\n",
    "perceptron.fit(X, y)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = perceptron.scoring(X, y)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Test predictions\n",
    "predictions = perceptron.prediction(X)\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Perceptron Accuracy: 100.00%\n",
      "Scikit-learn Perceptron Accuracy: 100.00%\n",
      "Custom Perceptron Predictions: [ 1 -1  1  1  1 -1  1  1  1  1  1 -1 -1 -1 -1  1  1  1  1  1 -1  1 -1  1\n",
      "  1  1  1  1 -1 -1 -1 -1  1 -1 -1  1  1 -1 -1 -1  1  1  1 -1 -1]\n",
      "Scikit-learn Predictions: [ 1 -1  1  1  1 -1  1  1  1  1  1 -1 -1 -1 -1  1  1  1  1  1 -1  1 -1  1\n",
      "  1  1  1  1 -1 -1 -1 -1  1 -1 -1  1  1 -1 -1 -1  1  1  1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron as SklearnPerceptron\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Convert to binary classification (e.g., setosa vs. non-setosa)\n",
    "y = np.where(y == 0, -1, 1)  # Only two classes: -1 (setosa) and 1 (non-setosa)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the custom perceptron\n",
    "perceptron = Perceptron_3(epochs=1000, learning_rate=0.01)\n",
    "perceptron.fit(X_train, y_train, shuffle = True)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = perceptron.score(X_test, y_test)\n",
    "print(f\"Custom Perceptron Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Compare with sklearn's Perceptron\n",
    "sklearn_perceptron = SklearnPerceptron(max_iter=1000, eta0=0.01)\n",
    "sklearn_perceptron.fit(X_train, y_train)\n",
    "sklearn_accuracy = sklearn_perceptron.score(X_test, y_test)\n",
    "print(f\"Scikit-learn Perceptron Accuracy: {sklearn_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Test predictions\n",
    "custom_predictions = perceptron.prediction(X_test)\n",
    "sklearn_predictions = sklearn_perceptron.predict(X_test)\n",
    "print(\"Custom Perceptron Predictions:\", custom_predictions)\n",
    "print(\"Scikit-learn Predictions:\", sklearn_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01171374]\n"
     ]
    }
   ],
   "source": [
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, epochs: int = 1000, learning_rate: float = 0.01) -> None:\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.coef_ = None  # Weights for the features\n",
    "        self.bias_ = 0  # Bias term\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> 'Perceptron':\n",
    "        \"\"\"\n",
    "        Train the perceptron using the provided training data.\n",
    "        \"\"\"\n",
    "        # Ensure the data is two-dimensional (n_samples, n_features)\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1, 1)  # Reshape to ensure it's 2D (if it's 1D)\n",
    "\n",
    "        # Initialize weights (coef) randomly small\n",
    "        self.coef_ = np.random.randn(X.shape[1]) * 0.01  # Small random weights\n",
    "        \n",
    "        # Iterating through all the epochs and data points\n",
    "        for epoch in range(self.epochs):\n",
    "            # Track the number of misclassifications in this epoch\n",
    "            errors = 0\n",
    "            for i in range(X.shape[0]):\n",
    "                # Compute the net input (weighted sum + bias)\n",
    "                net_input = np.dot(X[i], self.coef_) + self.bias_\n",
    "                \n",
    "                # Apply activation function: step function\n",
    "                y_hat = 1 if net_input > 0 else -1\n",
    "                \n",
    "                # If the prediction is wrong, update weights and bias\n",
    "                if y_hat != y[i]:\n",
    "                    # Update rule: weights += learning_rate * error * input\n",
    "                    self.coef_ += self.learning_rate * (y[i] - y_hat) * X[i]\n",
    "                    self.bias_ += self.learning_rate * (y[i] - y_hat)\n",
    "                    errors += 1\n",
    "            # Early stopping: If there are no errors in the epoch, stop training\n",
    "            if errors == 0:\n",
    "                break\n",
    "        return self\n",
    "    \n",
    "train_array = np.array([[0], [1], [2], [3], [4], [5], [6], [7]])\n",
    "train_targets = np.array([-1, -1, 1, 1, 1, 1, 1, 1])\n",
    "perceptron1 = Perceptron(epochs = 100_000, learning_rate = 0.01)\n",
    "perceptron1.fit(train_array, train_targets)\n",
    "print(perceptron1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron_2(object):\n",
    "    def __init__(self, eta = .5, epochs=50):\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        self.w_ = np.random.rand(1 + X.shape[1])\n",
    "        print(self.w_)\n",
    "        self.errors_ = []\n",
    "        \n",
    "        for _ in range(self.epochs):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (self.predict(xi) - target)\n",
    "                self.w_[:-1] -= update*xi\n",
    "                self.w_[-1] -= update\n",
    "                errors += int(update != 0)\n",
    "            if errors == 0:\n",
    "                return self\n",
    "            else:\n",
    "                self.errors_.append(errors)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_[:-1]) + self.w_[-1]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: 1}"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = dict()\n",
    "delta[5] = 1\n",
    "\n",
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.56132929 -2.0017013 ]\n",
      "-2.4229866167677963\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/RandyRDavila/Data_Science_and_Machine_Learning_Spring_2022/main/Lecture_3/Datasets/iris_dataset.csv\")\n",
    "# Store the desired species values in the numpy array y\n",
    "y = df.iloc[0:100].species.values\n",
    "\n",
    "# Convert each entry of y with setosa to -1 and otherwise 1\n",
    "y = np.where(y == 'setosa', -1, 1)\n",
    "\n",
    "# Store the desired feature measurements in the matrix X\n",
    "X = df[[\"sepal_length\", \"sepal_width\"]].iloc[:100].values\n",
    "\n",
    "# Instantiate one instance of the Perceptron class\n",
    "clf = Perceptron(epochs = 100_000)\n",
    "\n",
    "# Call the train method to train the weights and bias of the given instance\n",
    "clf.fit(X, y, shuffle = False)\n",
    "print(clf.coef_)\n",
    "print(clf.bias_)\n",
    "\n",
    "y_hat = clf.prediction(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compare y_hat and y\n",
    "print(y == y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt \n",
    "# from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "# plt.figure(figsize = (10, 8))\n",
    "# plot_decision_regions(X, y, clf = clf)\n",
    "# plt.title(\"My First Perceptron\", fontsize = 18)\n",
    "# plt.xlabel(\"sepal length [cm]\", fontsize = 15)\n",
    "# plt.ylabel(\"petal length [cm]\", fontsize = 15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97400644 0.87372018 0.93023528]\n",
      "[  80.27400644 -101.42627982 -128.06976472]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n",
      "[  80.27400644 -101.42627982 -128.06976472]\n"
     ]
    }
   ],
   "source": [
    "# Store the desired species values in the numpy array y\n",
    "y = df.iloc[0:100].species.values\n",
    "\n",
    "# Convert each entry of y with setosa to -1 and otherwise 1\n",
    "y = np.where(y == 'setosa', -1, 1)\n",
    "\n",
    "# Store the desired feature measurements in the matrix X\n",
    "X = df[[\"sepal_length\", \"sepal_width\"]].iloc[:100].values\n",
    "\n",
    "# Instantiate one instance of the Perceptron class\n",
    "clf_2 = Perceptron_2(epochs = 100_000)\n",
    "\n",
    "# Call the train method to train the weights and bias of the given instance\n",
    "clf_2.train(X, y)\n",
    "print(clf_2.w_)\n",
    "\n",
    "y_hat = clf_2.predict(X)\n",
    "\n",
    "# Compare y_hat and y\n",
    "print(y == y_hat)\n",
    "print(clf_2.w_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.22  -0.369]] [-0.05]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "import numpy as np\n",
    "\n",
    "# Store the desired species values in the numpy array y\n",
    "y = df.iloc[0:100].species.values\n",
    "\n",
    "# Convert each entry of y with setosa to -1 and otherwise 1\n",
    "y = np.where(y == 'setosa', -1, 1)\n",
    "\n",
    "# Store the desired feature measurements in the matrix X\n",
    "X = df[[\"sepal_length\", \"sepal_width\"]].iloc[:100].values\n",
    "\n",
    "# Instantiate one instance of the Perceptron class\n",
    "model = Perceptron(max_iter=1000, eta0=0.01)\n",
    "\n",
    "# Call the train method to train the weights and bias of the given instance\n",
    "model.fit(X, y)\n",
    "\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "print(coefficients, intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "plt.figure(figsize = (10, 8))\n",
    "plot_decision_regions(X, y, clf = clf)\n",
    "plt.title(\"My First Perceptron\", fontsize = 18)\n",
    "plt.xlabel(\"sepal length [cm]\", fontsize = 15)\n",
    "plt.ylabel(\"petal length [cm]\", fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.35344034],\n",
       "       [ 1.11782379]])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.35344034  1.11782379]\n"
     ]
    }
   ],
   "source": [
    "print(weights.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.35294118],\n",
       "       [ 1.11764706]])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.zeros((2,1))  # including bias as first column\n",
    "learning_rate = 0.01\n",
    "for epoch in range(10000):\n",
    "    y_pred = x @ weights\n",
    "    error = y_pred - y\n",
    "    weights -= learning_rate * (x.T @ error) / len(y)\n",
    "    # for i in range(x.shape[0]):\n",
    "    #     xi = x[i].reshape(1, -1)   # shape (1,2)\n",
    "    #     yi = y[i]                   # scalar\n",
    "    #     y_pred = xi @ weights       # predicted value\n",
    "    #     error = y_pred - yi  \n",
    "    #     weights -= learning_rate * xi.T * error\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Perceptron algorithms (NumPy)\n",
    "\n",
    "    This module implements the single-layer and multilayer perceptron \n",
    "\n",
    "    Functions\n",
    "    ---------\n",
    "    \n",
    "\n",
    "    Classes\n",
    "    ---------\n",
    "   \n",
    "\"\"\"\n",
    "\n",
    "# TODO: finish above!\n",
    "\n",
    "__all__ = [\n",
    "    'Perceptron',\n",
    "]\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import *\n",
    "import warnings\n",
    "from rice_ml.preprocess.datatype import *\n",
    "from rice_ml.preprocess.split import _random_number\n",
    "from rice_ml.supervised_learning.distances import _ensure_numeric\n",
    "\n",
    "ArrayLike = Union[np.ndarray, Sequence[float], Sequence[Sequence[float]], pd.DataFrame, pd.Series]\n",
    "\n",
    "\n",
    "def _validate_parameters(learning_rate: Optional[float],\n",
    "                         epochs: Optional[int],\n",
    "                         ) -> None:\n",
    "\n",
    "    # TODO: add docstrings, potentially add functionality for collecting/graphing error counts\n",
    "\n",
    "    if not isinstance(learning_rate, (int, float)):\n",
    "        raise TypeError('Learning rate must be a float')\n",
    "    if learning_rate <= 0:\n",
    "        warnings.warn(f\"For model to learn properly, learning rate should be greater than zero\", UserWarning)\n",
    "    if not isinstance(epochs, int):\n",
    "        raise TypeError('Maximum epochs must be a float')\n",
    "    if epochs <= 0:\n",
    "        raise ValueError('Maximum epochs must be greater than zero')\n",
    "    \n",
    "\n",
    "def _validate_arrays_perceptron(data_array: Optional[ArrayLike] = None,\n",
    "                              target_vector: Optional[ArrayLike] = None\n",
    "                              ) -> Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]:\n",
    "\n",
    "    # TODO: add docstrings\n",
    "\n",
    "    if data_array is not None:\n",
    "        array = _2D_numeric(data_array, 'data_array')\n",
    "\n",
    "        if np.isnan(array).any():\n",
    "            raise ValueError('Data array contains missing data (NaN values)')\n",
    "\n",
    "    if target_vector is not None:\n",
    "        target_vector = np.array(target_vector)\n",
    "        if target_vector.ndim == 2 and (target_vector.shape[1] == 1 or target_vector.shape[0] == 1):\n",
    "            vector = target_vector.reshape(-1)\n",
    "            vector = _1D_vectorized(vector, 'target_vector')\n",
    "        else:\n",
    "            vector = _1D_vectorized(target_vector, 'target_vector')\n",
    "        if np.isnan(vector).any():\n",
    "            raise ValueError('Target vector contains missing data (NaN values)')\n",
    "\n",
    "    if data_array is not None and target_vector is not None:\n",
    "        _shape_match(array, vector)\n",
    "        return array, vector\n",
    "    elif data_array is not None:\n",
    "        return array\n",
    "    elif target_vector is not None:\n",
    "        return vector\n",
    "\n",
    "\n",
    "def _sigmoid(z):\n",
    "    \n",
    "    # TODO: add unit tests?\n",
    "\n",
    "    return 1.0/(1.0 + np.exp(-z))\n",
    "\n",
    "def derivative_sigmoid(z):\n",
    "    return _sigmoid(z) * (1.0 - _sigmoid(z))\n",
    "    \n",
    "\n",
    "class multilayer_Perceptron():\n",
    "\n",
    "    def __init__(self,\n",
    "                  layers: ArrayLike,\n",
    "                  epochs: int = 1000,\n",
    "                  learning_rate: float = 0.01\n",
    "                 ) -> None:\n",
    "\n",
    "        _validate_parameters(learning_rate = learning_rate, epochs = epochs)\n",
    "        \n",
    "        layer_array = _ensure_numeric(layers)\n",
    "\n",
    "        self.layers = layers\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.coef_: Optional[list] = None\n",
    "        self.bias_: Optional[list] = None\n",
    "        self.class_mapping_: Optional[dict] = None\n",
    "\n",
    "    def _weight_initialization(self, random_state: Optional[int] = None) -> Tuple[list, list]:\n",
    "        layers = self.layers\n",
    "        weights = []\n",
    "        bias = []\n",
    "        rng = _random_number(random_state)\n",
    "        for i in range(1, len(layers)):\n",
    "            layer_weight = rng.standard_normal((layers[i - 1], layers[i]))\n",
    "            layer_bias = np.zeros(layers[i]) # rng.standard_normal\n",
    "            weights.append(layer_weight)\n",
    "            bias.append(layer_bias)\n",
    "        \n",
    "        return weights, bias\n",
    "    \n",
    "    def _forward_layer(self, training_array: np.ndarray, weights: list, bias: list) -> Tuple[list, list]:\n",
    "        \n",
    "        train_array = _validate_arrays_perceptron(training_array)\n",
    "\n",
    "        z = []\n",
    "        a = [train_array]\n",
    "        for i in range(len(weights)):\n",
    "            z_layer = np.matmul(a[-1], weights[i]) + bias[i]\n",
    "            z.append(z_layer)\n",
    "            a_layer = _sigmoid(z_layer)\n",
    "            a.append(a_layer)\n",
    "            \n",
    "        return z, a\n",
    "\n",
    "    def _back_propagation(self, z: list, a: list, weights: list, training_targets: np.ndarray) -> Tuple[list, list]:\n",
    "\n",
    "        train_targets = _validate_arrays_perceptron(training_targets) # TODO: account for multiple classes!\n",
    "        \n",
    "        L = len(self.layers) - 1\n",
    "        learning_rate = self.learning_rate\n",
    "        delta = dict()\n",
    "        delta[L] = (a[-1] - train_targets) * derivative_sigmoid(z[-1])\n",
    "        d_weights = []\n",
    "        d_bias = []\n",
    "\n",
    "        for i in range(L - 1, 0, -1):\n",
    "            delta[i] = (np.matmul(delta[i + 1], weights[i].T)) * derivative_sigmoid(z[i - 1])\n",
    "    \n",
    "        for j in range(1, L + 1):\n",
    "            d_weights_layer = learning_rate * np.matmul(a[j - 1].T, delta[j])\n",
    "            d_bias_layer = learning_rate * np.mean(delta[j], axis = 0)\n",
    "            d_weights.append(d_weights_layer)\n",
    "            d_bias.append(d_bias_layer)\n",
    "\n",
    "        return d_weights, d_bias\n",
    "\n",
    "    def _weight_update(self, weights: list, bias: list, d_weights: list, d_bias: list) -> Tuple[list, list]:\n",
    "        \n",
    "        for i in range(len(weights)):\n",
    "                weights[i] -= d_weights[i]\n",
    "                bias[i] -= d_bias[i]\n",
    "\n",
    "        return weights, bias\n",
    "\n",
    "    def fit(self, training_array: np.ndarray, training_targets: np.ndarray, random_state: Optional[int] = None) -> 'multilayer_Perceptron':\n",
    "        \n",
    "        train_array = _validate_arrays_perceptron(training_array)\n",
    "        train_targets = _validate_arrays_perceptron(training_targets)\n",
    "\n",
    "        weights, bias = self._weight_initialization(random_state = random_state)\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            z, a = self._forward_layer(train_array, weights, bias)\n",
    "            d_weights, d_bias = self._back_propagation(z, a, weights, train_targets)\n",
    "            weights, bias = self._weight_update(weights, bias, d_weights, d_bias)\n",
    "\n",
    "        self.coef_ = weights\n",
    "        self.bias_ = bias\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def _verify_fit(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        if self.coef_ is None or self.bias_ is None:\n",
    "            raise RuntimeError(\"Model is not fitted; call fit(training_array, training_targets)\")\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, testing_array: np.ndarray):\n",
    "        \n",
    "        # TODO: doctrings/comments\n",
    "\n",
    "        self._verify_fit()\n",
    "\n",
    "        test_array = _validate_arrays_perceptron(testing_array)\n",
    "        \n",
    "        coef_array = self.coef_\n",
    "        # coef_array = _1D_vectorized(self.coef_) # TODO: fix this!\n",
    "\n",
    "        if test_array.shape[1] != self.coef_[0].shape[0]:\n",
    "            raise ValueError('Test array must have the same number of input features as coefficients')\n",
    "        \n",
    "        bias = self.bias_\n",
    "\n",
    "        z, a = self._forward_layer(testing_array, self.coef_, self.bias_)\n",
    "\n",
    "        prediction = a[-1]\n",
    "\n",
    "        predicted_labels = np.where(prediction > 0.5, 1, 0)\n",
    "\n",
    "        return prediction, predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weights = list of length L - 1 (L is number of layers, L - 1 is number of layers not including output) - indexed from 0 to L - 2\n",
    "- each entry in weights: array of dimension (number of neurons in next layer x number of neurons in past layer)\n",
    "biases = list of length L - 1\n",
    "- each entry in biases: vector of dimension (number of neurons in next layer x 1)\n",
    "activation = list of length L (with first entry just the train array, so L - 1 meaningful entries)\n",
    "- each entry in activation: array of dimension (number of samples, number of neurons in layer before one being calculated for)\n",
    "z = list of length L - 1\n",
    "- each entry in z: array of dimension (number of samples, number of neurons in layer being calculated for (off by 1 index from activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.99132972e-01 8.76348496e-04]\n",
      " [9.38306166e-01 6.33514452e-02]\n",
      " [9.36380644e-01 6.23814358e-02]\n",
      " [1.26031855e-01 8.73582736e-01]]\n",
      "[[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1],\n",
    "])\n",
    "X_test = X_train.copy() # Use the same inputs for testing\n",
    "\n",
    "Y_train = np.array([\n",
    "    [1, 0],  # Input (0, 0) -> Class 0\n",
    "    [1, 0],  # Input (0, 1) -> Class 0\n",
    "    [1, 0],  # Input (1, 0) -> Class 0\n",
    "    [0, 1],  # Input (1, 1) -> Class 1\n",
    "])\n",
    "# Model setup\n",
    "# Layers: [2 Input, 2 Hidden, 1 Output] - The same architecture is fine.\n",
    "model = multilayer_Perceptron(layers=[2, 2, 2], epochs=5000, learning_rate=0.1) \n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "prediction, predictions = model.predict(X_test)\n",
    "\n",
    "print(prediction)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-1.1244749 , -1.11475602],\n",
      "       [-0.15569741,  0.0827548 ],\n",
      "       [ 0.73760329, -0.093025  ]]), array([[-0.57136956,  0.72300382],\n",
      "       [-1.31929255,  0.63363937]]), array([[ 0.50434387],\n",
      "       [-0.40621188]])] [array([-0.50024246,  0.0590798 ]), array([ 1.1589291, -1.6235606]), array([-1.10884683])]\n",
      "[array([[-1.1244749 , -1.11475602],\n",
      "       [-0.15569741,  0.0827548 ],\n",
      "       [ 0.73760329, -0.093025  ]]), array([[-0.57136956,  0.72300382],\n",
      "       [-1.31929255,  0.63363937]]), array([[ 0.50434387],\n",
      "       [-0.40621188]])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.multilayer_Perceptron at 0x1537d4520>"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [3, 2, 2, 1]\n",
    "\n",
    "# Create an MLP instance\n",
    "mlp = multilayer_Perceptron(layers, learning_rate=0.1, epochs=1000)\n",
    "\n",
    "# Toy dataset (X: 4 samples, 2 features; y: binary target)\n",
    "X = np.array([[0, 0, 0],\n",
    "              [0, 1, 0],\n",
    "              [1, 0, 1],\n",
    "              [1, 1, 1]])\n",
    "\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]])\n",
    "\n",
    "# Fit the model to the data\n",
    "mlp.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.33333333 2.33333333]\n",
      " [2.33333333 2.33333333]]\n",
      "[[2.33333333 2.33333333]\n",
      " [2.33333333 2.33333333]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EighResult(eigenvalues=array([0.        , 4.66666667]), eigenvectors=array([[-0.70710678,  0.70710678],\n",
       "       [ 0.70710678,  0.70710678]]))"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array = np.array([\n",
    "    [1, 2],\n",
    "    [2, 3],\n",
    "    [4, 5]\n",
    "])\n",
    "\n",
    "observation_number = data_array.shape[0]\n",
    "means = np.mean(data_array, axis = 0)\n",
    "\n",
    "covariance_matrix = np.dot((data_array - means).T, (data_array - means)) / (observation_number - 1)\n",
    "print(covariance_matrix)\n",
    "cov_numpy = np.cov(data_array, rowvar=False)\n",
    "print(cov_numpy)\n",
    "\n",
    "np.linalg.eigh(covariance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def z_score_standardize(data_array: ArrayLike, return_params: bool = False, ddof: int = 0) -> Union[np.ndarray, Tuple[np.ndarray, dict]]:\n",
    "    \n",
    "    # TODO: add type hints/docstrings/examples\n",
    "\n",
    "    array = _2D_numeric(data_array)\n",
    "\n",
    "    if not isinstance(ddof, int):\n",
    "        raise TypeError(f\"ddof parameter must be an integer, got {type(ddof).__name__}\")\n",
    "    \n",
    "    if not isinstance(return_params, bool):\n",
    "        raise TypeError(f\"return_params must be a boolean, got {type(return_params).__name__}\")\n",
    "    \n",
    "    if ddof < 0:\n",
    "        raise ValueError(f\"ddof parameter must be greater than or equal to zero\")\n",
    "\n",
    "    columnwise_mean = array.mean(axis = 0)\n",
    "    scale = array.std(axis = 0, ddof = ddof)\n",
    "    scale[scale == 0.0] = 1.0\n",
    "    standardized_array = (array - columnwise_mean) / scale\n",
    "\n",
    "    if return_params:\n",
    "        return standardized_array, {'mean': columnwise_mean, 'scale': scale}\n",
    "\n",
    "    return standardized_array\n",
    "\n",
    "\n",
    "class pca():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 n_components: int) -> None:\n",
    "        \n",
    "        if not isinstance(n_components, int):\n",
    "            raise TypeError('Number of retained components must be an integer')\n",
    "        if n_components <= 0:\n",
    "            raise ValueError('Number of retained components must be greater than zero')\n",
    "\n",
    "        self.n_components = n_components\n",
    "        self.components: Optional[np.ndarray] = None\n",
    "        self.eigenvalues: Optional[np.ndarray] = None\n",
    "        self.variance: Optional[np.ndarray] = None\n",
    "\n",
    "        # TODO: add a check here that n_components does not exceed number of features\n",
    "    \n",
    "    def fit(self, data_input_array: ArrayLike) -> np.ndarray:\n",
    "\n",
    "        data_array = z_score_standardize(data_input_array)\n",
    "\n",
    "        if self.n_components > data_array.shape[1]:\n",
    "            raise ValueError('Number of retained components cannot exceed number of features')\n",
    "\n",
    "        observation_number = data_array.shape[0]\n",
    "        means = np.mean(data_array, axis = 0)\n",
    "\n",
    "        covariance_matrix = np.dot((data_array - means).T, (data_array - means)) / (observation_number - 1)\n",
    "\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "\n",
    "        sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "        sorted_eigenvalues = eigenvalues[sorted_indices]\n",
    "        sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "        self.eigenvalues = sorted_eigenvalues[:self.n_components]\n",
    "        self.variance = sorted_eigenvalues[:self.n_components]/(np.sum(eigenvalues))\n",
    "        self.components = sorted_eigenvectors[:, :self.n_components]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _verify_fit(self) -> 'pca':\n",
    "        if self.components is None or self.variance is None:\n",
    "            raise RuntimeError(\"Model is not fitted; call fit(data_input_array)\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_input_array: ArrayLike) -> np.ndarray:\n",
    "\n",
    "        self._verify_fit()\n",
    "        data_array = z_score_standardize(data_input_array)\n",
    "        transformed_data = np.dot(data_array, self.components)\n",
    "\n",
    "        return transformed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.67397595 -0.25169344]\n",
      " [-0.68991106 -0.12173674]\n",
      " [-0.26415742  0.96012009]]\n",
      "[0.67185508 0.31058257]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.07448672, -1.67301084],\n",
       "       [ 2.45265516,  0.78952027],\n",
       "       [-0.89213185,  0.64291825],\n",
       "       [ 0.2954202 , -0.50985255],\n",
       "       [-1.78145679,  0.75042487]])"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [2.5, 2.4, 0.5],\n",
    "    [0.5, 0.7, 2.2],\n",
    "    [2.2, 2.9, 2.9],\n",
    "    [1.9, 2.2, 1.5],\n",
    "    [3.1, 3.0, 3.3]\n",
    "])\n",
    "\n",
    "pca_new = pca(n_components = 2)\n",
    "\n",
    "pca_new.fit(X)\n",
    "print(pca_new.components)\n",
    "print(pca_new.variance)\n",
    "\n",
    "pca_new.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _validate_parameters(max_depth: Optional[int], min_samples_split: Optional[int]) -> None:\n",
    "\n",
    "    # TODO: type hints, docstrings\n",
    "\n",
    "    if max_depth is not None and not isinstance(max_depth, int):\n",
    "        raise TypeError('Maximum depth must be an integer')\n",
    "    if max_depth is not None and max_depth <= 0:\n",
    "        raise ValueError('Maximum depth must be greater than zero')\n",
    "    if not isinstance(min_samples_split, int):\n",
    "        raise TypeError('Minimum samples required to split node must be an integer')\n",
    "    if min_samples_split <= 0:\n",
    "        raise TypeError('Minimum samples required to split node must be greater than zero')\n",
    "    \n",
    "def _validate_parameters_node(feature_index: Optional[int], \n",
    "                              threshold_value: Optional[float], \n",
    "                              left: Optional[\"Node\"] = None, \n",
    "                              right: Optional[\"Node\"] = None) -> None:\n",
    "\n",
    "    # TODO: type hints, docstrings\n",
    "\n",
    "    if feature_index is not None and not isinstance(feature_index, int):\n",
    "        raise TypeError('Feature index must be an integer')\n",
    "    if feature_index is not None and feature_index < 0:\n",
    "        raise ValueError('Feature index must be greater than or equal to zero')\n",
    "    if threshold_value is not None and not isinstance(threshold_value, (float, int)):\n",
    "        raise TypeError('Threshold value must be a float')\n",
    "    if left is not None and not isinstance(left, Node):\n",
    "        raise TypeError('Left node must be an instance of the Node class')\n",
    "    if right is not None and not isinstance(right, Node):\n",
    "        raise TypeError('Right node must be an instance of the Node class')\n",
    "\n",
    "def _entropy(train_targets: np.ndarray):\n",
    "\n",
    "    train_targets = _1D_vectorized(train_targets)\n",
    "\n",
    "    _, counts = np.unique(train_targets, return_counts = True)\n",
    "    probabilities = counts / np.sum(counts)\n",
    "    probabilities_filtered = probabilities[probabilities > 0]\n",
    "    entropy = -np.sum(probabilities_filtered * np.log2(probabilities_filtered))\n",
    "\n",
    "    return entropy\n",
    "\n",
    "\n",
    "class Node():\n",
    "\n",
    "    def __init__(self,\n",
    "                 feature_index: Optional[int] = None,\n",
    "                 threshold_value: Optional[float] = None,\n",
    "                 left: \"Node\" = None,\n",
    "                 right: \"Node\" = None,\n",
    "                 value: Optional[Any] = None) -> None:\n",
    "        \n",
    "        _validate_parameters_node(feature_index, threshold_value, left, right)\n",
    "\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold_value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value: Optional[Any] = value\n",
    "\n",
    "    def is_leaf(self) -> bool:\n",
    "        return self.value is not None\n",
    "\n",
    "class decision_tree():\n",
    "\n",
    "    def __init__(self,\n",
    "                 max_depth: Optional[int] = None,\n",
    "                 min_samples_split: Optional[int] = 2) -> None:\n",
    "        \n",
    "        _validate_parameters(max_depth, min_samples_split)\n",
    "\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree: Optional[Node] = None\n",
    "        self._class_mappings: Optional[dict] = None\n",
    "        self._reverse_class_mappings: Optional[dict] = None\n",
    "        self._n_features: Optional[int] = None\n",
    "\n",
    "    def _information_gain(self,\n",
    "                          parent_class: np.ndarray,\n",
    "                          left_class: np.ndarray,\n",
    "                          right_class: np.ndarray) -> ...:\n",
    "        \n",
    "        parent_entropy = _entropy(parent_class)\n",
    "        left_entropy = _entropy(left_class)\n",
    "        right_entropy = _entropy(right_class)\n",
    "\n",
    "        if len(parent_class) != len(left_class) + len(right_class):\n",
    "            raise ValueError('Summed number of split samples must equal total number of samples')\n",
    "        \n",
    "        left_weight = len(left_class) / len(parent_class)\n",
    "        right_weight = len(right_class) / len(parent_class)\n",
    "\n",
    "        final_gain = parent_entropy - (left_weight * left_entropy + right_weight * right_entropy)\n",
    "\n",
    "        return final_gain\n",
    "    \n",
    "    def _best_split(self,\n",
    "                    training_array: ArrayLike,\n",
    "                    training_targets: ArrayLike) -> ...:\n",
    "        \n",
    "        train_array = _2D_numeric(training_array)\n",
    "        train_targets = _1D_vectorized(training_targets)\n",
    "\n",
    "        _, n_features = train_array.shape\n",
    "\n",
    "        best_gain = -np.inf\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "\n",
    "        for feature in range(n_features):\n",
    "            possible_thresholds = np.unique(train_array[:, feature])\n",
    "            for threshold in possible_thresholds:\n",
    "                left_indices = train_array[:, feature] <= threshold\n",
    "                right_indices = train_array[:, feature] > threshold\n",
    "                \n",
    "                left_classes = train_targets[left_indices]\n",
    "                right_classes = train_targets[right_indices]\n",
    "\n",
    "                if len(left_classes) == 0 or len(right_classes) == 0:\n",
    "                    continue\n",
    "                \n",
    "                gain = self._information_gain(train_targets, left_classes, right_classes)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "        \n",
    "        return best_feature, best_threshold\n",
    "                \n",
    "    def _leaf_value(self, training_targets: np.ndarray) -> Union[int, float, str]:\n",
    "\n",
    "        train_targets = _1D_vectorized(training_targets)\n",
    "        classes, counts = np.unique(train_targets, return_counts = True)\n",
    "        classification = classes[np.argmax(counts)]\n",
    "\n",
    "        return classification\n",
    "    \n",
    "    def _build_tree(self, training_array: ArrayLike, training_targets: ArrayLike, depth: int) -> Node:\n",
    "\n",
    "        train_array = _2D_numeric(training_array)\n",
    "        train_targets = _1D_vectorized(training_targets)\n",
    "\n",
    "        n_samples, n_features = train_array.shape\n",
    "\n",
    "        if n_samples < self.min_samples_split:\n",
    "            return Node(value = self._leaf_value(train_targets))\n",
    "        if self.max_depth is not None and self.max_depth <= depth:\n",
    "            return Node(value = self._leaf_value(train_targets))\n",
    "        if len(np.unique(train_targets)) == 1:\n",
    "            return Node(value = self._leaf_value(train_targets))\n",
    "        \n",
    "        best_feature, best_threshold = self._best_split(train_array, train_targets)\n",
    "\n",
    "        left_indices = train_array[:, best_feature] <= best_threshold\n",
    "        right_indices = train_array[:, best_feature] > best_threshold\n",
    "        \n",
    "        left_classes = train_targets[left_indices]\n",
    "        right_classes = train_targets[right_indices]\n",
    "\n",
    "        left_child = self._build_tree(train_array[left_indices, :], left_classes, depth + 1)\n",
    "        right_child = self._build_tree(train_array[right_indices, :], right_classes, depth + 1)\n",
    "\n",
    "        return Node(feature_index = best_feature, threshold_value = best_threshold, left = left_child, right = right_child)\n",
    "    \n",
    "    def fit(self, training_array: ArrayLike, training_targets: ArrayLike) -> \"decision_tree\":\n",
    "        \n",
    "        unique_classes = list(dict.fromkeys(training_targets))\n",
    "        self._class_mappings = {cls: i for i, cls in enumerate(unique_classes)}\n",
    "\n",
    "        self._reverse_class_mappings = {\n",
    "                                    i: (cls.item() if isinstance(cls, np.generic) else cls)\n",
    "                                    for cls, i in self._class_mappings.items()\n",
    "                                }\n",
    "        \n",
    "        train_targets = np.array([self._class_mappings[item] for item in training_targets])\n",
    "        \n",
    "        train_array = _2D_numeric(training_array)\n",
    "        self._n_features = train_array.shape[1]\n",
    "\n",
    "        final_tree = self._build_tree(train_array, train_targets, 0)\n",
    "        self.tree = final_tree\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def _verify_fit(self) -> \"decision_tree\":\n",
    "        if self.tree is None:\n",
    "            raise RuntimeError(\"Model is not fitted; call fit(training_array, training_targets)\")\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, testing_array: ArrayLike) -> np.ndarray:\n",
    "\n",
    "        self._verify_fit()\n",
    "\n",
    "        test_array = _2D_numeric(testing_array)\n",
    "\n",
    "        if test_array.shape[1] != self._n_features:\n",
    "            raise ValueError(\"Number of features in testing data must match number of features in training data\")\n",
    "        \n",
    "        # TODO: add something to test that test_array has the same number of features\n",
    "\n",
    "        prediction_array = np.full((test_array.shape[0],), np.nan, dtype = object)\n",
    "        for sample in range(test_array.shape[0]):\n",
    "            prediction = self._predict_recursive(test_array[sample, :], self.tree)\n",
    "            prediction_array[sample] = prediction\n",
    "        \n",
    "        if any(value is np.nan or value is None for value in prediction_array):\n",
    "            raise ValueError(\"Predictions were not made for all samples\")\n",
    "        \n",
    "        predictions = np.array([self._reverse_class_mappings[p] for p in prediction_array], dtype=object)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "    def _predict_recursive(self, testing_row: np.ndarray, node: Node) -> Union[int, float, str]:\n",
    "        \n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        \n",
    "        if testing_row[node.feature_index] <= node.threshold:\n",
    "            return self._predict_recursive(testing_row, node.left)\n",
    "        else:\n",
    "            return self._predict_recursive(testing_row, node.right)\n",
    "    \n",
    "    def print_tree(self, node: Optional[Node] = None, depth: int = 0) -> None:\n",
    "        \n",
    "        if node is None:\n",
    "            self._verify_fit()\n",
    "            node = self.tree\n",
    "\n",
    "        if node.is_leaf():\n",
    "            print(\"\\t\" * depth + f\"Predict: {node.value}\")\n",
    "        else:\n",
    "            print(\"\\t\" * depth + f\"Feature {node.feature_index} <= {node.threshold}\")\n",
    "            self.print_tree(node.left, depth + 1)\n",
    "            self.print_tree(node.right, depth + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1]\n",
      "Feature 0 <= 0.0\n",
      "\tPredict: 0\n",
      "\tPredict: 1\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([\n",
    "    [0, 3, 0],  # Red, small, smooth\n",
    "    [0, 5, 1],  # Red, medium, rough\n",
    "    [1, 4, 0],  # Green, medium, smooth\n",
    "    [1, 6, 1],  # Green, large, rough\n",
    "    [2, 2, 0],  # Yellow, small, smooth\n",
    "    [2, 7, 1],  # Yellow, large, rough\n",
    "    [0, 4, 0],\n",
    "    [1, 5, 1],\n",
    "    [2, 3, 0],\n",
    "    [1, 7, 1]\n",
    "])\n",
    "\n",
    "# Target values: Edible=1, Not=0\n",
    "y_train = np.array([0, 0, 1, 1, 0, 1, 0, 1, 0, 1])\n",
    "\n",
    "X_test = np.array([\n",
    "    [0, 2, 0],  # Red, very small, smooth\n",
    "    [1, 6, 0],  # Green, large, smooth\n",
    "    [2, 5, 1],  # Yellow, medium-large, rough\n",
    "    [0, 6, 1],  # Red, large, rough\n",
    "    [1, 3, 0]   # Green, small, smooth\n",
    "])\n",
    "\n",
    "decision = decision_tree(max_depth = 1)\n",
    "\n",
    "decision.fit(X_train, y_train)\n",
    "\n",
    "predict = decision.predict(X_test)\n",
    "\n",
    "print(predict)\n",
    "\n",
    "decision.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class regression_tree():\n",
    "\n",
    "    def __init__(self,\n",
    "                 max_depth: Optional[int] = None,\n",
    "                 min_samples_split: Optional[int] = 2) -> None:\n",
    "        \n",
    "        _validate_parameters(max_depth, min_samples_split)\n",
    "\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree: Optional[Node] = None\n",
    "        self._n_features: Optional[int] = None\n",
    "\n",
    "    def _variance_reduction(self,\n",
    "                          parent_class: np.ndarray,\n",
    "                          left_class: np.ndarray,\n",
    "                          right_class: np.ndarray) -> float:\n",
    "        \n",
    "        parent_variance = np.var(parent_class)\n",
    "        left_variance = np.var(left_class)\n",
    "        right_variance = np.var(right_class)\n",
    "\n",
    "        if len(parent_class) != len(left_class) + len(right_class):\n",
    "            raise ValueError('Summed number of split samples must equal total number of samples')\n",
    "        \n",
    "        left_weight = len(left_class) / len(parent_class)\n",
    "        right_weight = len(right_class) / len(parent_class)\n",
    "\n",
    "        final_var_reduction = parent_variance - (left_weight * left_variance + right_weight * right_variance)\n",
    "\n",
    "        return final_var_reduction\n",
    "    \n",
    "    def _best_split(self,\n",
    "                    training_array: ArrayLike,\n",
    "                    training_targets: ArrayLike) -> Tuple[int, float]:\n",
    "        \n",
    "        train_array = _2D_numeric(training_array)\n",
    "        train_targets = _ensure_numeric(training_targets)\n",
    "\n",
    "        _, n_features = train_array.shape\n",
    "\n",
    "        best_var = -np.inf\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "\n",
    "        for feature in range(n_features):\n",
    "            feature_values = np.sort(np.unique(train_array[:, feature]))\n",
    "            possible_thresholds = (feature_values[:-1] + feature_values[1:]) / 2\n",
    "            for threshold in possible_thresholds:\n",
    "                left_indices = train_array[:, feature] <= threshold\n",
    "                right_indices = train_array[:, feature] > threshold\n",
    "                \n",
    "                left_classes = train_targets[left_indices]\n",
    "                right_classes = train_targets[right_indices]\n",
    "\n",
    "                if len(left_classes) == 0 or len(right_classes) == 0:\n",
    "                    continue\n",
    "                \n",
    "                var = self._variance_reduction(train_targets, left_classes, right_classes)\n",
    "\n",
    "                if var > best_var:\n",
    "                    best_var = var\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "        \n",
    "        return best_feature, best_threshold\n",
    "                \n",
    "    def _leaf_value(self, training_targets: np.ndarray) -> Union[int, float, str]:\n",
    "\n",
    "        train_targets = _ensure_numeric(training_targets)\n",
    "        regression = np.mean(train_targets)\n",
    "\n",
    "        return regression\n",
    "    \n",
    "    def _build_tree(self, training_array: ArrayLike, training_targets: ArrayLike, depth: int) -> Node:\n",
    "\n",
    "        train_array = _2D_numeric(training_array)\n",
    "        train_targets = _ensure_numeric(training_targets)\n",
    "\n",
    "        n_samples, n_features = train_array.shape\n",
    "\n",
    "        if n_samples < self.min_samples_split:\n",
    "            return Node(value = self._leaf_value(train_targets))\n",
    "        if self.max_depth is not None and self.max_depth <= depth:\n",
    "            return Node(value = self._leaf_value(train_targets))\n",
    "        if np.var(train_targets) == 0:\n",
    "            return Node(value = self._leaf_value(train_targets))\n",
    "        \n",
    "        best_feature, best_threshold = self._best_split(train_array, train_targets)\n",
    "\n",
    "        left_indices = train_array[:, best_feature] <= best_threshold\n",
    "        right_indices = train_array[:, best_feature] > best_threshold\n",
    "        \n",
    "        left_classes = train_targets[left_indices]\n",
    "        right_classes = train_targets[right_indices]\n",
    "\n",
    "        left_child = self._build_tree(train_array[left_indices, :], left_classes, depth + 1)\n",
    "        right_child = self._build_tree(train_array[right_indices, :], right_classes, depth + 1)\n",
    "\n",
    "        return Node(feature_index = best_feature, threshold_value = best_threshold, left = left_child, right = right_child)\n",
    "    \n",
    "    def fit(self, training_array: ArrayLike, training_targets: ArrayLike) -> \"regression_tree\":\n",
    "        \n",
    "        train_targets = _ensure_numeric(training_targets)\n",
    "        train_array = _2D_numeric(training_array)\n",
    "        self._n_features = train_array.shape[1]\n",
    "\n",
    "        final_tree = self._build_tree(train_array, train_targets, 0)\n",
    "        self.tree = final_tree\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def _verify_fit(self) -> \"regression_tree\":\n",
    "        if self.tree is None:\n",
    "            raise RuntimeError(\"Model is not fitted; call fit(training_array, training_targets)\")\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, testing_array: ArrayLike) -> np.ndarray:\n",
    "\n",
    "        self._verify_fit()\n",
    "\n",
    "        test_array = _2D_numeric(testing_array)\n",
    "\n",
    "        if test_array.shape[1] != self._n_features:\n",
    "            raise ValueError(\"Number of features in testing data must match number of features in training data\")\n",
    "\n",
    "        prediction_array = np.full((test_array.shape[0],), np.nan, dtype = float)\n",
    "        for sample in range(test_array.shape[0]):\n",
    "            prediction = self._predict_recursive(test_array[sample, :], self.tree)\n",
    "            prediction_array[sample] = prediction\n",
    "        \n",
    "        if any(value is np.nan or value is None for value in prediction_array):\n",
    "            raise ValueError(\"Predictions were not made for all samples\")\n",
    "        \n",
    "        return prediction_array\n",
    "\n",
    "    def _predict_recursive(self, testing_row: np.ndarray, node: Node) -> Union[int, float, str]:\n",
    "        \n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        \n",
    "        if testing_row[node.feature_index] <= node.threshold:\n",
    "            return self._predict_recursive(testing_row, node.left)\n",
    "        else:\n",
    "            return self._predict_recursive(testing_row, node.right)\n",
    "    \n",
    "    def print_tree(self, node: Optional[Node] = None, depth: int = 0) -> None:\n",
    "        \n",
    "        if node is None:\n",
    "            self._verify_fit()\n",
    "            node = self.tree\n",
    "\n",
    "        if node.is_leaf():\n",
    "            print(\"\\t\" * depth + f\"Predict: {node.value}\")\n",
    "        else:\n",
    "            print(\"\\t\" * depth + f\"Feature {node.feature_index} <= {node.threshold}\")\n",
    "            self.print_tree(node.left, depth + 1)\n",
    "            self.print_tree(node.right, depth + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 6. 9.]\n",
      "Feature 0 <= 2.5\n",
      "\tFeature 0 <= 1.5\n",
      "\t\tPredict: 2.0\n",
      "\t\tPredict: 4.0\n",
      "\tFeature 0 <= 3.5\n",
      "\t\tPredict: 6.0\n",
      "\t\tPredict: 9.0\n",
      "0 2.5\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([[1], [2], [3], [4], [5]])\n",
    "y_train = np.array([2.0, 4.0, 6.0, 8.0, 10.0])  # Linear relationship: y = 2*x\n",
    "\n",
    "# Testing data\n",
    "X_test = np.array([[1.5], [3.5], [5]])\n",
    "\n",
    "regression = regression_tree(max_depth = 2, min_samples_split=1)\n",
    "regression.fit(X_train, y_train)\n",
    "print(regression.predict(X_test))\n",
    "regression.print_tree()\n",
    "\n",
    "best_feature, best_threshold = regression._best_split(X_train, y_train)\n",
    "print(best_feature, best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4. 6.]\n",
      "Feature 0 <= 1.5\n",
      "\tPredict: 4.0\n",
      "\tPredict: 6.0\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([\n",
    "    [1, 2],\n",
    "    [1, 4],\n",
    "    [2, 2],\n",
    "    [2, 4]\n",
    "])\n",
    "y_train = np.array([3.0, 5.0, 5.0, 7.0])\n",
    "\n",
    "tree = regression_tree(max_depth=1, min_samples_split=2)\n",
    "tree.fit(X_train, y_train)\n",
    "X_test = np.array([[1,3],[2,3]])\n",
    "y_pred = tree.predict(X_test)\n",
    "print(y_pred)  # should be approx [4.0, 6.0]\n",
    "tree.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 5.]\n",
      "Feature 0 <= 1.0\n",
      "\tFeature 1 <= 3.0\n",
      "\t\tPredict: 3.0\n",
      "\t\tPredict: 5.0\n",
      "\tFeature 1 <= 3.0\n",
      "\t\tPredict: 5.0\n",
      "\t\tPredict: 7.0\n"
     ]
    }
   ],
   "source": [
    "# Training data (2 features)\n",
    "X_train = np.array([\n",
    "    [1, 2],\n",
    "    [1, 4],\n",
    "    [2, 2],\n",
    "    [2, 4]\n",
    "])\n",
    "y_train = np.array([3.0, 5.0, 5.0, 7.0])  # roughly: y = x1 + x2\n",
    "\n",
    "# Testing data\n",
    "X_test = np.array([\n",
    "    [1, 3],\n",
    "    [2, 3]\n",
    "])\n",
    "\n",
    "# Expected outcomes (depending on splits):\n",
    "#   1,3  leaf covering [1,2], [1,4]  mean = (3+5)/2 = 4\n",
    "#   2,3  leaf covering [2,2], [2,4]  mean = (5+7)/2 = 6\n",
    "expected_y = np.array([4.0, 6.0])\n",
    "\n",
    "tree = regression_tree(max_depth=None, min_samples_split=1)\n",
    "tree.fit(X_train, y_train)\n",
    "X_test = np.array([[1,3],[2,3]])\n",
    "y_pred = tree.predict(X_test)\n",
    "print(y_pred)  # should be approx [4.0, 6.0]\n",
    "tree.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[1], [1], [2], [2]])\n",
    "y_train = np.array([5.0, 5.0, 10.0, 10.0])\n",
    "\n",
    "X_test = np.array([[1], [2], [1.5]])\n",
    "\n",
    "# Expected outcomes:\n",
    "#   1  leaf covering [1,1]  mean = 5\n",
    "#   2  leaf covering [2,2]  mean = 10\n",
    "#   1.5  maybe split [1,2]  mean = (5+10)/2 = 7.5\n",
    "expected_y = np.array([5.0, 10.0, 7.5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
