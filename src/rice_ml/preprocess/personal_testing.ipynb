{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [],
   "source": [
    "ArrayLike = Union[np.ndarray, Sequence[float], Sequence[Sequence[float]], pd.DataFrame, pd.Series]\n",
    "\n",
    "def _2D_numeric(data: ArrayLike, name: str = 'Data') -> np.ndarray:\n",
    "    # TODO: add type hints and docstrings, change the name Data, make the isinstance(ArrayLike thing)\n",
    "\n",
    "    array = np.asarray(data)\n",
    "    if array.ndim != 2:\n",
    "        raise ValueError(f'{name} must be a 2D array; got {array.ndim}D instead.')\n",
    "    if array.size == 0:\n",
    "        raise ValueError(f'{name} must be non-empty')\n",
    "    if not np.issubdtype(array.dtype, np.number):\n",
    "        try:\n",
    "            array = array.astype(float, copy = False)\n",
    "        except (TypeError, ValueError) as e:\n",
    "            raise TypeError(f'All entries in {name} must be numeric') from e\n",
    "    else:\n",
    "        array = array.astype(float, copy = False)\n",
    "    return array\n",
    "\n",
    "def _1D_numeric(data_vector: Optional[ArrayLike], name: str = 'Data') -> Optional[np.ndarray]:\n",
    "    \n",
    "    # TODO: add type hints and docstrings, change the name Data\n",
    "\n",
    "    if data_vector is None:\n",
    "        return None\n",
    "    vector = np.asarray(data_vector)\n",
    "    if vector.ndim != 1:\n",
    "        raise ValueError(f'{name} must be a 1D array; got {vector.ndim}D instead')\n",
    "    if vector.size == 0:\n",
    "        raise ValueError(f'{name} must be non-empty')\n",
    "    return vector\n",
    "\n",
    "def _shape_match(data_array: np.ndarray, data_vector: Optional[np.ndarray]) -> None:\n",
    "\n",
    "    # TODO: add type hints and docstrings\n",
    "\n",
    "    if not isinstance(data_array, np.ndarray):\n",
    "        raise ValueError(f'Data array must be an array, got {type(data_array).__name__}')\n",
    "    \n",
    "    if (data_vector is not None) and (not isinstance(data_vector, np.ndarray)):\n",
    "        raise ValueError(f'Data vector must be an array, got {type(data_vector).__name__}')\n",
    "\n",
    "    if data_vector is not None:\n",
    "        if data_array.shape[0] != data_vector.shape[0]:\n",
    "            raise ValueError(f'Both arrays must have the same first dimension;'\n",
    "                             f'got data_array.shape[0] = {data_array.shape[0]} '\n",
    "                             f'and data_vector.shape[0] = {data_vector.shape[0]} instead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = np.zeros((3,2))\n",
    "df2 = np.array([1,0, 3])\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    'A': [1.0, 5.0, 9.0, np.nan],       # numeric with a NaN\n",
    "    'B': [2.0, np.nan, 2.0, 4.0],       # numeric with repeated value (mode exists)\n",
    "    'C': [np.nan, 7.0, 11.0, 15.0],     # numeric with one NaN\n",
    "    'D': [4.0, 4.0, np.nan, 4.0],       # numeric with mode being 4\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [],
   "source": [
    "_shape_match(df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def missing_data(data_array: np.array, strategy: str):\n",
    "\n",
    "    # TODO: type hints, docstring, explanation of strategies, add workaround for all unique values in mode\n",
    "\n",
    "    array = _2D_numeric(data_array)\n",
    "\n",
    "    possible_strategies = {'drop', 'mean', 'median', 'mode'}\n",
    "    if strategy not in possible_strategies:\n",
    "        raise ValueError(f\"Strategy must be one of {possible_strategies}, got '{strategy}'\")\n",
    "    \n",
    "    if strategy == 'drop':\n",
    "        cleaned_array = array[~np.any(np.isnan(array), axis = 1)]\n",
    "    else:\n",
    "        cleaned_array = array.copy()\n",
    "        for column in range(array.shape[1]):\n",
    "            empty_elements = np.isnan(array[:, column])\n",
    "            if strategy == 'mean':\n",
    "                column_mean = np.nanmean(array[:, column])\n",
    "                cleaned_array[empty_elements, column] = column_mean\n",
    "            if strategy == 'median':\n",
    "                column_median = np.nanmedian(array[:, column])\n",
    "                cleaned_array[empty_elements, column] = column_median\n",
    "            if strategy == 'mode':\n",
    "                column_elements = array[:, column][~np.isnan(array[:, column])]\n",
    "                column_mode = stats.mode(column_elements).mode\n",
    "                cleaned_array[empty_elements, column] = column_mode\n",
    "            \n",
    "    return(cleaned_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplicates = pd.DataFrame({\n",
    "    'A': [1, 2, 1, 4, 1],\n",
    "    'B': [5, 6, 5, 8, 5],\n",
    "    'C': [9, 10, 9, 12, 9]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def duplicate_identify(data_array: ArrayLike, drop: bool = False):\n",
    "\n",
    "    # TODO: type hints, docstring, explanation of strategies, option to print duplicate rows/indicate (?)\n",
    "\n",
    "    array = _2D_numeric(data_array)\n",
    "    if not isinstance(drop, bool):\n",
    "            raise TypeError(f\"Drop parameter must be True or False, got {type(drop).__name__}\")\n",
    "\n",
    "    indices = []\n",
    "    for row in range(array.shape[0]):\n",
    "        for comparison_row in range(row + 1, array.shape[0]):\n",
    "            if np.array_equal(array[row], array[comparison_row]) and row != comparison_row:\n",
    "                indices.append(comparison_row)\n",
    "    indices = list(set(indices))\n",
    "\n",
    "    if drop == True:\n",
    "        cleaned_array = np.delete(array, indices, axis = 0)\n",
    "    elif drop == False:\n",
    "        cleaned_array = array.copy()\n",
    "\n",
    "    return cleaned_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  5.  9.]\n",
      " [ 2.  6. 10.]\n",
      " [ 1.  5.  9.]\n",
      " [ 4.  8. 12.]\n",
      " [ 1.  5.  9.]]\n"
     ]
    }
   ],
   "source": [
    "indices = duplicate_identify(df_duplicates, False)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[10, 20, 30], [12, 22, 29], [11, 21, 31], [100, 20, 30], [13, 200, 28]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_identify(data_array: ArrayLike, method: str, *, drop: bool = False, threshold: float = 3):\n",
    "\n",
    "    # TODO: type hints, docstring, explanation of strategies, option to print outliers/indicate (?)\n",
    "\n",
    "    array = _2D_numeric(data_array)\n",
    "\n",
    "    if not isinstance(drop, bool):\n",
    "        raise TypeError(f\"Drop parameter must be True or False, got {type(drop).__name__}\")\n",
    "    if not isinstance(threshold, (float, int)) or isinstance(threshold, bool):\n",
    "        raise TypeError(f\"threshold must be a float or integer, got {type(threshold).__name__}\")\n",
    "    possible_methods = {'IQR', 'zscore'}\n",
    "    if method not in possible_methods:\n",
    "        raise ValueError(f\"Method of outlier detection must be one of {possible_methods}, got '{method}'\")\n",
    "    \n",
    "    if method == 'IQR':\n",
    "        outlier_indices = set()\n",
    "        for column in range(array.shape[1]):\n",
    "            q3 = np.percentile(array[:, column], 75)\n",
    "            q1 = np.percentile(array[:, column], 25)\n",
    "            iqr = q3 - q1\n",
    "            indices = (np.where((array[:, column] > q3 + 1.5 * iqr) | (array[:, column] < q1 - 1.5 * iqr))[0]).tolist()\n",
    "            outlier_indices.update(indices)\n",
    "\n",
    "    if method == 'zscore':\n",
    "        outlier_indices = set()\n",
    "        z_scores = np.zeros_like(array, dtype=float)\n",
    "        z_scores = z_score_standardize(array, False,1)\n",
    "        print(z_scores)\n",
    "        outlier_rows = np.any(np.abs(z_scores) > threshold, axis=1)\n",
    "        outlier_indices.update(np.where(outlier_rows)[0])\n",
    "\n",
    "\n",
    "    if drop:\n",
    "        cleaned_array = np.delete(array, list(outlier_indices), axis = 0)\n",
    "    else:\n",
    "        cleaned_array = array.copy()\n",
    "\n",
    "    return cleaned_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.54215661 -0.51043295  0.39223227]\n",
      " [-0.48568196 -0.48254044 -0.58834841]\n",
      " [-0.51391929 -0.49648669  1.37281295]\n",
      " [ 1.99920249 -0.51043295  0.39223227]\n",
      " [-0.45744464  1.99989302 -1.56892908]]\n",
      "[[ 10.  20.  30.]\n",
      " [ 12.  22.  29.]\n",
      " [ 11.  21.  31.]\n",
      " [100.  20.  30.]\n",
      " [ 13. 200.  28.]]\n"
     ]
    }
   ],
   "source": [
    "test2 = outlier_identify(X, 'zscore', drop = True, threshold = 2)\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [10, 200, 5],\n",
    "    [12, 210, 6],\n",
    "    [11, 205, 5],\n",
    "    [13, 215, 6]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_standardize(data_array: ArrayLike, return_params: bool = False, ddof: int = 0)  -> Union[np.ndarray, Tuple[np.ndarray, dict]]:\n",
    "    \n",
    "    # TODO: add type hints/docstrings/examples\n",
    "\n",
    "    array = _2D_numeric(data_array)\n",
    "\n",
    "    if not isinstance(ddof, int):\n",
    "        raise TypeError(f\"Delta degrees of freedom parameter must be an integer, got {type(ddof).__name__}\")\n",
    "    \n",
    "    if not isinstance(return_params, bool):\n",
    "        raise TypeError(f\"return_params must be a boolean, got {type(return_params).__name__}\")\n",
    "\n",
    "    columnwise_mean = array.mean(axis = 0)\n",
    "    scale = array.std(axis = 0, ddof = ddof)\n",
    "    scale[scale == 0.0] = 1.0\n",
    "    standardized_array = (array - columnwise_mean) / scale\n",
    "\n",
    "    if return_params:\n",
    "        return standardized_array, {'mean': columnwise_mean, 'scale': scale}\n",
    "\n",
    "    return standardized_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.34164079, -1.34164079, -1.        ],\n",
       "        [ 0.4472136 ,  0.4472136 ,  1.        ],\n",
       "        [-0.4472136 , -0.4472136 , -1.        ],\n",
       "        [ 1.34164079,  1.34164079,  1.        ]]),\n",
       " {'mean': array([ 11.5, 207.5,   5.5]),\n",
       "  'scale': array([1.11803399, 5.59016994, 0.5       ])})"
      ]
     },
     "execution_count": 907,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard = z_score_standardize(X, True, 0)\n",
    "standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1, 10],\n",
    "    [2, 20],\n",
    "    [3, 30]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_standardize(data_array: ArrayLike, *, feature_range: Tuple[float, float] = (0.0, 1.0), return_params: bool = False)  -> Union[np.ndarray, Tuple[np.ndarray, dict]]:\n",
    "\n",
    "    # TODO: add type hints/docstrings/examples\n",
    "\n",
    "    array = _2D_numeric(data_array)\n",
    "    \n",
    "    if not (isinstance(feature_range, Tuple) and len(feature_range) == 2 and all(isinstance(element, (int, float)) for element in feature_range)):\n",
    "        raise TypeError(f\"Feature range must be a tuple of length 2 (min, max) with float or integer elements\")\n",
    "    \n",
    "    if not isinstance(return_params, bool):\n",
    "        raise TypeError(f\"return_params must be a boolean, got {type(return_params).__name__}\")\n",
    "    \n",
    "    feature_min, feature_max = feature_range[0], feature_range[1]\n",
    "    if feature_min >= feature_max:\n",
    "        raise ValueError(f\"Minimum of feature range must be less than maximum\")\n",
    "    \n",
    "    column_maximums = array.max(axis = 0)\n",
    "    column_minimums = array.min(axis = 0)\n",
    "    scale = column_maximums - column_minimums\n",
    "    scale[scale == 0.0] = 1.0\n",
    "    standardized_array = feature_min + ((array - column_minimums) / scale) * (feature_max - feature_min)\n",
    "\n",
    "    if return_params:\n",
    "        return standardized_array, {'minimum': column_minimums, 'maximum': column_maximums, 'scale': scale, 'feature_range': feature_range}\n",
    "    return standardized_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0. , 0. ],\n",
       "        [0.5, 0.5],\n",
       "        [1. , 1. ]]),\n",
       " {'minimum': array([ 1., 10.]),\n",
       "  'maximum': array([ 3., 30.]),\n",
       "  'scale': array([ 2., 20.]),\n",
       "  'feature_range': (0.0, 1.0)})"
      ]
     },
     "execution_count": 910,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard = min_max_standardize(X, return_params = True)\n",
    "standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [ 2, -5,  3],\n",
    "    [ 4,  0, -6],\n",
    "    [-2,  5,  0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_abs_standardize(data_array: ArrayLike, return_params: bool = False) -> Union[np.ndarray, Tuple[np.ndarray, dict]]:\n",
    "    \n",
    "    # TODO: add type hints/docstrings/examples\n",
    "\n",
    "    array = _2D_numeric(data_array)\n",
    "\n",
    "    if not isinstance(return_params, bool):\n",
    "        raise TypeError(f\"return_params must be a boolean, got {type(return_params).__name__}\")\n",
    "    \n",
    "    absolute_value_array = abs(array)\n",
    "    column_maximums = absolute_value_array.max(axis = 0)\n",
    "    column_maximums[column_maximums == 0.0] = 1.0\n",
    "    standardized_array = array / column_maximums\n",
    "\n",
    "    if return_params:\n",
    "        return standardized_array, {'scale': column_maximums}\n",
    "    return standardized_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5, -1. ,  0.5],\n",
       "       [ 1. ,  0. , -1. ],\n",
       "       [-0.5,  1. ,  0. ]])"
      ]
     },
     "execution_count": 913,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard = max_abs_standardize(X)\n",
    "standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [3, 4, 0],\n",
    "    [1, 2, 2],\n",
    "    [0, 0, 5],\n",
    "    [0,0,0],\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_standardize(data_array: ArrayLike, epsilon: float = 1e-15) -> np.ndarray:\n",
    "\n",
    "    # TODO: add type hints/docstrings/examples\n",
    "\n",
    "    array = _2D_numeric(data_array)\n",
    "\n",
    "    if not isinstance(epsilon, (float, int)):\n",
    "        raise TypeError(f\"Floor value must be a float, got {type(epsilon).__name__}\")\n",
    "    \n",
    "    if epsilon <= 0:\n",
    "        raise ValueError(\"Floor value must be greater than zero\")\n",
    "    \n",
    "    l2_norms = np.linalg.norm(array, axis = 1)\n",
    "    l2_norms[l2_norms <= epsilon] = epsilon\n",
    "    l2_norms = l2_norms[:, None]\n",
    "\n",
    "    standardized_array = array / l2_norms\n",
    "\n",
    "    return standardized_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6       , 0.8       , 0.        ],\n",
       "       [0.33333333, 0.66666667, 0.66666667],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 916,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_standardize(X, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(['cat', 'cat', 'cat',\n",
    "              'dog', 'dog',\n",
    "              'mouse', 'cat'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bounded_count(length: int, proportion: float) -> int:\n",
    "    count = int(round(proportion * length))\n",
    "    if length <= 1:\n",
    "        if count < length:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "    return min(max(1, count), length - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stratified_indices(data: np.ndarray, \n",
    "                        test_size: float, \n",
    "                        rng: np.random.Generator, \n",
    "                        *, \n",
    "                        validation: bool = False,\n",
    "                        val_size: Optional[float] = None) -> Union[Tuple[np.array, np.array],Tuple[np.array, np.array, np.array]]:\n",
    "\n",
    "    # TODO: docstrings/type hints, examples\n",
    "\n",
    "    if not isinstance(test_size, float):\n",
    "        raise TypeError(f\"Test proportion must be a float, got {type(test_size).__name__}\")\n",
    "    if not isinstance(validation, bool):\n",
    "        raise TypeError(f\"Validation parameter must be a boolean, got {type(validation).__name__}\")\n",
    "    \n",
    "    if not (0.0 < test_size < 1.0):\n",
    "        raise ValueError(f\"Test proportion must be between 0 and 1, got {test_size}\")\n",
    "    \n",
    "    data = _1D_numeric(data)\n",
    "\n",
    "    if not validation:\n",
    "        classes, label_index = np.unique(data, return_inverse = True)\n",
    "        testing_indices = []\n",
    "        training_indices = []\n",
    "        for class_number in range(len(classes)):\n",
    "            class_index = np.flatnonzero(label_index == class_number)\n",
    "            rng.shuffle(class_index)\n",
    "\n",
    "            if len(classes) > 1:\n",
    "                test_number = max(1, int(round(test_size * len(class_index))))\n",
    "            else:\n",
    "                test_number = int(round(test_size * len(class_index)))\n",
    "\n",
    "            if len(class_index) > 1:\n",
    "                test_number = min(test_number, len(class_index) - 1)\n",
    "\n",
    "            testing_indices.append(class_index[0:test_number])\n",
    "            training_indices.append(class_index[test_number:])\n",
    "        \n",
    "        training_indices = np.concatenate(training_indices)\n",
    "        testing_indices = np.concatenate(testing_indices)\n",
    "\n",
    "        return testing_indices, training_indices\n",
    "\n",
    "    elif validation:\n",
    "        if not isinstance(val_size, float):\n",
    "            raise TypeError(f\"Validation set proportion must be a float, got {type(val_size).__name__}\")\n",
    "        if not (0.0 < val_size < 1.0):\n",
    "            raise ValueError(f\"Validation set proportion must be between 0 and 1, got {val_size}\")\n",
    "        if val_size + test_size >= 1.0:\n",
    "            raise ValueError(\"Combined validation and test set proportions must be less than 1.\")\n",
    "        \n",
    "        val_size_remaining = val_size / (1.0 - test_size)\n",
    "\n",
    "        classes, label_index = np.unique(data, return_inverse = True)\n",
    "        testing_indices = []\n",
    "        training_indices = []\n",
    "        val_indices = []\n",
    "\n",
    "        for class_number in range(len(classes)):\n",
    "            class_index = np.flatnonzero(label_index == class_number)\n",
    "            rng.shuffle(class_index)\n",
    "\n",
    "            if len(classes) > 1:\n",
    "                test_number = max(1, int(round(test_size * len(class_index))))\n",
    "            else:\n",
    "                test_number = int(round(test_size * len(class_index)))\n",
    "\n",
    "            if len(class_index) <= 1:\n",
    "                if test_number < len(class_index):\n",
    "                    test_number = 0\n",
    "                else:\n",
    "                    test_number = 1\n",
    "            else:\n",
    "                 test_number = min(test_number, len(class_index) - 1)\n",
    "\n",
    "            testing_indices_initial = class_index[0:test_number]\n",
    "            remaining_indices = class_index[test_number:]\n",
    "\n",
    "            val_number = int(round(val_size_remaining * len(remaining_indices)))\n",
    "            if len(remaining_indices) <= 1:\n",
    "                if val_number < len(remaining_indices):\n",
    "                    val_number = 0\n",
    "                else:\n",
    "                    val_number = 1\n",
    "            else:\n",
    "                val_number = min(val_number, len(remaining_indices) - 1)\n",
    "            \n",
    "            val_indices_initial = remaining_indices[0:val_number]\n",
    "            training_indices_initial = remaining_indices[val_number:]\n",
    "\n",
    "            testing_indices.append(testing_indices_initial)\n",
    "            training_indices.append(training_indices_initial)\n",
    "            val_indices.append(val_indices_initial)\n",
    "\n",
    "        training_indices = np.concatenate(training_indices)\n",
    "        testing_indices = np.concatenate(testing_indices)\n",
    "        val_indices = np.concatenate(val_indices)\n",
    "        \n",
    "        return testing_indices, training_indices, val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 0 4]\n",
      "[2 3 5]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "test, train, validate = _stratified_indices(y, 0.3, np.random.default_rng(), validation=True, val_size=0.2)\n",
    "print(train)\n",
    "print(test)\n",
    "print(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1.0, 10.0],   # class 'A'\n",
    "    [1.1, 11.0],\n",
    "    [0.9, 9.5],\n",
    "    [1.2, 10.5],\n",
    "    [5.0, 50.0],   # class 'B'\n",
    "    [5.1, 49.5],\n",
    "    [4.9, 51.0],\n",
    "    [9.0, 90.0],   # class 'C'\n",
    "    [9.1, 91.0]\n",
    "])\n",
    "\n",
    "y = np.array(['A', 'A', 'A', 'A', 'B', 'B', 'B', 'C', 'C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _random_number(random_state: Optional[int]) -> np.random.Generator:\n",
    "    \n",
    "    # TODO: type hints/docstrings\n",
    "\n",
    "    if random_state is None:\n",
    "        return np.random.default_rng()\n",
    "    else:\n",
    "        if not isinstance(random_state, int):\n",
    "            raise TypeError(f\"Random state must be an integer\")\n",
    "        return np.random.default_rng(int(random_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(data_array: ArrayLike, \n",
    "               data_vector: Optional[ArrayLike] = None, \n",
    "               test_size: float = 0.3,\n",
    "               validation: bool = False, \n",
    "               val_size: Optional[float] = 0.1,  \n",
    "               shuffle: bool = True, \n",
    "               stratify: Optional[ArrayLike] = None, \n",
    "               random_state: Optional[int] = None\n",
    "               ) -> Union[\n",
    "                        Union\n",
    "                            [Tuple[np.ndarray, np.ndarray], \n",
    "                             Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]], \n",
    "                        Union[\n",
    "                            Tuple[np.ndarray, np.ndarray, np.ndarray],\n",
    "                            Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray],\n",
    "                        ]]:\n",
    "    \n",
    "    array = _2D_numeric(data_array,'data array')\n",
    "\n",
    "    if not isinstance(test_size, float):\n",
    "        raise TypeError(f\"Test proportion must be a float, got {type(test_size).__name__}\")\n",
    "    if not isinstance(validation, bool):\n",
    "        raise TypeError(f\"Validation parameter must be a boolean, got {type(validation).__name__}\")\n",
    "    if not isinstance(shuffle, bool):\n",
    "        raise TypeError(f\"Shuffle parameter must be a boolean, got {type(shuffle).__name__}\")\n",
    "    \n",
    "    if not (0.0 < test_size < 1.0):\n",
    "        raise ValueError(f\"Test proportion must be between 0 and 1, got {test_size}\")\n",
    "\n",
    "\n",
    "    rng = _random_number(random_state)\n",
    "\n",
    "    if not validation:\n",
    "        if not stratify is None:\n",
    "            stratify_array = _1D_numeric(stratify, 'stratify')\n",
    "            if len(stratify_array) != array.shape[0]:\n",
    "                raise ValueError('Stratify must have the same length as the data array')\n",
    "            testing_indices, training_indices = _stratified_indices(stratify_array, test_size, rng)\n",
    "        else:\n",
    "            indices = np.arange(array.shape[0])\n",
    "            if shuffle:\n",
    "                rng.shuffle(indices)\n",
    "            test_number = _bounded_count(len(indices), test_size)\n",
    "            testing_indices = indices[0:test_number]\n",
    "            training_indices = indices[test_number:]\n",
    "\n",
    "        training_array = array[training_indices]\n",
    "        testing_array = array[testing_indices]\n",
    "\n",
    "        if data_vector is None:\n",
    "            return training_array, testing_array\n",
    "        else:\n",
    "            vector = _1D_numeric(data_vector, 'label')\n",
    "            _shape_match(array, vector)\n",
    "            training_data_vector = vector[training_indices]\n",
    "            testing_data_vector = vector[testing_indices]\n",
    "            return training_array, testing_array, training_data_vector, testing_data_vector\n",
    "\n",
    "    elif validation:\n",
    "        if not isinstance(val_size, float):\n",
    "            raise TypeError(f\"Validation set proportion must be a float, got {type(val_size).__name__}\")\n",
    "        if not (0.0 < val_size < 1.0):\n",
    "            raise ValueError(f\"Validation set proportion must be between 0 and 1, got {val_size}\")\n",
    "        if val_size + test_size >= 1.0:\n",
    "            raise ValueError(\"Combined validation and test set proportions must be less than 1.\")\n",
    "                \n",
    "        if not stratify is None:\n",
    "            stratify_array = _1D_numeric(stratify, 'stratify')\n",
    "            if len(stratify_array) != array.shape[0]:\n",
    "                raise ValueError('Stratify must have the same length as the data array')\n",
    "            testing_indices, training_indices, val_indices = _stratified_indices(stratify_array, test_size, rng, validation = True, val_size = val_size)\n",
    "        else:\n",
    "            val_prop_remaining = val_size / (1.0 - test_size)\n",
    "            indices = np.arange(array.shape[0])\n",
    "            if shuffle:\n",
    "                rng.shuffle(indices)\n",
    "\n",
    "            test_number = _bounded_count(len(indices), test_size)\n",
    "            testing_indices = indices[0:test_number]\n",
    "            remaining_indices = indices[test_number:]\n",
    "\n",
    "            val_number = _bounded_count(len(remaining_indices), val_prop_remaining)\n",
    "            val_indices = remaining_indices[0:val_number]\n",
    "            training_indices = remaining_indices[val_number:]\n",
    "\n",
    "        training_array = array[training_indices]\n",
    "        testing_array = array[testing_indices]\n",
    "        val_array = array[val_indices]\n",
    "\n",
    "        if data_vector is None:\n",
    "            return training_array, testing_array, val_array\n",
    "        else:\n",
    "            vector = _1D_numeric(data_vector, 'label')\n",
    "            _shape_match(array, vector)\n",
    "            training_data_vector = vector[training_indices]\n",
    "            testing_data_vector = vector[testing_indices]\n",
    "            val_data_vector = vector[val_indices]\n",
    "            return training_array, testing_array, val_array, training_data_vector, testing_data_vector, val_data_vector\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.9,  9.5],\n",
       "        [ 1.2, 10.5],\n",
       "        [ 5.1, 49.5],\n",
       "        [ 9.1, 91. ]]),\n",
       " array([[ 1.1, 11. ],\n",
       "        [ 5. , 50. ],\n",
       "        [ 9. , 90. ]]),\n",
       " array([[ 1. , 10. ],\n",
       "        [ 4.9, 51. ]]),\n",
       " array(['A', 'A', 'B', 'C'], dtype='<U1'),\n",
       " array(['A', 'B', 'C'], dtype='<U1'),\n",
       " array(['A', 'B'], dtype='<U1'))"
      ]
     },
     "execution_count": 977,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test(X, y, test_size = 0.3, validation = True, val_size = 0.2, stratify = y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
